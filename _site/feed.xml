<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-10-05T10:28:39+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">dsm Blogs</title><subtitle>This is a blog about Data Science and Machine Learning. I write about all the things I learn in this domain. I also share my knowledge with you.</subtitle><entry><title type="html">Policy Gradients</title><link href="http://localhost:4000/ai/2024/10/03/Policy_gradients.html" rel="alternate" type="text/html" title="Policy Gradients" /><published>2024-10-03T10:00:10+05:30</published><updated>2024-10-03T10:00:10+05:30</updated><id>http://localhost:4000/ai/2024/10/03/Policy_gradients</id><content type="html" xml:base="http://localhost:4000/ai/2024/10/03/Policy_gradients.html"><![CDATA[<p>Policy Gradients are a fundamental concept in reinforcement learning, offering a powerful approach to training agents in complex environments. Letâ€™s explore this fascinating topic in detail! ğŸ§ </p>

<p>In Reinforcement learning, there are two types of methods value-based methods and policy-based methods.</p>

<h1 id="policy-">Policy ğŸ®</h1>

<p>The algorithm a software agent uses to determine its actions is called its policy. The goal of the agent is to learn a policy that maximizes its reward over time. ğŸ¯</p>

<p>There are several types of policies:</p>

<ol>
  <li><strong>Deterministic policies</strong> ğŸ”’: 
These directly map states to actions</li>
  <li><strong>Stochastic policies</strong> ğŸ²: 
These map states to probability distributions over actions. An action is randomly chosen based on the probability distribution, and itâ€™s not necessary for the agent to always choose the action with the highest probability. This type of policy involves some randomness</li>
</ol>

<h2 id="value-based-methods">Value-Based Methods</h2>

<p>Value-based methods focus on learning the value function and <em>deriving a policy from it</em>. Some popular algorithms include: Q-Learning, SARSA (State-Action-Reward-State-Action), DQN (Deep Q-Network), Double DQN.</p>

<p>Check the other post about Q-learning to learn more about value based methods.</p>

<p><a href="https://ds-meena.github.io/ai/2024/09/23/Q_learning.html">Q-Learning</a></p>

<h2 id="policy-based-methods">Policy-Based Methods</h2>

<p>Policy-based methods refer to any reinforcment learning technicque that <em>directly learn a policy</em> without explicitly computing value functions. These can include:</p>

<ul>
  <li><strong>Policy Iteration</strong>: A method that alternates between policy evaluation and policy improvement.</li>
  <li><strong>Evolutionary Algorithms</strong>: Methods that use principles of biological evolution to optimize policies.</li>
  <li><strong>Policy Gradient Methods</strong>: Techniques that use gradient ascent to optimize the policy directly.</li>
</ul>

<h1 id="policy-gradients-">Policy Gradients ğŸ“ˆ</h1>

<p>In policy gradients, the agent learns to make decisions based on a policy, which is a mapping from states to actions. The method is particularly useful for problems where the environment is fully observable, and the agent can learn through trial and error. ğŸ§ ğŸ”</p>

<p>The policy gradient algorithm is an iterative process that gradually updates the policy parameters to maximize the expected reward. It improves the policy by playing, using gradient ascent and discounted rewards. The optimization is done using gradient ascent methods, such as stochastic gradient ascent. ğŸ”„ğŸ’¹</p>

<p>Policy gradients have been successfully applied to various domains, including robotics and natural language processing. ğŸ¤–ğŸ’¬</p>

<h3 id="the-fundamental-concept-">The Fundamental Concept ğŸ’¡</h3>

<p>The core idea of Policy Gradient methods can be summarized in three steps:</p>

<ol>
  <li>The agent performs an action based on its current policy ğŸ¤–</li>
  <li>The environment provides feedback in the form of a reward signal ğŸ‘€</li>
  <li>The policy is updated to increase the probability of actions that led to high rewards and decrease the probability of actions that led to low rewards ğŸ“ˆğŸ“‰</li>
</ol>

<h2 id="mathematical-framework-">Mathematical Framework ğŸ”¢</h2>

<p>Letâ€™s say we have a simple policy that chooses actions uniformly at random. The expected return for this policy could be calculated as:</p>

\[E_{Ï„âˆ¼Ï€_Î¸}[R(Ï„)] = \frac{1}{N} \sum_{i=1}^N R(Ï„_i)\]

<p>Where N is the number of sampled trajectories, and $R(Ï„_i)$ is the return (sum of rewards) for the $ith$ trajectory.</p>

<p>The Policy Gradient theorem forms the backbone of these methods. The objective is to maximize the expected return:</p>

\[J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} [R(\tau)]\]

<p>Where:</p>

<ul>
  <li>$J(Î¸)$ is the expected return</li>
  <li>$Î¸$ represents the policy parameters</li>
  <li>$Ï„$ is a trajectory (state-action sequence e.g. <code class="language-plaintext highlighter-rouge">Ï„ = [
  (s0, a0, r0, s1),  # (state, action, reward, next state)
  (s1, a1, r1, s2),
  (s2, a2, r2, s3),
  ...
  (sT, aT, rT, sT+1)
])</code></li>
  <li>$Ï€_Î¸$ is the policy</li>
  <li>$R(Ï„)$ is the return of a trajectory</li>
</ul>

<p>The gradient of this objective with respect to the policy parameters is given by:</p>

\[\nabla_\theta J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} \left[ \sum_{t=0}^T \nabla_\theta \log \pi_\theta(a_t \lvert s_t) R(\tau) \right]\]

<p>This equation can be interpreted as follows:</p>

<ul>
  <li>$âˆ‡_Î¸ log Ï€_Î¸(a_t\lvert s_t)$ is the gradient of the log probability of taking action $a_t$ in state $s_t$</li>
  <li>$R(Ï„)$ is the return of the trajectory, acting as a weighting factor</li>
  <li>The summation is over all time steps in the trajectory</li>
  <li>The expectation $E$ is taken over all possible trajectories under the current policy</li>
</ul>

<p>This equation tells us how to adjust our policy parameters Î¸ to increase the expected return. In practice, we often estimate this expectation using a finite number of sampled trajectories.</p>

<h2 id="practical-implementation-ï¸">Practical Implementation ğŸ–¥ï¸</h2>

<p>In practice, we often use the following steps to implement Policy Gradient methods:</p>

<ol>
  <li>Initialize the policy parameters $Î¸$ randomly</li>
  <li>For each episode:
    <ol>
      <li>Generate a trajectory $Ï„$ by following the current policy $Ï€_Î¸$</li>
      <li>Calculate the returns $R(Ï„)$ for the trajectory</li>
      <li>
        <p>Update the policy parameters using gradient ascent:</p>

\[Î¸ â† Î¸ + Î± âˆ‡_Î¸ J(Î¸)\]

        <p>Where Î± is the learning rate</p>
      </li>
    </ol>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">PolicyGradient</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_states</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_states</span> <span class="o">=</span> <span class="n">n_states</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_actions</span> <span class="o">=</span> <span class="n">n_actions</span>
        <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_build_model</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="c1"># represents our policy Ï€_Î¸
</span>    <span class="k">def</span> <span class="nf">_build_model</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_states</span><span class="p">,)),</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">),</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="k">return</span> <span class="n">model</span>
    
    <span class="c1"># follows stochastic policy Ï€_Î¸(a_t|s_t)
</span>    <span class="k">def</span> <span class="nf">choose_action</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_states</span><span class="p">])</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">probabilities</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="c1"># optimize the policy given a sequence of states, actions, rewards (trajectory)
</span>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">):</span>
        <span class="n">states</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span>
        
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
            <span class="n">neg_log_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">actions</span><span class="p">)</span>

            <span class="c1"># calcualte - log Ï€_Î¸(a_t|s_t) * R(Ï„) = -1 * gain
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">neg_log_prob</span> <span class="o">*</span> <span class="n">rewards</span><span class="p">)</span>
        
        <span class="c1"># calculate gradient of -ve gain
</span>        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        
        <span class="c1"># apply gradient descent
</span>        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
</code></pre></div></div>

<p>This code implements the Policy gradient method:</p>

<ol>
  <li>The policy $Ï€_Î¸$ is represented by the neural network model.</li>
  <li>The action selection follows the stochastic policy: $Ï€_Î¸(a_t\lvert s_t$).</li>
  <li>
    <p>The train method implements the policy gradient theorem:</p>

\[\nabla_\theta J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} \left[ \sum_{t=0}^T \nabla_\theta \log \pi_\theta(a_t\lvert s_t) R(\tau) \right]\]

    <p>Here, tf.nn.sparse_softmax_cross_entropy_with_logits computes $-log Ï€_Î¸(a_t\lvert s_t)$, and we multiply it by the rewards.</p>
  </li>
  <li>
    <p>The gradient computation and parameter update follow the equation:</p>

\[Î¸ â† Î¸ - Î± (- âˆ‡_Î¸ J(Î¸))\]

    <p>First -ve represents gradient descent and the second -ve represents negative of gradient of gain. That mean it maximizes the rewards.</p>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="nf">make</span><span class="p">(</span><span class="sh">'</span><span class="s">Acrobot-v1</span><span class="sh">'</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="nc">PolicyGradient</span><span class="p">(</span><span class="n">n_states</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">n_actions</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">reset</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># trajectory of the episode
</span>    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="p">.</span><span class="nf">choose_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        
        <span class="n">states</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">actions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">rewards</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
   
        <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
        
        <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
            <span class="k">break</span>
    
    <span class="c1"># Normalize rewards
</span>    <span class="n">rewards</span> <span class="o">=</span> <span class="p">(</span><span class="n">rewards</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
    
    <span class="c1"># Now, optimize the policy using trajectory of the episode
</span>    <span class="n">agent</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">)</span>
</code></pre></div></div>

<p>We have implemented the policy gradient of <a href="https://gymnasium.farama.org/environments/classic_control/acrobot/">Acrobot-v1</a> environment. Where it tries to stand up and avoid penalty of -1.</p>

<h2 id="advantages-and-challenges-">Advantages and Challenges ğŸ†ğŸš§</h2>

<p>Policy Gradient methods offer several benefits:</p>

<ul>
  <li>They can handle continuous action spaces effectively</li>
  <li>They can learn stochastic policies, which can be crucial in certain environments</li>
  <li>They can be more stable than value-based methods in some scenarios</li>
</ul>

<p>However, they also face challenges:</p>

<ul>
  <li>High variance in gradient estimates, which can lead to unstable learning</li>
  <li>Sample inefficiency, often requiring many interactions with the environment</li>
  <li>Sensitivity to hyperparameter choices</li>
</ul>

<h3 id="advanced-variants-">Advanced Variants ğŸš€</h3>

<p>Several advanced algorithms have been developed to address these challenges:</p>

<ul>
  <li><strong>Actor-Critic methods</strong>: Combine policy gradients with value function approximation to reduce variance</li>
  <li><strong>Trust Region Policy Optimization (TRPO)</strong>: Constrains policy updates to improve stability</li>
  <li><strong>Proximal Policy Optimization (PPO)</strong>: A simpler and more efficient version of TRPO</li>
</ul>

<p>Understanding these concepts and their mathematical foundations is crucial for effectively implementing and improving Policy Gradient methods in reinforcement learning applications.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Policy Gradients offer a powerful and flexible approach to reinforcement learning. By directly optimizing the policy, they can handle complex, high-dimensional action spaces and learn stochastic policies. While they face challenges like sample inefficiency and high variance, ongoing research continues to improve these methods, making them an exciting area of study in the field of AI and machine learning. ğŸ“ğŸ”¬</p>

<p>Remember, mastering policy gradients takes practice and experimentation. Happy learning! ğŸš€ğŸ¤–</p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Policy Gradients are a fundamental concept in reinforcement learning, offering a powerful approach to training agents in complex environments. Letâ€™s explore this fascinating topic in detail! ğŸ§ ]]></summary></entry><entry><title type="html">Q-Learning</title><link href="http://localhost:4000/ai/2024/09/23/Q_learning.html" rel="alternate" type="text/html" title="Q-Learning" /><published>2024-09-23T10:00:10+05:30</published><updated>2024-09-23T10:00:10+05:30</updated><id>http://localhost:4000/ai/2024/09/23/Q_learning</id><content type="html" xml:base="http://localhost:4000/ai/2024/09/23/Q_learning.html"><![CDATA[<h1 id="introduction">Introduction</h1>

<p>In this blog, we will learn about the fundamental algorithms used in reinforcement learning. Itâ€™s not about neural networks but the mathematical algorithms involved in learning.</p>

<h1 id="markov-decision-process-">Markov Decision Process ğŸ¤”</h1>

<p>Letâ€™s understand the problem, we are trying to solve here. The environment of an agent can be modelled as a Markov decision process, where the agent can choose one of several actions and the transition probabilities depend on the chosen action. ğŸ¤–</p>

<p>Our aim is to find an optimal policy for the agent, by following that agent can maximize the rewards earned in the enviornment.</p>

<p><img src="/assets/2024/September/markov%20decision%20chain.png" alt="alt text" />
<em>Fig: Example of Markov chain  <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">credit for image</a></em></p>

<p>Letâ€™s learn some of the algorithms that are used to find the optimal policy for the agent.</p>

<h2 id="state-value-iteration-algorithm-">(State) Value Iteration algorithm ğŸ”„</h2>

<p>In this algorithm, we calcualte the state value $V(s)$ for all states.</p>

<p>Optimal state value $V^*(s)$ of any state s, is the sum of all discounted future rewards the agent can expect on average after it reaches a state s, assuming it acts optimally. ğŸ¯</p>

<p>$V\star(s) = max_a \sum_sP(s,a,s\prime)[R(s,a,s\prime)+\gamma.V^*(s\prime)]$  for all s</p>

<p><em>Eq: Bellman Optimality Equation</em></p>

<p>where,</p>

<ul>
  <li>$P(s,a,sâ€™)$ = transition probability from state s to state sâ€™, given that agent chose action a [conditional probability]. ğŸ²</li>
  <li>$R(s,a,sâ€™)$ = reward the agent gets when it goes from state s to state sâ€™, given that agent chose action a ğŸ†</li>
  <li>$\gamma$ = discount factor ğŸˆ¹</li>
</ul>

<p>If we increase discount factor, we will value the future rewards more.
Bellman optimality equation assumes, that we already have the optimal state value for next state sâ€™. Since, we donâ€™t have future value; we update state values iteratively as follows:</p>

<ol>
  <li>First initialize all the state value estimates to 0.</li>
  <li>
    <p>Iteratively update them using recurrent relation</p>

    <p>$V_{k+1}(s) \leftarrow  \underset{a}{\max} \underset{sâ€™}{\sum}P(s,a,sâ€™) [R(s,a,sâ€™) + \gamma.V_k(sâ€™)]$ for all s</p>

    <p><em>Eq: Value Iteration algorithm</em> ğŸ”</p>

    <p>where</p>

    <ul>
      <li>$V_k(s)$ = estimated value of state s at the $k^{th}$ iteration</li>
    </ul>
  </li>
</ol>

<p>After the Value Iteration algorithm converges, we can derive the optimal policy $Ï€^\star$ for each state s: ğŸ¥³</p>

\[\pi^*(s) = \underset{a}{argmax} \sum_{s'} P(s, a, s')[R(s,a,s') + \gamma V^*(s')]\]

<p>This means that for each state, the optimal action is the one that maximizes the expected sum of the immediate reward and the discounted optimal value of the next state. ğŸ’°</p>

<h2 id="q-value-iteration-algorithm-">Q-Value Iteration algorithm ğŸ²</h2>

<p>This algorithm is used to find the optimal state-action values, genreally called Q-values (Quality values). ğŸ’¡</p>

<p>Optimal Q-value of state-action pair (s, a), $Q^*(s, a)$, is the sum of discounted future rewards the agent can expect on average after it reaches state s and chooses an action a. ğŸ’°</p>

<p>It involves following steps:</p>
<ol>
  <li>Initialize all Q-values estimates to 0.</li>
  <li>
    <p>Then update them using below recurrence relation. ğŸ”„</p>

    <p>$Q_{k+1}(s,a) \leftarrow \underset{sâ€™}{\sum}T(s,a,sâ€™)[R(s,a,sâ€™)+\gamma.\underset{aâ€™}{max} \space Q_k(sâ€™,aâ€™)]$</p>

    <p><em>Eq: Q-Value Iteration algorithm</em></p>

    <p>where:</p>
    <ul>
      <li>$\underset{aâ€™}{max} \space Q_k(sâ€™, aâ€™)$ is the maximum Q-value for the next state sâ€™ and all possible actions aâ€™ at $k_{th}$ iteratin</li>
    </ul>
  </li>
</ol>

<p>After the Q-Value Iteration algorithm converges, we can derive the optimal policy $\pi^*(s)$ for each state s.</p>

\[\pi^*(s) = \underset{a}{argmax} \space Q^\star(s,a)\]

<p>That means, when the agent is in state s it should choose the action with the highest Q-Value for that state. ğŸ†</p>

<p>Letâ€™s apply the Q-Value Iteration algorithm to MDP given in above image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># shape=[s, a, s']  # row - current state, column = action
# s2 to s0 given action a1 transition probability = [2][1][0]
</span><span class="n">transition_probabilities</span> <span class="o">=</span> <span class="p">[</span> 
		<span class="p">[[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]],</span> 
		<span class="p">[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="bp">None</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span> 
		<span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="bp">None</span><span class="p">]</span>
	<span class="p">]</span>

<span class="c1"># shape=[s, a, s']
</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">[</span>  
		<span class="p">[[</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> 
		<span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">50</span><span class="p">]],</span> 
		<span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">+</span><span class="mi">40</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
	<span class="p">]</span>

<span class="c1"># from s0, s1, s2
</span><span class="n">possible_actions</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>   

<span class="c1"># Initialize Q-Values
</span><span class="n">Q_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="p">)</span>  <span class="c1"># -np.inf for impossible actions
</span><span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">actions</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">possible_actions</span><span class="p">):</span>
	<span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">actions</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>     <span class="c1"># 0 for possible actions
</span>	
<span class="c1"># Q-Value Iteration algorithm
</span><span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.90</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
	<span class="n">Q_prev</span> <span class="o">=</span> <span class="n">Q_values</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
	
	<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
		<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">possible_actions</span><span class="p">[</span><span class="n">s</span><span class="p">]:</span>

			<span class="n">Q_values</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">([</span><span class="n">transition_probabilities</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="n">a</span><span class="p">][</span><span class="n">sp</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">rewards</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="n">a</span><span class="p">][</span><span class="n">sp</span><span class="p">]</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">Q_prev</span><span class="p">[</span><span class="n">sp</span><span class="p">]))</span>
				<span class="k">for</span> <span class="n">sp</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)])</span>
                        
<span class="nf">print</span><span class="p">(</span><span class="n">Q_values</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Best action for each state: </span><span class="sh">"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">Q_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># [[18.91891892 17.02702702 13.62162162]
#  [ 0.                -inf -4.87971488]
#  [       -inf 50.13365013        -inf]]
# Best action for each state  [0 0 1]
</span></code></pre></div></div>

<p>Using above algorithm we can find the best policy for the agent.</p>

<h1 id="q-learning-">Q-Learning ğŸ¤–</h1>

<p>If you notice in the above MDP diagram, the transition probabilities and rewards are given us in advance. Thatâ€™s not the case in real word ğŸŒ, now comes the role of Q-Learning algorithm. <strong>Q-Learning algorithm</strong> is an adaptation of the Q-Value Iteration algorithm to the situation where the transition probabilities and the rewards are initially unknown.</p>

<p>This algorithm is useful for problems where the environment is fully observable, and the agent can learn by trial and error. Q-learning has been successfully applied to problems such as game playing, robotics, and natural language processing. ğŸ§ ğŸ¤–</p>

<p>This is an example of <strong>model-free reinforcement learning</strong>, where the transition probabilities and the rewards are initially unknown and agent has to learn these by direct interactions and experiences.</p>

<p>$Q(s,a) \underset {\alpha}{\leftarrow} r + \gamma.\underset{aâ€™}{max} \space Q(sâ€™, aâ€™)$</p>

<p><em>Eq: Q-Learning algorithm</em></p>

<p>$ old \underset {\alpha}{\leftarrow} new â‡’ old(1-a) + a*new$ [This is how be interpret the above equation]</p>

<h2 id="q-learning-algorithm-">Q-learning algorithm ğŸ§ </h2>

<ol>
  <li>Initialize the Q-table with arbitrary values for all state-action pairs.</li>
  <li>Observe the current state.</li>
  <li>Select an action to take based on the current state and the values in the Q-table. This can be done using an exploration-exploitation strategy such as epsilon-greedy.</li>
  <li>Take the selected action and observe the reward and the new state. (a, r, sâ€™)</li>
  <li>
    <p>Update the Q-value for the state-action pair that was just taken based on the observed reward and the maximum Q-value for the new state.</p>

    <p>The Q-learning algorithm uses the following equation to update the Q-value for a state-action pair:</p>

    <p>$Q(s,a) {\leftarrow} (1-\alpha)Q(s,a) + \alpha(  r + \gamma.\underset{aâ€™}{max} \space Q(sâ€™, aâ€™))$</p>

    <p>Where:</p>

    <ul>
      <li>Q(s, a) is the Q-value for state s and action a</li>
      <li>Î± is the learning rate, which determines how much the Q-value is updated in each iteration</li>
      <li>r is the reward received for taking action a in state s</li>
      <li>Î³ is the discount factor, which determines the importance of future rewards</li>
      <li>$\underset{aâ€™}{max} \space Q(sâ€™, aâ€™)$ is the maximum Q-value for the next state sâ€™ and all possible actions aâ€™ (maximum future reward estimate)</li>
      <li>sâ€™ is the next state reached after taking action a in state s</li>
    </ul>
  </li>
  <li>Repeat ğŸ”„ steps 2-5 until the algorithm converges or a maximum number of iterations is reached.</li>
</ol>

<p>The optimal policy ğŸ† can be derived by selecting the action with the highest Q-value for each state as in Q-value Iteration algorithm.</p>

<p>Letâ€™s implement Q-Learning algorithm using open AI gym environment (Taxi-v3). ğŸš•</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="nf">make</span><span class="p">(</span><span class="sh">'</span><span class="s">Taxi-v3</span><span class="sh">'</span><span class="p">)</span>

<span class="n">Q_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="n">env</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">n</span><span class="p">,</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span><span class="p">])</span>

<span class="c1"># exploration policy
</span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Exploration rate
</span>
<span class="k">def</span> <span class="nf">exploration_policy</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="nf">sample</span><span class="p">()</span>  <span class="c1"># Explore
</span>    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">])</span>  <span class="c1"># Exploit
</span></code></pre></div></div>

<p>Q-Learning algorithm with learning rate decay: â˜¢ï¸</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Hyperparameters
</span><span class="n">alpha0</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Initial learning rate
</span><span class="n">decay</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>  <span class="c1"># Discount factor
</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">reset</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
    
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="nf">exploration_policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        
        <span class="c1"># Q-learning update
</span>        <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">episode</span> <span class="o">*</span> <span class="n">decay</span><span class="p">)</span>
        
        <span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">*=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span>
        <span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">+=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">Q_values</span><span class="p">[</span><span class="n">next_state</span><span class="p">]))</span>
        
        <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
</code></pre></div></div>

<p><img src="/assets/2024/September/Q_learning.png" alt="Fig: The Q-Value Iteration algorithm (left) versus the Q-Learning algorithm (donâ€™t know anything) (right)" /></p>

<p><em>Fig: The Q-Value Iteration algorithm (left) versus the Q-Learning algorithm (donâ€™t know anything) (right) <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">credit for image</a></em></p>

<p>Obviously, not knowing the transition probabilities or the rewards makes finding the optimal policy significantly harder!</p>

<h3 id="advantage">Advantage</h3>

<p>It can learn optimal policies without requiring a model of the environment. (Model-free reinforcement learning algorithm).  Instead, it learns directly from experience by updating the Q-values based on observed rewards and transitions between states.</p>

<h3 id="disadvantage">Disadvantage</h3>

<p>It can be computationally expensive and may require a large amount of data to converge to an optimal solution.</p>

<p>Overall, Q-learning is a powerful technique with many potential applications, but it is important to carefully consider the problem and the available data before choosing a Q-learning approach.</p>

<h2 id="references">References</h2>

<ol>
  <li>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Buy here</a></li>
</ol>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2024/09/15/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2024-09-15T15:08:10+05:30</published><updated>2024-09-15T15:08:10+05:30</updated><id>http://localhost:4000/jekyll/update/2024/09/15/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/09/15/welcome-to-jekyll.html"><![CDATA[<p>Youâ€™ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>Jekyll requires blog post files to be named according to the following format:</p>

<p><code class="language-plaintext highlighter-rouge">YEAR-MONTH-DAY-title.MARKUP</code></p>

<p>Where <code class="language-plaintext highlighter-rouge">YEAR</code> is a four-digit number, <code class="language-plaintext highlighter-rouge">MONTH</code> and <code class="language-plaintext highlighter-rouge">DAY</code> are both two-digit numbers, and <code class="language-plaintext highlighter-rouge">MARKUP</code> is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span></code></pre></figure>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyllâ€™s GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Youâ€™ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.]]></summary></entry><entry><title type="html">Gradient Descent</title><link href="http://localhost:4000/ai/2024/08/03/Gradient_descent.html" rel="alternate" type="text/html" title="Gradient Descent" /><published>2024-08-03T15:08:10+05:30</published><updated>2024-08-03T15:08:10+05:30</updated><id>http://localhost:4000/ai/2024/08/03/Gradient_descent</id><content type="html" xml:base="http://localhost:4000/ai/2024/08/03/Gradient_descent.html"><![CDATA[<p>In this blog post, we will understand the underlying algorithm for training neural networks. We will discuss gradient descent, the most basic step of training any model, and backpropagation.</p>

<h1 id="gradient-descent">Gradient Descent</h1>

<p>The gradient is, simply a row vector of a functionâ€™s partial derivatives. It represents the direction and rate of the steepest increase of a function.</p>

<p>Example: gradient $\nabla f$ of the function $f(a, b, c)  = ab^2 + 2c^3$, where the variables in order, are a, b, and c:</p>

<p>$\nabla f = (\frac{\partial f}{\partial a} \frac{\partial f}{\partial b} \frac{\partial f}{\partial c}) = (b^2 \space\space\space\space 2ab \space\space\space\space 6c^2)$</p>

<p>In basic calculus, with a simple algebraic function such as a polynomial, a standard optimization process is to:</p>

<ol>
  <li>take the derivative of the function</li>
  <li>set the derivative equal to 0, and then</li>
  <li>solve for the parameters (inputs) that satisfy this equation.</li>
</ol>

<p>Since, ANNs functions are very complicated, solving for 0 is not possible. Thus, <strong>heuristic methods are often used</strong> (trail &amp; error).</p>

<p>Gradient descent is a heuristic method that starts at a random point and iteratively moves in the direction (hence â€œgradientâ€) that decreases (hence â€œdescentâ€) the function that we want to minimize, which is usually a cost function. With enough of these steps in the decreasing direction, a local of these steps in the decreasing direction, a local minimum can theoretically be reached.</p>

<p>Colloquially, think of it as playing a game of â€œhotâ€ and â€œcoldâ€ until the improvement becomes negligible.</p>

<p><img src="/assets/2024/September/gradient%20descent.png" alt="nse-6188589518431236078-512387566.png" /></p>

<p>The gradient indicates the direction of steepest ascent of the function, and its negative is the direction of steepest descent.</p>

<h3 id="gradient-descent-algorithm">Gradient Descent Algorithm</h3>

<ol>
  <li>Initialize the weights and biases of the neural network with random values.</li>
  <li>Do the following until the cost stops improving or a fixed number of iterations:
    <ol>
      <li>Calculate cost function value with current parameters.</li>
      <li>Calculate the gradient of the cost function w.r.t to its parameters.</li>
      <li>Update the parameters by taking a small step in the opposite direction of the gradient.</li>
    </ol>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
	<span class="n">cost</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>  
	<span class="n">new_point</span> <span class="o">=</span> <span class="n">point</span> <span class="o">-</span> <span class="n">step_size</span> <span class="o">*</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>  <span class="c1"># -ve for descent
</span>	<span class="n">new_cost</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">new_point</span><span class="p">)</span>
	
	<span class="c1"># if doesn't improve cost
</span>	<span class="k">if</span> <span class="nf">abs</span><span class="p">(</span><span class="n">new_cost</span> <span class="o">-</span> <span class="n">cost</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
		<span class="k">return</span> <span class="n">value</span>
	
	<span class="c1"># go to new point
</span>	<span class="k">return</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">new_point</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
</code></pre></div></div>

<p>Letâ€™s look at an example of how we update the parameters:</p>

<p>Letâ€™s say we function $f(x, y) = 2 + 3x^2 + 4y^2$, and we try to do a single step of gradient descent. Find the next set of parameters if we start at (10, 10) with step size = 0.5?</p>

<p>Solution: We calculate gradient of this function, gradient $\nabla f = (\frac{\partial f}{\partial x} \frac{\partial f}{\partial y}) = (6x, 8y)$</p>

<p>We know that,</p>

<p>$\text{new point} = point - \text{step size} * gradient(point)$</p>

<p>$\text{new point} = (10, 10) - 0.5 * (12, 16) â‡’ (10, 10) - (6, 8) â‡’ (4, 2)$</p>

<p>Here, we moved in the direction opposite to the vector that is one-half the gradient at (10, 10).</p>

<p>A more scary way to write the above function and equation of gradient descent:
$w_{j+1} = w_j - \eta \nabla Q(w_j)$</p>

<p>where,</p>

<p>$w$ is a vector of parameters we are optimizing over</p>

<p>$Q$ is our cost function</p>

<p>$\eta$ learning parameter</p>

<p>$\nabla Q$ gives direction of steepest ascent, and $- \nabla Q$ points to direction of steepest descent.</p>

<p>Once you get to the bottom of the bowl, $\nabla Q = 0$, the algorithm terminates.</p>

<p><img src="/assets/2024/September/gradient%20descent%20pitfalls.png" alt="Fig: Gradient Descent pitfalls" /></p>

<p><em>Fig: Gradient Descent pitfalls</em></p>

<p>Gradient descent has some pitfalls, like it might get stuck at a local minimum, or the gradient might be much lower, e.g., on a plateau. Because of this, it might take more time to train.</p>

<p>Gradient descent is a key component of training neural networks, and understanding its properties and variants is important for building effective models.</p>

<h2 id="types-of-gradient-descent">Types of Gradient Descent</h2>

<p>There are several variants of gradient descent, including batch gradient descent, stochastic gradient descent, and mini-batch gradient descent. These variants differ in the number of examples used to compute the gradient at each iteration and can have different convergence rates and computational requirements.</p>

<p>Some of the Gradient Descent are explained below:</p>

<h3 id="1-batch-gradient-descent">1. Batch Gradient Descent</h3>

<p>Batch gradient descent (BGD) computes the gradient of the cost function with respect to the parameters for the entire training set at each iteration. The weights and biases are then updated based on this gradient.</p>

<p>gradient is calculated using all training examples.</p>

<p>Example â†’</p>

<p>$Q(w) = \frac{1}{N}   \sum_{i=1}^N Q_i(w)$    = cost is calculated using all training examples</p>

<p>$\nabla Q = \frac{1}{N} \sum_{i=1}^N \nabla Q_i$           = gradient is calculated using all training examples.</p>

<p>Gradient itself contains all parameters, here we are talking about examples.</p>

<p>how much the cost function will change if you change $\theta_j$ just a little bit. This is called <em>partial derivative.</em></p>

<p>$\frac{\partial}{\partial\theta_j}  MSE(\theta) = \frac{2}{m} \sum_{i=1}^{m} (\theta^Tx^{(i)} - y^{(i)})x_j^{(i)}$</p>

<p><img src="/assets/2024/September/gradient%20vector%20of%20cost.png" alt="Fig: Gradient vector of the cost function" /></p>

<p><em>Fig: Gradient vector of the cost function</em></p>

<p>Once you have the gradient vector, which points uphill, just go in the opposite direction to go downhill. This means subtracting $\Delta_{\theta}MSE(\theta)$ from $\theta$ (itâ€™s like going one unit back).</p>

<p>$\theta^{\text{next step}} = \theta - \eta\Delta_{\theta}MSE(\theta)$</p>

<p>Eq: Gradient Descent step</p>

<p>BGD can be computationally expensive, especially for large datasets, but it can converge quickly and reach a global minimum of the cost function.</p>

<h3 id="2-stochastic-gradient-descent">2. Stochastic Gradient Descent</h3>

<p>Stochastic gradient descent (SGD) updates the weights and biases based on the gradient of the cost function with respect to the parameters for a single training example at each iteration. The gradient is therefore noisy and may not be representative of the overall gradient.</p>

<p>gradient is calculated using one example (as we have been doing in perceptron)</p>

<p>If N is extremely large, computing</p>

<p>$\nabla Q = \frac{1}{N} \sum_{i=1}^N \nabla Q_i$</p>

<p>and evaluating all N functions at w may be very time-consuming.</p>

<p>Stochastic Gradient Descent (SGD) is called â€œstochasticâ€ because it uses a random sample. This randomness helps SGD to avoid local minima and converge faster.</p>

<h3 id="3-mini-batch-gradient-descent">3. Mini-Batch Gradient Descent</h3>

<p>Mini-batch gradient descent (MBGD) is a compromise between BGD and SGD. It computes the gradient of the cost function with respect to the parameters for a small batch of training examples at each iteration.</p>

<p>MBGD can be more computationally efficient than BGD and less noisy than SGD, and it can converge quickly with appropriate batch sizes.</p>

<p>The choice of gradient descent algorithm depends on the specific problem and the available computational resources.</p>

<h1 id="backpropagation">Backpropagation</h1>

<p>If gradient descent was a single step to optimize the weights, then backpropagation is the complete algorithm to train neural networks.
Letâ€™s understand the intuition behind backpropagation with an example. Suppose a we are predicting the affinity of a person being male athlete on basis of purchases. We have one hidden layer with two neurons which correspond to the likelihood of being male and related to sports. For input X, we predict some output and later get to know that the input was male sports shoes. Now, how should our neural network update the weight of item X in predicting a male if the weight is currently 0? It should increase the weight.</p>

<p><strong>Backpropagation</strong> (backward propagation of errors) is an algorithm for supervised learning of ANN using gradient descent. It works by computing the gradient of the cost function with respect to the networkâ€™s parameters, and then using this gradient to update the parameters using gradient descent. It is a generalization of the delta rule for perceptronâ€™s to multilayer feedforward neural networks.</p>

<p>The backpropagation algorithm consists of two main steps:</p>

<h3 id="1-forward-pass">1. Forward pass</h3>

<p>The input is fed through the network, and the output is computed for each layer using the current values of the weights and biases.</p>

<p>It also preserves the intermediate results since they are needed for the backward pass.</p>

<h3 id="2-backward-pass">2. Backward pass</h3>

<p>The gradient of the cost function with respect to the weights and biases of each layer is computed using the previously computed gradients and the output of the layer. Finally, the weights and biases are updated using the computed gradients and gradient descent.</p>

<p>Letâ€™s get to the proof:</p>

<p>Define for each neuron j in layer l the output $o_j^{(l)}$ such that</p>

<p>$o_j^{(l)} = \phi(a_j^{(l)}) = \phi \bigg ( \sum_{k=1}^n w_{kj}^{(l)} o_k^{l-1} \bigg),$</p>

<p>where,</p>

<p>$o_k^{(l-1)}$ neuron output from previous layer</p>

<p>$w_{kj}^{(l)}$ is weight on synapse from k to j (previous layer k neuron to current layer j neuron)</p>

<p>$a_j^{(l)}$ the â€œactivationâ€ of the neuron</p>

<p>bias is omitted</p>

<p>To find how any error function $E$ (usually mean squared error) changes with respect to a weight $w_{ij}^{(l)}$, we apply the chain rule</p>

<p>$\frac {\partial E}{\partial w_{ij}^{(l)}} = \frac {\partial E}{\partial o_j^{(l)}}\frac {\partial o_j^{(l)}}{\partial a_j^{(l)}} \frac {\partial a_j^{(l)}}{\partial w_{ij}^{(l)}}$</p>

<p>Derivation for Gradient of error function w.r.t to parameters:</p>

<p>$\frac {\partial a_j^{(l)}}{\partial w_{ij}^{(l)}} = o_i^{(l-1)}$</p>

<p>For other terms, we can derive the identify by using the chain rule to write</p>

<p>$\delta_j^{(l)} = \frac {\partial E}{\partial o_j^{(l)}}\frac {\partial o_j^{(l)}}{\partial a_j^{(l)}}$</p>

<p>$\qquad = \frac {\partial o_j^{(l)}}{\partial a_j^{(l)}} \bigg ( \frac {\partial E}{\partial o_j^{(l)}} \bigg)$</p>

<p>$\qquad = \phiâ€™ \bigg(a_j^{(l)} \bigg) \sum_m \frac{\partial E}{\partial o_m^{l+1}} \frac{\partial o_m^{l+1}}{\partial a_m^{l+1}} \frac{\partial a_m^{l+1}}{\partial o_j^{l}}$   divide and multiply by $\partial o_m^{l+1}$,  $\partial a_m^{l+1}$</p>

<p>$\qquad = \phiâ€™ \bigg(a_j^{(l)} \bigg) \sum_m \delta_m^{l+1} w_{jm}^l$              neuron j from current layer sends signals to next layer neuron m.</p>

<p>Note that this is our backpropagation formula. This allows us to compute previous layers of $\delta_j$ by later layers recursively â€” this is where backpropagation comes from. We can compute $\delta_j$ directly if $j$ is an output layer, so this process eventually terminates.</p>

<p>If we combine both of our results we can calculate gradient of Error w.r.t parameters:</p>

<p>$\frac {\partial E}{\partial w_{ij}^{(l)}}  = \phiâ€™ \big(a_j^{(l)} \big) \sum_m w_{jm}^{(l)} \delta_m^{(l+1)} \qquad o_i^{(l-1)},$</p>

<p>time complexity: $O(mn) = O(W)$</p>

<p>where m is the number of neurons in this layer and n is the number of neurons in next layer.</p>

<p>w = number of synapses in the network</p>

<p>The algorithm is called backpropagation because the gradient is computed backwards through the network, starting from the output layer and working backwards towards the input layer. This allows the algorithm to efficiently compute the gradient for each parameter in the network versus the naive approach of calculating the gradient of each layer separately, which can be used to update the weights and biases.</p>

<h2 id="vanishing-gradient-problem">Vanishing Gradient Problem</h2>

<p>Backpropagation is a powerful algorithm that has enabled the training of deep neural networks with many layers. However, it can suffer from the vanishing gradient problem, where the gradient becomes very small as it is propagated backwards through the network, making it difficult to update the weights and biases of the early layers in the network.</p>

<h3 id="why-gradient-keep-shrinking">Why Gradient keep shrinking</h3>

<p>The gradient at each layer is the product of the gradients of the subsequent layers multiplied by the gradient of the current layer. If the gradients of the subsequent layers are small, then the gradient of the current layer will also be small, which can make it difficult to update the weights and biases of the early layers in the network. This is known as the vanishing gradient problem.</p>

<p>This happens because of the activation function, because the activation function compresses the entire real numbers into a small range. You multiply few activation results and gradient becomes too small.</p>

<p>Example â†’ Sigmoid always gives output between [0, 1], If we use sigmoid while calculating gradientâ€™s for previous layers. It keep getting smaller.</p>

<p>This problem has been addressed through the use of activation functions such as ReLU and the development of more advanced optimization algorithms such as Adam and RMSProp.</p>

<p>Sometimes, a smooth approximation to this function is used: $f(x)=lnâ¡(1+e^x),$ which is called the <strong>softplus function</strong>.</p>

<p>Thatâ€™s if for this blog, hope this was worth your time. ğŸ¥°</p>

<h2 id="references">References</h2>

<ol>
  <li><a href="www.brilliant.org">Brilliant.org</a></li>
  <li>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Buy here</a></li>
</ol>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[In this blog post, we will understand the underlying algorithm for training neural networks. We will discuss gradient descent, the most basic step of training any model, and backpropagation.]]></summary></entry><entry><title type="html">Programming Languages</title><link href="http://localhost:4000/programming/2024/02/04/Programming_languages.html" rel="alternate" type="text/html" title="Programming Languages" /><published>2024-02-04T15:08:10+05:30</published><updated>2024-02-04T15:08:10+05:30</updated><id>http://localhost:4000/programming/2024/02/04/Programming_languages</id><content type="html" xml:base="http://localhost:4000/programming/2024/02/04/Programming_languages.html"><![CDATA[<p>Programming languages are the tools we use to write software, create web applications, manipulate data, and more. Theyâ€™re fundamental to the world of computing, and thereâ€™s a wide variety to choose from, each with their own strengths and weaknesses.</p>

<p>Letâ€™s start off with some common types of programming languages:</p>

<h2 id="1-procedural-programming-languages">1. Procedural Programming Languages</h2>

<p>This language type is one of the oldest. It revolves around procedures or routines. Theyâ€™re straightforward and efficient, but can be rigid and difficult to manage for larger software projects.</p>

<p>They are great for tasks that can be broken down into a series of sequential steps.</p>

<p>Examples include C and Pascal.</p>

<h3 id="go">Go</h3>

<p>Also known as Golang, Go is a statically-typed compiled language that was developed at Google. Itâ€™s known for its simplicity and efficiency. Itâ€™s particularly good for system-level programming, and itâ€™s also used in web development. It has a garbage collector, which makes memory management easier. However, itâ€™s less flexible than some other languages, due to its emphasis on simplicity.</p>

<p>It is primarily a procedural language, but it does offer some support for object-oriented programming.</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">package</span> <span class="n">main</span>

<span class="k">import</span> <span class="s">"fmt"</span>

<span class="k">func</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">fmt</span><span class="o">.</span><span class="n">Println</span><span class="p">(</span><span class="s">"Hello, world!"</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="2-object-oriented-programming-languages">2. Object-Oriented Programming Languages</h2>

<p>These languages organize code into â€˜objectsâ€™ that contain both data and the functions that operate on that data. Theyâ€™re great for larger projects and promote reusability, but can be overkill for smaller tasks.</p>

<p>Java and Python are examples.</p>

<p>Now, letâ€™s go in further details of some programming languages:</p>

<h3 id="java">Java</h3>

<p>Itâ€™s a general-purpose language known for its â€˜write once, run anywhereâ€™ philosophy. Itâ€™s widely used for building enterprise-scale applications. However, it requires a lot of memory and its syntax can be complex for beginners.
Other features â†’ memory safe, garbage collection</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">HelloWorld</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">printHello</span><span class="o">()</span> <span class="o">{</span>  
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Hello, world!"</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">HelloWorld</span> <span class="n">helloWorld</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">HelloWorld</span><span class="o">();</span>
        <span class="n">helloWorld</span><span class="o">.</span><span class="na">printHello</span><span class="o">();</span>
    <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div>

<h2 id="3-functional-programming-languages">3. Functional Programming Languages</h2>

<p>These languages treat computation as the evaluation of mathematical functions and avoid changing-state and mutable data. Theyâ€™re excellent for parallel processing and have no side effects, but their paradigm can be difficult to grasp for newcomers.</p>

<p>They excel at tasks that can be broken down into independent units that can be executed in any order because they donâ€™t depend on the state of the program.</p>

<p>Examples include Haskell and Lisp.</p>

<h3 id="haskell-functional">Haskell (Functional)</h3>

<p>Haskell is a statically typed, purely functional programming language with type inference and lazy evaluation. Itâ€™s used in fields where high-level, declarative code is beneficial, such as data analysis and symbolic computation. Due to its purity, code written in Haskell can be easy to test and reason about.</p>

<div class="language-haskell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">factorial</span> <span class="o">::</span> <span class="kt">Integer</span> <span class="o">-&gt;</span> <span class="kt">Integer</span>
<span class="n">factorial</span> <span class="mi">0</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">factorial</span> <span class="n">n</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">factorial</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">main</span> <span class="o">::</span> <span class="kt">IO</span> <span class="nb">()</span>
<span class="n">main</span> <span class="o">=</span> <span class="n">print</span> <span class="p">(</span><span class="n">factorial</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1">-- Outputs: 120</span>
</code></pre></div></div>

<h2 id="4-multi-paradigm-programming-languages">4. Multi-paradigm Programming Languages</h2>

<p>These languages support more than one programming paradigm, offering greater flexibility to developers. They can support procedural, object-oriented, functional programming, and others, depending on the language. They provide a lot of flexibility, but can also be more complex to learn and use because of the multiple paradigms.</p>

<p>Examples include JavaScript and C++.</p>

<p>Some examples are:</p>

<h3 id="javascript-procedural--object-oriented">JavaScript (procedural + object-oriented)</h3>

<p>Itâ€™s the language of the web, used for creating interactive web pages. Itâ€™s flexible and runs directly in the browser. But, it may have security issues and can be inconsistent across different browsers.</p>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">function</span> <span class="nf">greet</span><span class="p">(</span><span class="nx">name</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="dl">"</span><span class="s2">Hello, </span><span class="dl">"</span> <span class="o">+</span> <span class="nx">name</span> <span class="o">+</span> <span class="dl">"</span><span class="s2">!</span><span class="dl">"</span><span class="p">;</span>
<span class="p">}</span>

<span class="kd">var</span> <span class="nx">message</span> <span class="o">=</span> <span class="nf">greet</span><span class="p">(</span><span class="dl">"</span><span class="s2">world</span><span class="dl">"</span><span class="p">);</span>

<span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="nx">message</span><span class="p">);</span>
</code></pre></div></div>

<h3 id="c-procedural--object-oriented">C++ (procedural + object-oriented)</h3>

<p>Itâ€™s a powerful language used for system/software development and game programming. Itâ€™s fast and flexible. However, it has a steep learning curve and managing memory can be tricky.</p>

<h3 id="python">Python</h3>

<p>Itâ€™s a high-level, interpreted language known for its readability. Itâ€™s great for beginners and widely used in scientific computing, data analysis, and AI. However, itâ€™s slower than some other languages and not ideal for mobile app development.
Other features â†’ Memory safe, garbage collection</p>

<p>Each of these languages has its own use cases, advantages, and disadvantages. The key is to choose the right tool for the job at hand.</p>

<h2 id="memory-safe-languages">Memory safe Languages</h2>

<p>Memory-safe languages are programming languages that include preventive measures to avoid common memory-related errors, such as buffer overflow and null pointer dereferencing. These languages can either prevent such errors at compile-time or runtime.</p>

<p>Examples include Java, Python, Rust, Swift, Go, JavaScript, Ruby, C#, TypeScript and Kotlin</p>

<h4 id="buffer-overflow">Buffer Overflow</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">arr</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">arr</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>  <span class="c1"># This is fine in Python. The array resizes automatically.
</span><span class="nf">print</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>

</code></pre></div></div>

<p>In this code, Python automatically resizes the array as new elements are added, preventing a buffer overflow from occurring.</p>

<h4 id="null-pointer-dereferencing">Null Pointer Dereferencing</h4>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Main</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">String</span> <span class="n">str</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">str</span><span class="o">.</span><span class="na">length</span><span class="o">());</span>  <span class="c1">// This will throw a NullPointerException</span>
    <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div>

<p>In this code, <code class="language-plaintext highlighter-rouge">str</code> is null, so trying to call <code class="language-plaintext highlighter-rouge">str.length()</code> will throw a NullPointerException, preventing the program from continuing to run with invalid data.</p>

<h3 id="garbage-collection">Garbage collection</h3>

<hr />

<p>Garbage collection is a form of automatic memory management. Programming languages with garbage collection automatically reclaim memory that the programmer has allocated but is no longer in use. This process helps to eliminate common programming bugs related to memory management, such as memory leaks and dangling pointers (points to invalid memory).</p>

<p>For example, in Java, you do not need to manually deallocate memory once youâ€™re done using an object. The Java Virtual Machine (JVM) has a garbage collector that automatically frees up memory that is no longer needed. This greatly simplifies programming and reduces the chance of memory leaks.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Main</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// Creating a new object</span>
        <span class="nc">String</span> <span class="n">str</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">String</span><span class="o">(</span><span class="s">"Hello, world!"</span><span class="o">);</span>

        <span class="c1">// The object is now eligible for garbage collection because it's no longer reachable</span>
        <span class="n">str</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Another language that uses garbage collection is Python. Like Java, Python automatically manages memory, meaning that objects are automatically destroyed once they are no longer in use.</p>

<p>Here is an example of garbage collection in Python:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyClass</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="k">def</span> <span class="nf">__del__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="s"> has been deleted and is ready for garbage collection</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Create an object
</span><span class="n">my_obj</span> <span class="o">=</span> <span class="nc">MyClass</span><span class="p">(</span><span class="sh">"</span><span class="s">Object 1</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Now, let's delete this object
</span><span class="k">del</span> <span class="n">my_obj</span>

<span class="c1"># Since the object has been deleted, it's now eligible for garbage collection
</span>
</code></pre></div></div>

<p>When the <code class="language-plaintext highlighter-rouge">del</code> keyword is used, it removes a reference to the object.</p>

<p>However, itâ€™s important to note that an object can also become eligible for garbage collection without the <code class="language-plaintext highlighter-rouge">del</code> keyword, as long as there are no more references to it.</p>

<p>However, itâ€™s important to note that while garbage collection can make programming easier, it doesnâ€™t completely prevent memory-related bugs. For instance, if an object is mistakenly kept alive when itâ€™s not needed, this can still lead to memory leaks. Therefore, understanding how garbage collection works in your programming language of choice is still crucial.</p>

<p>Examples of programming languages that use garbage collection include â†’ Java, Python, JavaScript, C#, Ruby, Go and Kotlin.</p>

<h2 id="interpreted-vs-compile-time-language">Interpreted vs compile time language</h2>

<p>Interpreted and compiled languages represent two different ways of translating human-readable source code into machine code that a computer can execute.</p>

<h3 id="interpreted-languages">Interpreted Languages</h3>

<p>In an interpreted language, the source code is not directly translated into machine code. Either, an interpreter reads the source code line-by-line, and executes each command. (such as PHP or Ruby)</p>

<p>Or, the source code is first translated into this intermediate form like bytecode (such as Python, Java, and C#), which allows for platform independence as the same bytecode can be interpreted on different machines. This bytecode is then interpreted (e.g. Python) or compiled at runtime using JIT (it is an optimization, that makes it hybrid with compiled languages) (e.g. Java and C#).</p>

<p>Note, machine code is not executed line by line but as a whole. This allows for certain optimizations that can make the code run faster.</p>

<p><img src="/assets/2024/September/interpreted.png" alt="Untitled" /></p>

<p>Interpreted languages are generally more flexible, and they can even modify themselves during runtime.  However, they also tend to run slower than compiled languages, as the interpretation process takes time.</p>

<p>Examples of interpreted languages include Python, Ruby, and PHP.</p>

<h3 id="compiled-languages">Compiled Languages</h3>

<p>In a compiled language, the source code is directly translated into machine code by a compiler before itâ€™s run. This means that compiled programs generally run faster than interpreted ones, as all the translation work is done beforehand.</p>

<p>However, they are less flexible than interpreted languages, as the source code cannot be changed during runtime.</p>

<p>Examples of compiled languages include C, C++, and Go.</p>

<p><img src="/assets/2024/September/compiled.png" alt="Untitled" /></p>

<h3 id="jit-compilation">JIT compilation</h3>

<p>Just-In-Time (JIT) compilation is a method of execution where a program is compiled into machine code just before it is run, rather than ahead of time as with traditional compilation.</p>

<p>JIT compilation is used in several programming languages, most notably Java and JavaScript, but also in Python, Ruby, and .NET languages such as C#.</p>

<p>Java and C# are often described as a hybrid of compiled and interpreted languages, due to their two-step process. First, source code is compiled into an intermediate form (bytecode for Java, and Intermediate Language for C#), and then this intermediate form is further compiled to machine code at runtime by a Just-In-Time (JIT) compiler.</p>

<p><img src="/assets/2024/September/flowchart.png" alt="Fig: Flowchart from high level language to Output (Just my understanding) " /></p>

<p>*Fig: Flowchart from high level language to Output (Just my understanding) *</p>

<p>The main advantage of JIT compilation is that it can optimize the program for the machineâ€™s current state, taking into account factors such as the data being processed and the machineâ€™s architecture. This can result in more efficient execution than with traditionally compiled code.</p>

<p>However, JIT compilation also has some disadvantages. The compilation process can lead to an initial delay in execution, known as a â€œwarm-upâ€ period.</p>

<p>Additionally, JIT compilers are complex pieces of software that can introduce their own bugs and security vulnerabilities.</p>

<h2 id="statically-vs-dynamically-typed-languages">Statically vs Dynamically Typed languages</h2>

<h3 id="statically-typed-languages">Statically Typed Languages</h3>

<p>In statically typed languages, the variable type is checked at compile-time. This means that you must declare the data type of the variable when you define it, and once set, the variable type canâ€™t be changed. This approach can help catch errors early in the development process. Statically typed languages include Java, C, C++, Go, Rust, and Swift.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">num</span> <span class="o">=</span> <span class="mi">10</span><span class="o">;</span> <span class="c1">// Declare an integer variable</span>
<span class="n">num</span> <span class="o">=</span> <span class="s">"Hello"</span><span class="o">;</span> <span class="c1">// Error: incompatible types</span>
</code></pre></div></div>

<p>In the above Java code, an error would be thrown at compile time because you cannot assign a string to an integer variable.</p>

<h3 id="dynamically-typed-languages">Dynamically Typed Languages</h3>

<p>The counterpart to statically typed languages are dynamically typed languages. In these languages, the type is checked at runtime, which means that you can declare a variable without specifying its type, and its type can be changed later in the program. While this provides more flexibility, it can also lead to errors that are only discovered when the code is run. Dynamically typed languages include Python, Ruby, PHP, and JavaScript.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># num is an integer
</span><span class="n">num</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Hello</span><span class="sh">"</span>  <span class="c1"># num is now a string
</span></code></pre></div></div>

<p>In the above Python code, the <code class="language-plaintext highlighter-rouge">num</code> variable can be reassigned to a string without any errors, because the type check happens at runtime.</p>

<p>Itâ€™s worth noting that some languages, like Python, are also capable of type hinting. This is a feature that allows developers to specify the expected type of a variable or function return, improving code readability and allowing for better IDE support and error checking, even though the language itself is dynamically typed.</p>

<p>Thatâ€™s it for this blog. ğŸ¦„ğŸ¦„ I hope this helps you to better understand your favorite programming language. If you find any mistake or have any doubt feel free to contact!</p>]]></content><author><name></name></author><category term="Programming" /><summary type="html"><![CDATA[Programming languages are the tools we use to write software, create web applications, manipulate data, and more. Theyâ€™re fundamental to the world of computing, and thereâ€™s a wide variety to choose from, each with their own strengths and weaknesses.]]></summary></entry><entry><title type="html">How to do clustering</title><link href="http://localhost:4000/ai/2024/01/20/How_to_do_clustering.html" rel="alternate" type="text/html" title="How to do clustering" /><published>2024-01-20T15:08:10+05:30</published><updated>2024-01-20T15:08:10+05:30</updated><id>http://localhost:4000/ai/2024/01/20/How_to_do_clustering</id><content type="html" xml:base="http://localhost:4000/ai/2024/01/20/How_to_do_clustering.html"><![CDATA[<h1 id="clustering">Clustering</h1>

<p>Clustering is a type of unsupervised learning that involves grouping similar inputs into clusters or categories.</p>

<p>This technique can be used to identify patterns or relationships in data that may not be immediately apparent. There are many algorithms that can be used for clustering, including k-means, hierarchical clustering, and DBSCAN. The choice of clustering algorithm depends on the specific problem and the characteristics of the data.</p>

<p>Hard clustering â†’ Assigning each instance to a single cluster.</p>

<p>Soft clustering â†’ Assigning each instance a score per cluster, it can be a similarity score (or affinity).</p>

<h2 id="types-of-clustering">Types of Clustering</h2>

<p>There are several types of clustering algorithms, including:</p>

<h3 id="centroid-based-clustering">Centroid-based clustering</h3>

<p>Centroid-based clustering is a type of clustering method in which the position of a cluster is represented by the central point of its objects.</p>

<p>A popular example of centroid-based clustering is the k-means algorithm. Centroid-based algorithms are efficient but sensitive to initial conditions and outliers.</p>

<p><img src="https://developers.google.com/static/machine-learning/clustering/images/CentroidBasedClustering.svg" alt="Fig: Centroid based clustering" /></p>

<p><em>Fig: Centroid based clustering</em></p>

<p>Letâ€™s learn about K-means clustering, an example of centroid-based clustering.</p>
<h3 id="k-means">K-Means</h3>

<p>The model learns to group inputs into k clusters based on similarity. It is a straightforward and efficient algorithm for data segmentation and pattern recognition.</p>

<p>The main objective of k-means clustering is to partition the data into â€˜kâ€™ clusters, where â€˜kâ€™ is a user-defined parameter representing the number of clusters desired.</p>

<p>Hereâ€™s how the k-means clustering algorithm works:</p>

<ol>
  <li><strong>Initialization</strong>: Choose â€˜kâ€™ initial centroids (cluster centers) randomly from the data points. These centroids represent the initial cluster centers.</li>
  <li><strong>Assignment</strong>: Assign each data point to the nearest centroid. This step is based on the distance metric, commonly the Euclidean distance, but other distance measures can also be used.</li>
  <li><strong>Update Centroids</strong>: Calculate the mean of all the data points assigned to each centroid. Move the centroid to the mean position. This step aims to find the new cluster centers.</li>
  <li><strong>Repeat Assignment and Update</strong>: Repeatedly assign data points to the nearest centroid and update the centroids until convergence or until a maximum number of iterations is reached.</li>
  <li><strong>Convergence</strong>: The algorithm converges when the centroids no longer change significantly between iterations or when a predefined convergence criterion is met.</li>
  <li><strong>Result</strong>: After convergence, each data point will be assigned to one of the â€˜kâ€™ clusters based on the final positions of the centroids.</li>
</ol>

<p>When sets of circles from competing centroids overlap they form a line. The result is whatâ€™s called a <strong>Voronoi tessellation</strong>.</p>

<p><img src="https://storage.googleapis.com/kaggle-media/learn/images/KSoLd3o.jpg" alt="Fig: K-means clustering creates a Voronoi tessallation of the feature space." /></p>

<p>Fig: K-means clustering creates a Voronoi tessallation of the feature space.</p>

<p>Choosing the appropriate value of â€˜kâ€™ is critical in k-means clustering. The number of clusters should be determined based on domain knowledge or through techniques like the elbow method, silhouette score, or other clustering evaluation metrics.</p>

<p>K-means clustering is widely used in various applications, such as customer segmentation, image compression, anomaly detection, and data preprocessing for other machine learning tasks.</p>

<p>It is important to note that k-means is sensitive to the initial random centroid selection, and it may converge to a suboptimal solution depending on the initial positions of the centroids.</p>

<p><img src="/assets/2024/September/suboptimal%20solutions.png" alt="Fig: Suboptimal solutions due to unlucky centroid initializations" /></p>

<p><em>Fig: Suboptimal solutions due to unlucky centroid initializations</em></p>

<p>To mitigate this issue, it is common to run the algorithm multiple times with different initializations and choose the best result based on a chosen evaluation metric.</p>

<h4 id="disadvantages-of-k-means-algorithm">Disadvantages of K-means algorithm:</h4>

<ul>
  <li>Need to run K-means few times, before finding global optimal solution.</li>
  <li>Need to specify number of clusters.</li>
  <li>K-means does not behave very well when the clusters have varying sizes, different densities, or non-spherical shapes.</li>
</ul>

<p>Letâ€™s demonstrate the K-means clustering using a real-world dataset. Here, weâ€™ll use the popular <code class="language-plaintext highlighter-rouge">Iris</code> dataset available in the <code class="language-plaintext highlighter-rouge">sklearn</code> datasets module. This dataset includes measurements of 150 iris flowers from three different species.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Load the iris dataset
</span><span class="n">iris</span> <span class="o">=</span> <span class="nf">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span>

<span class="c1"># Apply K-means clustering
</span><span class="n">kmeans</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># n_init tells how many random initializations to do (times the whole process is repeated)
</span><span class="n">kmeans</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span>

<span class="c1"># labels
</span><span class="sh">"""</span><span class="s">
array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2,
       2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2,
       2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0], dtype=int32)
</span><span class="sh">"""</span>

<span class="c1"># Plot the clusters (plot using any 2 attributes, your wish)
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">kmeans</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Some other functions
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">kmeans</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># score for each cluster
</span></code></pre></div></div>

<p><img src="https://www.kaggleusercontent.com/kf/158886682/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..PCQzfyplvHilkSHDdYpjew.S3D9I--L2F0_KlZBRlvAkZPFDXrYGZNfA3IcbtkIUUUPTNth3ZeUka7FOqQqPW4Z-hNChF0fyxZ-qQaoeIqequH6AyA9Ad2KIIqFUsJTQXuIdnnrYadSQjF19vrMpVXZct2M1MUBOzX_obMwyA8dU2yXV6vgk3_YbOCu-lf02MHWw8t25Tizqh5hbUmdsm2PoTFPgkn_M2R54xanJFb8upKBC7JOF6k7MBS0Dhzo-kXhku7fNLFKDLJhOZTEJcCD46JIFj0BlteTf_bGB6ijfz2rFo-ub7yJEvgHDSKZyzgKc0eMihW6k_iMf2WSKoidCZao7Jj4DcIEGlZy7-BMWMDk5Eus9qmODrd63UB1xVI4ZjJ25W9itFlO_8kI67yv4xSWN8fIRqhtOo4bvLKySNQOYA1bE9WNFXeX_1Ug9mqqr5-K5f8xGtC5rkzQs-KnuDRhtYdcmzot_U2s-QHs96hJkC53FHwqdKf453pGvMnJCobbh4ZF9Z_DKa7R0t_vXaZVx0RAZMLcJDaGZ5XnYZXb7MdUd9NJbTQEpGI849jUwiIhK9oav7dP7w02w7UsSRUdJKzJlQEA3HFDN_4d53hM1FULpc1RgZufrSEvQEfo08Dam398PRhtyq98NhjAkL6Roe25uoAAhyfi2NndN3G5a3P4YtoBInrpIwzG1iI.ajnu3QmYOLkOgnndJwPAXw/__results___files/__results___6_0.png" alt="Fig: Dataset is divided into 3 clusters" /></p>

<p>In this code, <code class="language-plaintext highlighter-rouge">iris.data</code> is a 150x4 matrix where each row is a flower sample and each column is a feature (sepal length, sepal width, petal length, petal width). The K-means algorithm groups the flowers into 3 clusters based on these features. The final line plots the clusters, with the cluster centers marked in red.</p>

<h3 id="density-based-clustering">Density-based clustering</h3>

<p>Density-based clustering connects areas of high example density into clusters. This method can form clusters of any shape as long as dense areas are connected. However, it struggles with data that has different densities and many dimensions. Also, these algorithms intentionally do not include outliers in any clusters.</p>

<p><img src="https://developers.google.com/static/machine-learning/clustering/images/DensityClustering.svg" alt="Fig: Density based clustering" /></p>

<p><em>Fig: Density based clustering</em></p>

<ul>
  <li><strong>DBSCAN Clustering</strong>: the model learns to group inputs into clusters based on density, with high-density regions representing clusters and low-density regions representing noise.</li>
  <li><strong>Mean Shift Clustering:</strong> the model learns to identify and group inputs based on local density maxima.</li>
</ul>

<h3 id="distribution-based-clustering">Distribution-based clustering</h3>

<p>This clustering approach assumes data is composed of distributions, such as <a href="https://wikipedia.org/wiki/Normal_distribution"><strong>Gaussian distributions</strong></a>. As distance from the distributionâ€™s center increases, the probability that a point belongs to the distribution decreases.</p>

<p><img src="https://developers.google.com/static/machine-learning/clustering/images/DistributionClustering.svg" alt="Fig: Distribution-based clustering" /></p>

<p>Fig: Distribution-based clustering</p>

<p>A common example of distribution-based clustering is the Gaussian Mixture Model (GMM).</p>

<h3 id="hierarchical-clustering">Hierarchical clustering</h3>

<p>The model learns to group inputs into a hierarchy of clusters, with larger clusters containing smaller clusters.</p>

<p><img src="https://developers.google.com/static/machine-learning/clustering/images/HierarchicalClustering.svg" alt="Fig: Hierarchical clustering" /></p>

<p>Fig: Hierarchical clustering</p>

<ul>
  <li>Agglomerative clustering</li>
  <li>BIRCH (scale well to large dataset)</li>
</ul>

<p>Each type of clustering algorithm is suited for different types of data and problems, and choosing the right type of clustering is an important part of building an accurate machine learning model.</p>

<h2 id="applications-of-clustering">Applications of Clustering:</h2>

<ul>
  <li>Data analysis</li>
  <li>Customer segmentation</li>
  <li>recommender systems</li>
  <li>Dimensionality reduction</li>
  <li>Anomaly detection (outlier detection)</li>
  <li>Search engines</li>
  <li>image segmentation</li>
  <li>Semi-supervised learning</li>
</ul>

<h2 id="creating-a-similarity-matrix">Creating a Similarity Matrix</h2>

<p>A similarity matrix is a matrix where each element ij represents the similarity between the ith and jth elements of the dataset. A common method of calculating similarity is by using the Euclidean distance.</p>

<p>In the context of clustering, we use a similarity matrix to find the similarity between any element and itâ€™s corresponding centroid.</p>

<p>There are 2 types of similarity measures: â€“</p>

<ol>
  <li>
    <p><strong>Supervised similarity</strong> measure refers to the use of a supervised machine learning model to calculate how similar two items are. This model is trained on data that includes the correct answer, which it uses to learn how to predict the similarity of new items.</p>
  </li>
  <li>
    <p><strong>Manual similarity</strong> measure means calculating the similarity between two items using a predefined formula or method, without the use of a machine learning model. This approach is often used when itâ€™s straightforward to calculate similarity, such as measuring the distance between two points in a space.</p>
  </li>
</ol>

<p>Here is a sample Python code for creating a similarity matrix:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">cdist</span>

<span class="c1"># Calculate Euclidean distance between each sample and each cluster centroid
</span><span class="n">dist_matrix</span> <span class="o">=</span> <span class="nf">cdist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">)</span>

<span class="c1"># Create similarity matrix
</span><span class="n">similarity_matrix</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">dist_matrix</span>

<span class="c1"># Print the similarity matrix
</span><span class="nf">print</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">)</span>

<span class="sh">"""</span><span class="s">
Output
array([[ 0.29246175,  7.074606  ,  0.19764636],
       [ 0.29424103,  2.23394674,  0.19550559],
       [ 0.28016253,  2.3974543 ,  0.18941707],
       [ 0.29219179,  1.90353644,  0.1940395 ],
       [ 0.28841184,  5.30147879,  0.19591195],
       [ 0.31779005,  1.4770227 ,  0.2136073 ],
</span><span class="sh">"""</span>
</code></pre></div></div>

<p>Each row in the similarity matrix corresponds to a sample, and each column corresponds to a cluster centroid. The higher the value in the similarity matrix, the closer the sample is to the corresponding cluster centroid.</p>

<h2 id="interpret-results">Interpret results</h2>

<p>The results of K-means clustering can be visualized using a scatter plot, as shown above. Each cluster is represented by a different colour, and the cluster centres are marked in red.</p>

<p>The results can also be evaluated quantitatively using various metrics such as inertia (sum of squared distances of samples to their closest cluster centre) and silhouette score (a measure of how close each sample in one cluster is to the samples in the neighbouring clusters).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Calculate silhouette score
</span><span class="n">sil_score</span> <span class="o">=</span> <span class="nf">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># Print silhouette score
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Silhouette Score: </span><span class="sh">'</span><span class="p">,</span> <span class="n">sil_score</span><span class="p">)</span>

<span class="c1"># Print inertia
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Inertia: </span><span class="sh">'</span><span class="p">,</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># Inertia:  78.85144142614601
# Silhouette Score:  0.5528190123564095
</span></code></pre></div></div>

<p>In this code, <code class="language-plaintext highlighter-rouge">kmeans.inertia_ returns</code> the inertia of the KMeans clustering. A lower inertia means a better model.
In this code, silhouette_score(X, labels) calculates the silhouette score of the clustering result. A higher silhouette score indicates that the samples are well clustered.</p>

<p>Thatâ€™s it for this blog. I hope you learned something useful about clustering â¤ï¸â¤ï¸.</p>

<h3 id="references">References</h3>

<p><a href="https://developers.google.com/machine-learning/clustering">Google Developers</a></p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Clustering]]></summary></entry><entry><title type="html">Just machine learning</title><link href="http://localhost:4000/ai/2023/10/29/Just_machine_learning.html" rel="alternate" type="text/html" title="Just machine learning" /><published>2023-10-29T15:08:10+05:30</published><updated>2023-10-29T15:08:10+05:30</updated><id>http://localhost:4000/ai/2023/10/29/Just_machine_learning</id><content type="html" xml:base="http://localhost:4000/ai/2023/10/29/Just_machine_learning.html"><![CDATA[<p>In this blog post, weâ€™re going to talk about machine learning and its different types.</p>

<p>Artificial intelligence (AI) refers to machines that are programmed to learn and perform tasks that usually require human thinking, like recognizing images, understanding speech, making decisions, and translating languages.</p>

<p>Machine learning is a branch of AI that allows computers to learn and make predictions or decisions based on data. It uses algorithms and statistical models to analyze data, find patterns, and make predictions on new data.</p>

<h1 id="supervised-learning">Supervised Learning</h1>

<p>Supervised learning is a machine learning technique where a model is trained on labeled data. The model is presented with inputs and corresponding outputs, and it learns to make predictions based on those inputs.</p>

<p>This technique is used for tasks such as classification, regression, and prediction.</p>

<p>Some common types of supervised learning include:</p>

<ul>
  <li><strong>Classification:</strong> the model learns to classify inputs into different categories or classes.</li>
  <li><strong>Regression:</strong> the model learns to predict a continuous output based on the input.</li>
  <li><strong>Time Series Prediction:</strong> the model learns to make predictions based on time series data.</li>
  <li><strong>Anomaly Detection:</strong> the model learns to identify unusual or unexpected data points.</li>
</ul>

<h2 id="classification">Classification</h2>

<p>Classification is a type of supervised learning in machine learning where the model learns to put inputs into different categories or classes.</p>

<p>Examples â†’ Image recognition, sentiment analysis, and speech recognition.</p>

<p>There are a bunch of algorithms that can be used for classification, including decision trees, random forests, and support vector machines (SVMs).</p>

<p>The choice of algorithm depends on the specific problem and the characteristics of the data. For example, decision trees are great for problems with just a few features, while SVMs are awesome when there are lots of features and the data isnâ€™t linearly separable.</p>

<p>There are many algorithms that can be used for classification, including:</p>

<ul>
  <li>Decision trees</li>
  <li>Random forests (Ensemble method)</li>
  <li>Support vector machines (SVMs)</li>
  <li>Nearest neighbor</li>
  <li>K-nearest neighbors (KNN)</li>
  <li>Naive Bayes</li>
</ul>

<p>Letâ€™s Discuss some of these techniques:</p>

<h3 id="decision-trees">Decision Trees</h3>

<p>Decision trees are a type of classification algorithm used in machine learning. They are especially handy for problems with just a few features and a ton of training examples.</p>

<p>The basic idea behind decision trees is to split up the input space into different regions, where each region represents a different class or category. This is done by recursively splitting up the input space over and over again based on the values of the input features.</p>

<p><img src="https://static.javatpoint.com/tutorial/machine-learning/images/decision-tree-classification-algorithm.png" alt="Fig: Decision Tree" /></p>

<p><em>Fig: Decision Tree <a href="www.javatpoint.com">javatpoint</a></em></p>

<p>At each level of the tree, the algorithm picks the input feature that separates the training examples into different classes the best. This feature is used to make a decision node, which splits the input space into two or more regions. The process is repeated on each of the resulting regions until a stopping criterion is met, like reaching the maximum depth or having a minimum number of examples in each region.</p>

<p>Decision trees are super easy to understand and interpret, and they can be used for both classifying and regression problems. They can also handle non-linear relationships between the input features and the target variable.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="n">score</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p>Decision trees can also be used for regression problems, where the goal is to predict a continuous output variable based on the input features. The decision tree algorithm works in the same way as for classification problems, but instead of predicting a class label, it predicts a numeric value.</p>

<p>Here is an example of a decision tree for a regression problem:</p>

<h4 id="regression-decision-tree">Regression Decision Tree</h4>

<p><img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_tree_regression_001.png" alt="Fig: Regression Decision Tree" /></p>

<p><em>Fig: Regression Decision Tree <a href="scikit-learn.org">scikit-learn</a></em></p>

<p>In this example, the decision tree is used to fit a sine curve as a result it learns linear regression approximating the sine curve. We can see in this example, that if max depth of the tree is set to high, it can overfit the training data by learning the noise observations also.</p>

<p>The algorithm chooses the feature that results in the best split of the data based on a measure of the variance reduction. The prediction for each leaf node is the average of the target values of the training examples that fall within that leaf node.</p>

<p>However, decision trees can be sensitive to small changes in the input data and may overfit the training data if not properly regularized. To address these issues, ensemble methods such as random forests and gradient boosting are often used.</p>

<p>Overall, decision trees are a simple and effective technique for classification and regression problems, particularly when the decision boundary is simple or linear.</p>

<h4 id="nearest-neighbor-classification">Nearest-neighbor classification</h4>

<p>In this algorithm, the model given an input chooses the class of the nearest data point to that point.</p>

<p>This technique is useful for problems where the decision boundary between classes is complex or nonlinear. However, it can be computationally expensive and may not perform well on high-dimensional data.</p>

<h4 id="k-nearest-neighbor-classification-knn">K-Nearest Neighbor Classification (KNN)</h4>

<p>In this algorithm, the model assigns a class to a new data point based on the classes of the k nearest data points in the training data set. The value of k is a hyperparameter that can be tuned to optimize the modelâ€™s performance.</p>

<p>This technique is often used for problems with a small number of classes and a large number of features. However, it can be sensitive to the choice of distance metric used to calculate the distance between data points.</p>

<p><img src="/assets/2024/October/0_ItVKiyx2F3ZU8zV5.png" alt="Fig: KNN Example" /></p>

<p><em>Fig: KNN Example <a href="medium.com">medium</a></em></p>

<p>Overall, k-nearest neighbor classification is a simple and effective technique for classification problems, particularly when the decision boundary is complex or nonlinear.</p>

<h3 id="regression">Regression</h3>

<p>Regression is a type of supervised learning in machine learning. It involves the use of algorithms and statistical models to predict a continuous output based on input data.</p>

<p>This is useful when trying to predict a value that falls within a range, such as the price of a house based on its size, location, and other factors.</p>

<p>Example â†’ f(size, location, architecture) = price
                   f(1200, Delhi, 2 story building) = 1 million</p>

<h3 id="types-of-regression">Types of Regression</h3>

<p>There are several types of regression, including:</p>

<ul>
  <li>
    <p><strong>Linear Regression:</strong> the model learns to predict a continuous output based on a linear relationship between the input and output variables.</p>

    <p><img src="https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-in-machine-learning.png" alt="Linar regression" /></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># using skitit learn
</span>  <span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Linear</span> <span class="n">Regression</span>
    
  <span class="n">model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    
  <span class="c1"># Print coefficients and accuracy
</span>  <span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
    
  <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Logistic Regression:</strong> the model learns to predict a binary output based on the input variables.</li>
  <li><strong>Polynomial Regression:</strong> the model learns to predict a continuous output based on a polynomial relationship between the input and output variables.</li>
  <li><strong>Ridge Regression:</strong> a regularization technique used to prevent overfitting in linear regression models.</li>
  <li><strong>Lasso Regression:</strong> a regularization technique used to prevent overfitting in linear regression models, but with a different approach than Ridge Regression.</li>
  <li><strong>Elastic Net Regression:</strong> a combination of Ridge and Lasso Regression, which balances their strengths and weaknesses.</li>
</ul>

<p>Each type of regression is suited for different types of data and problems, and choosing the right type of regression is an important part of building an accurate machine learning model.</p>

<h4 id="logistic-regression">Logistic Regression</h4>

<p>Logistic regression is a type of supervised learning in machine learning that is used for binary classification tasks. In this technique, the model learns to predict a binary output (0 or 1) based on the input variables.</p>

<p>It is commonly used in applications such as fraud detection, spam filtering, and medical diagnosis.</p>

<p>The logistic regression algorithm uses a sigmoid function to map the input values to a range between 0 and 1 (generate probabilities), which represents the probability of the input data belonging to one of the two categories. The algorithm then makes a binary decision based on this probability.</p>

<p><img src="https://static.javatpoint.com/tutorial/machine-learning/images/logistic-regression-in-machine-learning.png" alt="Logistic Regression" /></p>

<p><em>Fig: Logistic regression <a href="javatpoint.com">javatpoint</a></em></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Logistic Regression
</span><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">Y_test</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="ridge-regression">Ridge Regression</h4>

<p>Ridge regression is a type of linear regression that adds a regularization term (L2) to the cost function to prevent overfitting. The cost function for ridge regression is:</p>

<p>The Ridge Regression Equation is given by:</p>

<p>$J(w) = \sum_{i=1}^{m} [y^{(i)} - \hat{y}^{(i)}]^2 + \alpha\sum_{j=1}^{n} w_j^2$</p>

<p>where:</p>

<ul>
  <li>J(w) is the cost function</li>
  <li>m is the number of training examples</li>
  <li>n is the number of features</li>
  <li>y is the target variable</li>
  <li>w is the vector of coefficients</li>
  <li>Î± is the regularization parameter</li>
</ul>

<p>The first term in the equation is the mean squared error (MSE) between the predicted values and the true values. The second term is the L2 regularization term, which penalizes the magnitude of the coefficients.</p>

<h4 id="lasso-regression">Lasso Regression</h4>

<p>Lasso regression is another type of linear regression that adds a regularization term (L1) to the cost function. The cost function for lasso regression is:</p>

<p>$J(w) = \sum_{i=1}^{m} [y^{(i)} - \hat{y}^{(i)}]^2 + \alpha\sum_{j=1}^{n} \lvert w_j \rvert$</p>

<p>Where:</p>

<ul>
  <li>$J(w)$ is the cost function</li>
  <li>$m$ is the number of training examples</li>
  <li>$n$ is the number of features</li>
  <li>$y$ is the target variable</li>
  <li>$w$ is the vector of coefficients</li>
  <li>$\alpha$ is the regularization parameter (hyperparameter)</li>
</ul>

<p>The first term in the equation is the mean squared error (MSE) between the predicted values and the true values. The second term is the L1 regularization term, which penalizes the absolute value of the coefficients.</p>

<p>Lasso regression is useful for feature selection, as it tends to set the coefficients of less important features to zero. This can lead to a more interpretable model and improve its generalization performance.</p>

<h1 id="unsupervised-learning">Unsupervised Learning</h1>

<p>Unsupervised learning is a type of machine learning where the model is trained on unlabeled data. The model is not given any specific outputs to learn from, but instead must identify patterns and relationships in the input data on its own.</p>

<p>This technique is used for tasks such as clustering, anomaly detection, and dimensionality reduction.</p>

<p>Some common types of unsupervised learning include:</p>

<ul>
  <li>
    <p><strong>Clustering:</strong> the model learns to group similar inputs into clusters or categories.</p>

    <p><a href="https://ds-meena.github.io/ai/2024/01/20/How_to_do_clustering.html">But how you do clustering?</a></p>
  </li>
  <li><strong>Anomaly Detection:</strong> the model learns to identify unusual or unexpected data points.</li>
  <li><strong>Dimensionality Reduction:</strong> the model learns to identify the most important features or variables in the input data.</li>
  <li><strong>Density estimation</strong> involves a model learning a probability density function (PDF), which is used in anomaly detection. Instances found in very-low density regions are considered anomalies.</li>
</ul>

<p>Unsupervised learning is useful when working with large amounts of data that may not be well understood or labeled. By identifying patterns and relationships in the data, unsupervised learning can help to uncover insights and guide further analysis.</p>

<h1 id="reinforcement-learning">Reinforcement learning</h1>

<p>Reinforcement learning is like a cool type of machine learning where an agent learns to make decisions based on a reward system. The agent gets to interact with an environment, taking actions and getting feedback in the form of rewards or penalties. Over time, the agent gets smarter and learns to make decisions that give it the most rewards.</p>

<p>This technique is used for things like game playing, robotics, and autonomous driving. Itâ€™s all about teaching machines to make complex decisions and do cool things in the real world.</p>

<p>Reinforcement learning is really powerful and has lots of cool applications, but it can also be kind of complex and take up a lot of computer power. So, before you decide to use reinforcement learning, you should think about the problem and the data you have.</p>

<h1 id="ensemble-methods">Ensemble Methods</h1>

<p>A group of predictors is called ensemble and an ensemble learning algorithm is called Ensemble method.</p>

<p>In other words, Ensemble methods are a type of machine learning technique that involve combining multiple models to improve their performance.</p>

<p>Ensemble has a similar bias but a lower variance than a single predictor trained on a the original training set.</p>

<p>There are several types of ensemble methods (algorithms), including:</p>

<h2 id="bagging">Bagging</h2>

<p>The model combines the predictions of multiple models trained on different subsets of the training data. This can help to reduce overfitting and improve the accuracy of the model.</p>

<p><img src="/assets/2024/October/Untitled.png" alt="Fig: Bagging and pasting involves training several predictors on different random samples of the training set" /></p>

<p><em>Fig: Bagging and pasting involves training several predictors on different random samples of the training set</em></p>

<p>Bagging - sampling is performed with replacement (bootstrap=True)</p>

<p>Pasting - sampling is performed without replacement (bootstrap=False)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">bag_clf</span> <span class="o">=</span> <span class="nc">BaggingClassifier</span><span class="p">(</span>
    <span class="nc">DecisionTreeClassifier</span><span class="p">(),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">bootstrap</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span>
<span class="n">bag_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag_clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<p>n_estimators = number of decision trees</p>

<p>max_samples = 100 training samples randomly sampled from training set</p>

<p>bootstrap = True, with replacement</p>

<p>n_jobs = number of CPU cores to use for training and predictions, -1 means use all available</p>

<p>Bootstrapping introduces more diversity into the predictor, means it is more biased than pasting; but the diversity also means the predictors are less correlated and ensemble variance is reduced.</p>

<h3 id="random-forests">Random Forests</h3>

<p>Random Forest is an ensemble of Decision trees, generally trained via the bagging method (or sometimes pasting), typically with <em>max_samples</em> set to the size of training set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">rnd_clf</span> <span class="o">=</span> <span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rnd_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">y_pred_rf</span> <span class="o">=</span> <span class="n">rnd_clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</code></pre></div></div>

<p>Random Forest algorithm introduces extra randomness when growing trees; instead of searching for the best feature when splitting a node, it searches for the best feature among a random subset of features.</p>

<p><strong>Feature Importance</strong></p>

<p>Random forests allow us to measure the relative importance of each feature. Feature importance is calculated by how much tree nodes that use that use that feature reduce impurity on average.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># feature importance
</span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="sh">"</span><span class="s">feature_names</span><span class="sh">"</span><span class="p">],</span> <span class="n">rnd_clf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>

<span class="c1"># output
# sepal length (cm) 0.10109300798027078
# sepal width (cm) 0.031280365249363895
# petal length (cm) 0.3941268382545283
# petal width (cm) 0.47349978851583696
</span></code></pre></div></div>

<p>Random forests are particularly useful for high-dimensional data and problems with complex decision boundaries. They can also handle missing values and noisy data.</p>

<p>Overall, random forests are a powerful and versatile technique for solving a wide range of machine learning problems.</p>

<h2 id="boosting">Boosting</h2>

<p>The model combines the predictions of multiple weak models to create a strong model. This can help to improve the accuracy of the model and reduce bias.</p>

<h3 id="adaboost">AdaBoost</h3>

<p>A type of boosting ensemble method used for classification problems. AdaBoost combines the predictions of multiple weak models using a weighted sum, where the relative weight of misclassified instances increased (boost).</p>

<p>The algorithm increases the relative weight of the misclassified training instances.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>

<span class="n">ada_clf</span> <span class="o">=</span> <span class="nc">AdaBoostClassifier</span><span class="p">(</span>
    <span class="nc">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
    <span class="n">algorithm</span><span class="o">=</span><span class="sh">"</span><span class="s">SAMME.R</span><span class="sh">"</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<span class="n">ada_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="gradient-boosting">Gradient Boosting</h3>

<p>A type of boosting ensemble method used for classification and regression problems. Gradient boosting tries to fit the new predictor to the residual errors (literally) made by the previous predictor.</p>

<p>The basic idea behind gradient boosting is to build a sequence of models, each of which tries to correct the errors of the previous models. The final prediction is the weighted sum of the predictions of all the models in the sequence.</p>

<p>For example, in a binary classification problem, the first model might predict the probability of the positive class for each example. The second model would then focus on the examples that were misclassified by the first model, and try to improve the predictions for those examples. The third model would then focus on the examples that were still misclassified by the first two models, and so on.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</code></pre></div></div>

<p>Gradient boosting with early stopping:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">xgboost</span>

<span class="n">xgb_reg</span> <span class="o">=</span> <span class="n">xgboost</span><span class="p">.</span><span class="nc">XGBRegressor</span><span class="p">()</span>
<span class="n">xgb_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">xgb_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
           <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)],</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">2</span>
           <span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">xgb_reg</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</code></pre></div></div>

<p>Gradient boosting is a powerful technique for improving the performance of machine learning models, particularly when working with complex data or when the performance of a single model is not sufficient. However, it can be computationally intensive and may require careful tuning of hyperparameters to achieve good performance.</p>

<h2 id="stacking">Stacking</h2>
<p>The model combines the predictions of multiple models using a meta-model (blender). This can help to improve the accuracy of the model and reduce overfitting.</p>

<p><img src="/assets/2024/October/Untitled%20copy.png" alt="Fig: Aggregating predictions using a blending predictor" /></p>

<p><em>Fig: Aggregating predictions using a blending predictor</em></p>

<p>Ensemble methods are particularly useful when working with complex data or when the performance of a single model is not sufficient. By combining the predictions of multiple models, ensemble methods can help to improve the accuracy and reliability of the model.</p>

<p>Overall, ensemble methods are a powerful technique for improving the performance of machine learning models, and they are widely used in industry and research. However, it is important to carefully consider the problem and the available data before choosing an ensemble method.</p>

<h2 id="references">References</h2>

<p><a href="https://www.kaggle.com/code/dsmeena/ch-7-ensemble-learning-and-random-forests">Kaggle Notebook</a></p>

<p><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Hands on Machine Learning - buy</a></p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[In this blog post, weâ€™re going to talk about machine learning and its different types.]]></summary></entry><entry><title type="html">Start a Webserver with aws</title><link href="http://localhost:4000/cloud/2023/10/22/Start-a-webserver-with-aws.html" rel="alternate" type="text/html" title="Start a Webserver with aws" /><published>2023-10-22T15:08:10+05:30</published><updated>2023-10-22T15:08:10+05:30</updated><id>http://localhost:4000/cloud/2023/10/22/Start-a-webserver-with-aws</id><content type="html" xml:base="http://localhost:4000/cloud/2023/10/22/Start-a-webserver-with-aws.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>In this blog, we are gonna try to create our own webserver in aws. We will follow operation Excellence principle by designing it failure by using multi-AZ architecture or extending it to more than 1 availability zones. We will use load balancer to uniformly distribute the requests coming to our webserver to different EC2 instances. and If you have a domain we will learn how to create DNS records so that your domain points to this newly created webserver. While doing all of this we will not forget the security principle of well-architected framework.</p>

<h3 id="create-an-ec2-instance">Create an EC2 Instance</h3>

<p>Letâ€™s first create an EC2 instance to run our webserver. Amazon Elastic compute cloud (EC2) is a web service that provides resizable computing capacity in the cloud.</p>

<p>EC2 offers a wide range of <a href="https://aws.amazon.com/ec2/instance-types/">instance types</a> to cater to different workload requirements. Here are some commonly used EC2 instance types:</p>

<ul>
  <li>General Purpose Instances</li>
  <li>Compute-Optimized Instances</li>
  <li>Memory-Optimized Instances</li>
  <li>Storage-Optimized Instances</li>
</ul>

<p>For creating a new EC2 instance follow the steps</p>

<ol>
  <li>Go to EC2 service, then go instances and click Launch an Instance.</li>
  <li>Give a name to your instance and choose an ubuntu AMI (Amazon Machine Image), its similar to docker images.</li>
  <li>Choose an Instance type, there are different instance families including General Purpose, compute-optimized, memory-optimized and storage-optimized. For now just choose t2.micro.</li>
  <li>Amazon recommends to use a key pair to securely connect to your instance. If you already have one use that otherwise you can easily create a new one.</li>
  <li>Leave other settings to default.</li>
  <li>Then click Launch Instance.</li>
</ol>

<p><img src="/assets/2024/September/start%20ec2%20instance.png" alt="Fig: Creating a new EC2 Instance" /></p>

<p><em>Fig: Creating a new EC2 Instance</em></p>

<h3 id="set-up-a-web-server">Set up a web server</h3>

<p>For this connect to your EC2 instance, by choosing your newly created instance and then click on connect. Make sure itâ€™s in running state.</p>

<p><img src="/assets/2024/September/connect%20to%20ec2%20instance.png" alt="Fig: Connecting to EC2 Instance" /></p>

<p><em>Fig: Connecting to EC2 Instance</em></p>

<p>After connecting, run the following commands:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt update
<span class="nb">sudo </span>apt upgrade

<span class="c"># This will instance apache web server</span>
<span class="nb">sudo </span>apt <span class="nb">install </span>apache2
</code></pre></div></div>

<p>If you see something like this after running upgrade, then you need to reboot your system. The different between rebooting and Start/stop is that on start/stop the hardware running your instance is changed but on rebooting the hardware is the same.</p>

<p><img src="/assets/2024/September/start%20ec2%20instance2.png" alt="Untitled" /></p>

<p>In the next screen, select via tab then click enter.</p>

<p><img src="/assets/2024/September/reboot%20instance.png" alt="Fig: Rebooting Instance" /></p>

<p><em>Fig: Rebooting Instance</em></p>

<p>Again connect to your instance and install the Apache webserver. If at this time you try to connect to your apache webserver via your EC2 pubic IP, it will be timed out.  because currently your EC2 instance does not allow http traffic.  For that we need to modify security group.</p>

<h3 id="using-security-group-as-firewall">Using security group as firewall</h3>

<p>Security groups in AWS are virtual firewalls that control inbound and outbound traffic for EC2 instances. They act as a protective layer around instances, allowing you to define rules that specify the protocols, ports, and IP ranges that are allowed to access the instances.</p>

<p>We will create a custom security group for our EC2 instance.  Inside EC2 service go to Network &amp; security panel and click on Create security group.</p>

<p>Add following inbound rules to the security group.</p>

<p><img src="/assets/2024/September/inbound%20rules.png" alt="Fig: Inbound rules to allow http traffic" /></p>

<p><em>Fig: Inbound rules to allow http traffic</em></p>

<p>To change add this newly created security group to your EC2 instance following the steps:</p>

<p>Instances â†’ select instance â†’ Action â†’ security â†’ change security group</p>

<p>Add the newly created security group and remove the old security group, then save it.</p>

<p><img src="/assets/2024/September/change%20security%20group.png" alt="Fig: Adding security group to EC2 instance" /></p>

<p><em>Fig: Adding security group to EC2 instance</em></p>

<p>Now, you will be able to send request to your webserver over http connection. To confirm, type the IPv4 address of your EC2 instance in browser and you will see the default Apache web server page.</p>

<p>Hooray, but thatâ€™s not it we are gonna do more than this to improve the architecture of our web server.</p>

<h3 id="create-backups-with-ami-snapshot">Create backups with AMI snapshot</h3>

<p>You can create the backup of your current webserver by creating an Image that contains all the information required to launch more EC2 instances with same configuration.</p>

<p>To create an image of your webserver follow the steps:</p>

<p>Instances â†’ select Instance â†’ Action â†’ Image and templates â†’ Create Image</p>

<p>Give some appropriate name to your image and keep the rest settings default. Click on create Image.</p>

<p>It will take some time to create the Image or we can say Amazon Machine Image (AMI). You will be able to check this AMI under AMI section of EC2 instance.</p>

<p><img src="/assets/2024/September/create%20ami%20snapshot.png" alt="Fig: Amazon Machine Images" /></p>

<p><em>Fig: Amazon Machine Images</em></p>

<p>After the status is changed to Available, click on Launch Instance from AMI to create your duplicate web servers. Prefer to select same key-pair, security group and under network settings choose a subnet (Availability zone) other than that your current EC2 instance is using to design for failures.</p>

<p><img src="/assets/2024/September/create%20new%20instance%20from%20ami.png" alt="Fig: Creating new instance from AMI" /></p>

<p><em>Fig: Creating new instance from AMI</em></p>

<p>After this you will have 2 EC2 instances running your webserver in two different availability zones. You can create as many as you want but for now letâ€™s keep it two and try some more things.</p>

<p>If you try to access the IPv4 of your new instance, you will see the default Apache page.</p>

<h3 id="scaling-with-elastic-load-balancer-elb">Scaling with Elastic Load Balancer (ELB)</h3>

<p>We will create an Elastic Load balancer (ELB) to uniformly route the incoming requests to healthy instances.</p>

<p>There are three types of load balancers that AWS provides:</p>

<ol>
  <li><strong>Application Load Balancer (ALB)</strong>: This load balancer operates at the application layer and is best suited for applications that require advanced routing capabilities. It can distribute traffic based on URL paths or HTTP headers, making it ideal for routing requests to different microservices or handling multiple domains. ALBs are commonly used for web applications, API gateways, and container-based architectures.</li>
  <li><strong>Network Load Balancer (NLB)</strong>: This load balancer operates at the transport layer (Layer 4) and is designed for applications that require ultra-high performance and low latency. It can handle extremely high volumes of traffic and is suitable for TCP/UDP-based applications, gaming, and real-time streaming.</li>
  <li><strong>Gateway Load Balancer (GLB)</strong>: This load balancer is designed to handle traffic at the edge of the AWS network and is used for scenarios where you need to distribute traffic across multiple virtual appliances, such as firewalls, intrusion detection systems, or deep packet inspection systems.</li>
</ol>

<p>For our task application load balancer is best choice. To create ALB go to EC2 dashboard then to Load Balancing section.</p>

<ol>
  <li>Click on Create new load balancer.</li>
  <li>Choose Application load balancer.</li>
  <li>Add security group that allows inbound traffic over internet.</li>
  <li>
    <p>Create a target group and add the EC2 instances â†’ Include as pending below â†’ Register pending targets.</p>

    <p><img src="/assets/2024/September/register%20target%20group.png" alt="Untitled" /></p>
  </li>
  <li>
    <p>Click Create Load balancer.</p>

    <p><img src="/assets/2024/September//create%20load%20balancer.png" alt="Fig: Application load balancer" /></p>

    <p><em>Fig: Application load balancer</em></p>
  </li>
</ol>

<p>If you go to the DNS name of the elb, you will be routed to one of the healthy EC2 instances.</p>

<p>But this domain doesnâ€™t look good, if you already have a domain or want to buy a domain in that case you use Route 53.</p>

<h3 id="route-53">Route 53</h3>

<p>Amazon Route 53 is a highly available and scalable Domain Name System (DNS) web service.</p>

<p>You can buy a domain from here also in around $12.</p>

<p>Pricing:</p>

<ul>
  <li>$0.50 per hosted zone / month for the first 25 hosted zones</li>
  <li>$0.10 per hosted zone / month for additional hosted zones</li>
</ul>

<p>If hosted zone deleted within 12 hours of creation then no charge.</p>

<h3 id="create-a-hosted-zone">Create a Hosted zone</h3>

<p>In Amazon Route 53, a hosted zone is a container for a collection of DNS records that define how domain names are resolved. It is a way to manage the DNS records for a domain. Each hosted zone represents a domain and contains the DNS records that specify how traffic for that domain is routed.</p>

<p>Create a hosted zone by going to Route 53 â†’ Hosted zones. In the domain add you own domain like <a href="http://abc.com">abc.com</a> Keep the rest default and click create Hosted zone.</p>

<p><img src="/assets/2024/September/create%20hosted%20zone.png" alt="Fig: Hosted zone for my website" /></p>

<p><em>Fig: Hosted zone for my website</em></p>

<p>Nameservers are part of the Domain Name System (DNS) infrastructure and are responsible for translating domain names into IP addresses</p>

<p>Replace your domain name server urls with hosted zone urls.</p>

<p><img src="/assets/2024/September/hostinger.png" alt="Fig: Added Route 53 Name servers" /></p>

<p><em>Fig: Added Route 53 Name servers</em></p>

<p>It might take few hours until the changes reflect for your domain. Till then lets add the record for our ALB.</p>

<p>1st record: It will point to the application load balancer.</p>

<p><img src="/assets/2024/September/create%20record.png" alt="Untitled" /></p>

<p>Create another record with subdomain www, this will point to the our first record.</p>

<p><img src="/assets/2024/September/create%20another%20record.png" alt="Fig: Creating record with www. and routing to dsm-blogs.in" /></p>

<p><em>Fig: Creating record with www. and routing to dsm-blogs.in</em></p>

<p>Now, if you try to access your domain you will see the default Apache web server page.</p>

<p><img src="/assets/2024/September/apache%20running.png" alt="Fig: Now, [dsm-blogs.in](http://dsm-blogs.in) is point to lba which directs to one of EC2 instances" /></p>

<p>Fig: Now, <a href="http://dsm-blogs.in">dsm-blogs.in</a> is point to lba which directs to one of EC2 instances</p>

<p>Hurray, we come really far starting from just EC2 instance to our own domain.</p>

<p>Thatâ€™s enough for this blog post. We will continue developing our webserver in future blog posts, by adding storage services like EBS, EFS and S3 and distributing content with CloudFront. Our aim is better understand the usage of services and when to use which service for our application.</p>

<p>Hope you learnt something useful from this blog. See ya in next blog posts â¤ï¸â¤ï¸.</p>]]></content><author><name></name></author><category term="cloud" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Advancing in Git</title><link href="http://localhost:4000/web/2023/09/23/Advancing-git.html" rel="alternate" type="text/html" title="Advancing in Git" /><published>2023-09-23T15:08:10+05:30</published><updated>2023-09-23T15:08:10+05:30</updated><id>http://localhost:4000/web/2023/09/23/Advancing-git</id><content type="html" xml:base="http://localhost:4000/web/2023/09/23/Advancing-git.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>This blog post discusses intermediate techniques for using Git, a version control system commonly used in software development. Topics covered include branch management, interactive staging, cherry-picking commits, creating and applying diff patches, and rebasing. The post also explains the use of pre-receive hooks and the Git Rerere feature.</p>

<h2 id="branch-management">Branch Management</h2>

<h3 id="git-reset">Git reset</h3>

<p>If youâ€™re using Git and you need to undo changes you made to files, you can use the <code class="language-plaintext highlighter-rouge">git reset</code> command. Basically, it resets your working directory and staging area to a previous commit. So, letâ€™s say you made some changes to files that you havenâ€™t committed yet, you can undo those changes with <code class="language-plaintext highlighter-rouge">git reset</code>.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git reset</td>
      <td>reset your working directory and staging area to a previous commit</td>
    </tr>
    <tr>
      <td>git reset â€“soft HEAD^</td>
      <td>reset your working directory to the previous commit but keep your changes in the staging area</td>
    </tr>
    <tr>
      <td>git reset â€“hard HEAD^</td>
      <td>reset both your working directory and staging area to the previous commit</td>
    </tr>
    <tr>
      <td>git reset <file></file></td>
      <td>unstage a file that you accidentally added to the staging area</td>
    </tr>
    <tr>
      <td>git clean -f</td>
      <td>remove untracked files</td>
    </tr>
    <tr>
      <td>git rm â€“cached testfile.js</td>
      <td>no longer track the file</td>
    </tr>
    <tr>
      <td>git restore â€“staged file.txt</td>
      <td>unstage the changes made to file</td>
    </tr>
    <tr>
      <td>git restore file.txt</td>
      <td>restore the file to its previous state</td>
    </tr>
  </tbody>
</table>

<p>Just keep in mind that <code class="language-plaintext highlighter-rouge">git reset</code> can be a bit risky since it can permanently discard changes and commits. So be careful when using it, alright?</p>

<h3 id="fetch">Fetch</h3>

<p><code class="language-plaintext highlighter-rouge">git fetch</code> is a command in Git that downloads new changes from a remote repository without merging them into the local branch. It updates the remote-tracking branch, which is a local branch that tracks changes in the remote repository.</p>

<p>After running <code class="language-plaintext highlighter-rouge">git fetch</code>, you can use <code class="language-plaintext highlighter-rouge">git merge</code> or <code class="language-plaintext highlighter-rouge">git rebase</code> to integrate the changes from the remote repository into your local branch. Alternatively, you can use <code class="language-plaintext highlighter-rouge">git checkout</code> to switch to the remote-tracking branch and inspect the changes without merging them.</p>

<p><code class="language-plaintext highlighter-rouge">git fetch</code> is a useful command to use when collaborating with others on a project. It allows you to keep your local repository up-to-date with changes made by others, without affecting your working directory.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git fetch</td>
      <td>Downloads new changes from a remote repository without merging them into the local branch.</td>
    </tr>
    <tr>
      <td>git fetch â€“tags</td>
      <td>Fetches all tags from the remote repository that are not already present in the local repository.</td>
    </tr>
    <tr>
      <td>git fetch â€“prune</td>
      <td>Deletes any remote-tracking branches that are no longer on the remote repository.</td>
    </tr>
    <tr>
      <td>git fetch -p</td>
      <td>Shortcut for <code class="language-plaintext highlighter-rouge">git fetch --prune</code>.</td>
    </tr>
  </tbody>
</table>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># command to overwrite of your local files with the master branch</span>
git fetch <span class="nt">--all</span>
git reset <span class="nt">--hard</span> origin/master
</code></pre></div></div>

<p>The git amend command allows you to modify the most recent commit on your branch. You can use it to add changes you forgot to include in the commit, or to modify the commit message. When you run <code class="language-plaintext highlighter-rouge">git commit --amend</code>, Git will open up your default text editor and allow you to edit the commit message. Once you save and close the editor, the commit message on your most recent commit will be updated.</p>

<p>If you have staged changes that were not included in the previous commit, running <code class="language-plaintext highlighter-rouge">git commit --amend</code> will add those changes to the previous commit. You can also use the <code class="language-plaintext highlighter-rouge">-m</code> flag to modify the commit message without opening the text editor.</p>

<p>To remove a file from the previous commit, you can use <code class="language-plaintext highlighter-rouge">git rm --cached &lt;file&gt;</code> and then run <code class="language-plaintext highlighter-rouge">git commit --amend</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># change the previous commit</span>
git add
git commit <span class="nt">--amend</span> <span class="c"># will add the staged changes to previous commit</span>

git commit <span class="nt">--amend</span> <span class="nt">-m</span> <span class="s2">"New commit message"</span>  <span class="c"># modify commit message</span>

<span class="c"># remove file from staging </span>
git <span class="nb">rm</span> <span class="nt">--cached</span> testfile.js    <span class="c"># no longer tracked</span>
</code></pre></div></div>

<h3 id="force-push-to-a-remote">Force push to a remote</h3>

<p>Reasons to use force push:</p>

<ul>
  <li>Local version is preferable to the remote version</li>
  <li>The remote version went wrong and needs repair</li>
  <li>Versions have diverged and merging is undesirable</li>
  <li>Force push replaces the remote branch with your local branch</li>
  <li>Use with caution</li>
  <li>Commits may disappear</li>
  <li>It can be disruptive for others using the remote branch</li>
  <li>Itâ€™s an easy way to frustrate your development team</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push -f</code> or <code class="language-plaintext highlighter-rouge">git push --force</code></td>
      <td>Force push the changes to the remote repository, replacing the commits that are already there and not in the local repository.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push --force-with-lease</code></td>
      <td>Allow force push if no one else has pushed changes to that branch since you pulled.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git commit -am "Add salsa to shopping list"</code></td>
      <td>Automatically add changed files to the staging area and add the message.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git log</code></td>
      <td>Show the commits in the local repository.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git log origin/main</code></td>
      <td>Show the commits in the <code class="language-plaintext highlighter-rouge">origin/main</code> branch.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git show origin/main</code></td>
      <td>Show the changes done in commits in the <code class="language-plaintext highlighter-rouge">origin/main</code> branch.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git reset --hard origin/main</code></td>
      <td>Replace the local repository with the remote repository. Collaborators can use this command to replace their local repository with the remote repository.</td>
    </tr>
  </tbody>
</table>

<h3 id="identify-merged-branches">Identify Merged branches</h3>

<p>Hereâ€™s a cool trick for Git! You can use the command <code class="language-plaintext highlighter-rouge">git branch --merged</code> to see which branches have been merged into your current branch. This is really useful if you want to keep track of what features have been incorporated or if you need to do some cleanup after merging a bunch of features. By default, the command uses your current branch, but you can specify other branch names or commits too. Basically, it shows you all the branches whose tips are reachable from the specified commit (or HEAD if you donâ€™t specify anything). So, if youâ€™re working on a project with multiple branches, give this command a try!</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git branch â€“merged</td>
      <td>List branches that have been merged to the current branch</td>
    </tr>
    <tr>
      <td>git branch â€“no-merged</td>
      <td>List branches that havenâ€™t been merged to the current branch</td>
    </tr>
    <tr>
      <td>git branch -r â€“merged</td>
      <td>Show results for remote branches that have been merged</td>
    </tr>
    <tr>
      <td>git merge main</td>
      <td>Merge the main branch into the current branch</td>
    </tr>
    <tr>
      <td>git branch â€“merged july_release</td>
      <td>Show what branches are merged into the specified branch</td>
    </tr>
    <tr>
      <td>git branch â€“merged origin/july_release</td>
      <td>Show what branches are merged into the specified remote branch</td>
    </tr>
    <tr>
      <td>git branch â€“merged b325a7c49</td>
      <td>Show what branches have this commit</td>
    </tr>
  </tbody>
</table>

<h3 id="prune-stale-branches">Prune Stale Branches</h3>

<p>To keep your Git repository organized, itâ€™s important to delete stale branches. A stale branch is a remote-tracking branch that no longer tracks anything because the actual branch in the remote repository has been deleted. To delete a remote branch, you must also delete your remote-tracking branch. However, if another collaborator deletes a remote branch, your remote-tracking branch remains. Fetching does not automatically delete remote-tracking branches, so you must manually prune them.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git branch -d bugfix</code></td>
      <td>Delete local branch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push -d origin bugfix</code></td>
      <td>Delete remote branch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git remote prune origin</code></td>
      <td>Delete stale remote-tracking branches</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git remote prune origin --dry-run</code></td>
      <td>Demo which branch would be pruned or removed</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git branch -r</code></td>
      <td>Show remote-tracking branches</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git fetch --prune</code> or <code class="language-plaintext highlighter-rouge">git fetch -p</code></td>
      <td>Shortcut to prune, then fetch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git config --global fetch.prune true</code></td>
      <td>Always prune before fetch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git prune</code></td>
      <td>Prune all unreachable objects</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git gc</code></td>
      <td>Part of garbage collection</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git prune --expire &lt;time&gt;</code></td>
      <td>Prune unreachable objects older than specified time</td>
    </tr>
  </tbody>
</table>

<h2 id="taging">Taging</h2>

<h3 id="create-tags">Create Tags</h3>

<p>Tags in Git are like bookmarks, marking important points in the history of a repository. They can be used to mark software versions or to highlight key features or changes. You can also use tags to mark points for discussion with collaborators, like bugs or issues. So, if youâ€™re working on a project in Git, donâ€™t forget to use tags to help keep track of important points in your repositoryâ€™s history!</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git tag issue_136 655da716e7</code></td>
      <td>Add lightweight tag (using hash or branch name)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git tag -am "Version 1.0" v1.0 dd5c49428a0</code></td>
      <td>Add annotated tag (most common)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git tag -d v1.0</code> or <code class="language-plaintext highlighter-rouge">git tag --delete v1.0</code></td>
      <td>Delete a tag</td>
    </tr>
  </tbody>
</table>

<h3 id="list-tags">List Tags</h3>

<p>| Command | Description |
| â€” | â€” |
| git tag
git tag â€“list
git tag -l | List tags alphabetically |
| git tag -l â€œv2*â€ | List tags beginning with â€œv2â€ |
| git tag -n | List tags with first line of each annotation |
| git tag -n5 | List tags with five lines of each annotation |
| git show v1.1 | Show changes made in the commits tagged with v1.1 |
| git diff v1.0..v1.1 | Show all differences from v1.0 to v1.1 |
| git switch v1.0 | Switch to the commit or branch labeled as v1.0 |
| git switch -c branch_v1 v1.0 | Create a new branch from a tag |</p>

<h3 id="push-tags-to-a-remote">Push Tags to a Remote</h3>

<p>Like branches, tags are local unless shared to a remote. Git push does not transfer tags, so they must be explicitly transferred. However, git fetch automatically retrieves shared tags. So, if youâ€™re collaborating with others on a project, make sure to share your tags to keep everyone in the loop!</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push origin v1.0</code></td>
      <td>Push a tag to a remote repository</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push origin --tags</code></td>
      <td>Push all tags to a remote repository</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git fetch</code></td>
      <td>Fetch commits and tags</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git fetch --tags</code></td>
      <td>Fetch only tags (with necessary commits) (rarely used)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push -d origin v1.0</code></td>
      <td>Delete remote tags like remote branches</td>
    </tr>
  </tbody>
</table>

<h2 id="interactive-staging">Interactive Staging</h2>

<h3 id="interactive-mode">Interactive Mode</h3>

<p>Interactive staging is a cool feature in Git that lets you pick and choose which changes you want to stage. This means you can make smaller, focused commits and avoid committing changes youâ€™re not sure about. Itâ€™s also a feature of many Git GUI tools. So, next time youâ€™re using Git, give interactive staging a try!</p>

<p>To enter into interactive mode, use:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git add <span class="nt">-i</span>
git add <span class="nt">--interactive</span>
</code></pre></div></div>

<p><img src="/assets/2024/September/interactive%20mode.png" alt="Untitled" /></p>

<p>In interactive mode, you can stage changes, unstage changes, and add untracked files. You can choose options either by clicking on the corresponding number or the first letter of the option:</p>

<ul>
  <li>s: Status of the repository</li>
  <li>u: Add files to the staging area</li>
  <li>r: Remove files from the staging area</li>
  <li>a: Add untracked files</li>
  <li>d: Differences in file</li>
  <li>q: Quit interactive mode</li>
  <li>h: Help</li>
</ul>

<h3 id="patch-mode">Patch mode</h3>

<p>In Git, you can pick and choose which changes you want to stage using interactive staging. This means you can make smaller, focused commits and avoid committing changes youâ€™re not sure about. You can stage each hunk (chunk of changes) separately. Itâ€™s really useful!</p>

<p>To enter patch mode, go to interactive mode and enter â€œpâ€, followed by the file number.</p>

<p><img src="/assets/2024/September/patch%20mode.png" alt="Untitled" /></p>

<p>Other ways to use patch mode</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git add â€“patch or git add -p</td>
      <td>Interactively choose which changes you want to add to the staging area.</td>
    </tr>
    <tr>
      <td>git stash -p</td>
      <td>Interactively choose which changes you want to stash.</td>
    </tr>
    <tr>
      <td>git reset -p</td>
      <td>Interactively choose which changes you want to unstage.</td>
    </tr>
    <tr>
      <td>git restore -p</td>
      <td>Interactively choose which changes you want to discard from your working directory.</td>
    </tr>
    <tr>
      <td>git commit -p</td>
      <td>Interactively choose which changes you want to include in your commit.</td>
    </tr>
  </tbody>
</table>

<h3 id="split-a-hunk">Split a Hunk</h3>

<p>When using Gitâ€™s interactive staging feature, you can split a hunk further by using the â€œsâ€ option in patch mode. This is useful when a hunk contains multiple changes and requires one or more unchanged lines between them.</p>

<h3 id="edit-a-hunk">Edit a Hunk</h3>

<p>When editing a hunk in Git, you can do it manually if needed. This is especially useful when a hunk cannot be split automatically. However, make sure to pay attention to the prefixes (+, -, space) while editing, or the hunk might not be staged correctly. So, take your time and give them the respect they deserve!</p>

<h2 id="share-select-changes">Share Select Changes</h2>

<h3 id="cherry-picking-commits">Cherry-Picking Commits</h3>

<p>Cherry-picking commits is like copying and pasting code from one branch to another. Each commit becomes a new commit on the current branch, and theyâ€™ll have different SHA codes. You can cherry-pick commits from any branch, but you canâ€™t do it with merge commits. You can use the â€“edit or -e flag to edit the commit message if you need to. However, conflicts can arise that youâ€™ll need to resolve. Itâ€™s a useful feature to have in your Git toolkit!</p>

<p><img src="/assets/2024/September/cherry%20pick.png" alt="Untitled" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git cherry-pick d4e8411d09
git cherry-pick d438411d09..57d290ec44
</code></pre></div></div>

<p>Resolve cherry-picking conflicts is similar to resolving merge conflicts. Just edit in editor and try again!</p>

<h3 id="diff-patches">Diff Patches</h3>

<p>If you want to share changes with collaborators but the changes arenâ€™t ready for a public branch or your collaborators donâ€™t share a remote, you can use diff patches to share the changes via files. Itâ€™s useful for discussing bugs or issues with collaborators or for sharing changes that need further testing before merging into the main branch.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff from-commit to-commit <span class="o">&gt;</span> output.diff
</code></pre></div></div>

<p>Use following common to apply changes in a diff patch file to the working directory. But remember, apply diff patches does not transfer commit history.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git apply output.diff 
</code></pre></div></div>

<h3 id="formatted-patches">Formatted Patches</h3>

<p>In Git, you can export each commit in Unix mailbox format using formatted patches. Itâ€™s a great way to distribute changes via email and includes commit messages. You can apply formatted patches using the <code class="language-plaintext highlighter-rouge">git am</code> command. Itâ€™s similar to cherry-picking, which copies and pastes code from one branch to another. However, formatted patches are better for sharing changes that arenâ€™t ready for a public branch or when collaborators donâ€™t share a remote. Keep in mind that applying formatted patches transfers the commit history.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch 2e33d..655da</code></td>
      <td>Creates patch files for all commits in the range</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch main</code> or <code class="language-plaintext highlighter-rouge">git format-patch main..HEAD</code></td>
      <td>Creates patch files for all commits on the current branch that are not in the <code class="language-plaintext highlighter-rouge">main</code> branch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-path -1 655da</code></td>
      <td>Creates a patch file for a single commit with hash <code class="language-plaintext highlighter-rouge">655da</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch 2e33d..655da -o ~/feature_patches</code></td>
      <td>Creates patch files for all commits in the range and puts them into a directory named <code class="language-plaintext highlighter-rouge">feature_patches</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch 2e33d..655da --stdout &gt; feature.patch</code></td>
      <td>Outputs patch files as a single file named <code class="language-plaintext highlighter-rouge">feature.patch</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git am feature/0001-some-name.patch</code></td>
      <td>Applies a single patch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git am feature/*.patch</code></td>
      <td>Applies all patches in a directory</td>
    </tr>
  </tbody>
</table>

<p>In the command <code class="language-plaintext highlighter-rouge">git am feature/*.patch</code>, <code class="language-plaintext highlighter-rouge">am</code> stands for â€œapply mailboxâ€. This command applies a mailbox-style patch to the current branch.</p>

<h2 id="rebasing">Rebasing</h2>

<h3 id="rebase-commits">Rebase Commits</h3>

<p>Rebasing is a way to move commits from one branch to another. Itâ€™s useful when you want to integrate recent commits without merging and to maintain a clearer, more linear project history. It also ensures that topic branch commits apply cleanly. So, if youâ€™re working on a project and want to keep your commits organized, give rebasing a try!</p>

<p><img src="/assets/2024/September/rebase.svg" alt="Untitled" /></p>

<p><em>Fig: Rebasing Feature branch <a href="www.atlassian.com">Credit</a></em></p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git rebase main</td>
      <td>Rebase current branch on tip of main (from feature branch)</td>
    </tr>
    <tr>
      <td>git rebase main new_feature</td>
      <td>Rebase new_feature to tip of main (from main)</td>
    </tr>
    <tr>
      <td>git rebase â€“onto newbase upstream branch</td>
      <td>Rebase branch onto newbase</td>
    </tr>
    <tr>
      <td>git rebase â€“onto target main new_feature</td>
      <td>Rebase new_feature commits on target branch that are not on main (merged)</td>
    </tr>
  </tbody>
</table>

<h4 id="handle-rebase-conflicts">Handle Rebase Conflicts</h4>

<p>When you rebase commits, it can cause conflicts with existing code. Git will pause the rebase before each conflicting commit, and youâ€™ll need to resolve the conflicts. This process is similar to resolving merge conflicts. Itâ€™s important to be patient and take your time to ensure that the conflicts are resolved correctly.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git rebase â€“continue</td>
      <td>Continue the rebase after resolving conflicts</td>
    </tr>
    <tr>
      <td>git rebase â€“skip</td>
      <td>Skip the current commit during the rebase process</td>
    </tr>
    <tr>
      <td>git log â€“graph â€“all â€“decorate â€“oneline</td>
      <td>Visualize the branch history as a graph</td>
    </tr>
    <tr>
      <td>git merge-base main new_feature</td>
      <td>Return the commit SHA where the topic branch diverges from main</td>
    </tr>
    <tr>
      <td>git rebase -i</td>
      <td>Open an interactive rebase prompt to choose which commits to move</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/2024/September/diverges.png" alt="Fig: The branch test diverges from main" /></p>

<p><em>Fig: The branch test diverges from main</em></p>

<h3 id="merging-vs-rebasing">Merging vs. Rebasing</h3>

<ul>
  <li>Two ways to incorporate changes from one branch into another branch</li>
  <li>Similar ends but the means are different</li>
  <li>Side effects are important to understand</li>
</ul>

<p><img src="https://www.edureka.co/blog/wp-content/uploads/2022/01/fig13.png" alt="Edureak" />
<em>Fig: Git Merge vs Git Rebase <a href="">Credit: Edureka</a></em></p>

<table>
  <thead>
    <tr>
      <th>Merging</th>
      <th>Rebasing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Adds a merge commit</td>
      <td>No additional merge commit</td>
    </tr>
    <tr>
      <td>Nondestructive</td>
      <td>Destructive: SHA changes, commits are rewritten</td>
    </tr>
    <tr>
      <td>Complete record of what happened and when</td>
      <td>No longer a complete record of what happened and when</td>
    </tr>
    <tr>
      <td>Easy to undo</td>
      <td>Tricky to undo</td>
    </tr>
    <tr>
      <td>Logs can become cluttered and nonlinear</td>
      <td>Logs are cleaner and more linear</td>
    </tr>
  </tbody>
</table>

<p><strong>The Golden Rule of Rebasing</strong></p>

<ul>
  <li>Thou Shalt not rebase a public branch</li>
  <li>Rebase abandons existing, shared commits and creates new, similar commits instead</li>
  <li>Collaborators would see project history vanish</li>
  <li>Getting all collaborators back in sync can be hassle</li>
</ul>

<p><strong>How to Choose</strong></p>

<ul>
  <li>Merge to allow commits to stand out or to be clearly grouped</li>
  <li>Merge to bring large topic branches back into main</li>
  <li>Rebase to add minor commits in main to a topic branch</li>
  <li>Rebase to move commits from one branch to another</li>
  <li>Merge anytime the topic branch is already public and being used by others (The Golden Rule of Rebasing).</li>
</ul>

<h3 id="interactive-rebasing">Interactive Rebasing</h3>

<p>Interactive rebasing is a feature in Git that allows you to modify commits as theyâ€™re being replayed. When you run <code class="language-plaintext highlighter-rouge">git rebase -i</code>, Git will open up the git-rebase-todo file for editing. In this file, you can reorder, skip, or edit commits. The options available to you in interactive rebasing include:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">pick</code>: include the commit</li>
  <li><code class="language-plaintext highlighter-rouge">drop</code>: remove the commit</li>
  <li><code class="language-plaintext highlighter-rouge">reword</code>: edit the commit message</li>
  <li><code class="language-plaintext highlighter-rouge">edit</code>: pause the rebasing process to allow you to make changes to the commit</li>
  <li><code class="language-plaintext highlighter-rouge">squash</code>: combine the commit with the one immediately before it</li>
  <li><code class="language-plaintext highlighter-rouge">fixup</code>: combine the commit with the one immediately before it, but discard its commit message</li>
</ul>

<p>Interactive rebasing is useful when you want to modify the history of a branch before sharing it with others. It can also be helpful for cleaning up your commit history by grouping related changes or removing unnecessary commits. However, be careful when using interactive rebasing, as it can be risky if not done properly. Itâ€™s always a good idea to make a backup copy of your branch before rebasing it.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Interactive rebase</span>
git rebase <span class="nt">-i</span> main new_feature

<span class="c"># Rebase last three commits onto the same branch</span>
<span class="c"># but with the opportunity to modify them</span>
git rebase <span class="nt">-i</span> HEAD~3
</code></pre></div></div>

<p><img src="/assets/2024/September/rebase.png" alt="Untitled" /></p>

<h3 id="squash-commits">Squash Commits</h3>

<p>Squash commits is a way to combine multiple commits into one. Itâ€™s useful for when you have several small commits that are related to each other and you want to make them into a single, cohesive commit. This can help to keep your commits organized and make it easier to understand the history of your code.</p>

<p>When squashing commits, youâ€™ll take the changes from each commit and combine them into a single commit. The commit message for the new commit will be a combination of the commit messages from the original commits. You can use the <code class="language-plaintext highlighter-rouge">git rebase -i</code> command to interactively rebase your branch and squash commits.</p>

<p>To squash commits, follow these steps:</p>

<ol>
  <li>Use <code class="language-plaintext highlighter-rouge">git log</code> to find the SHA IDs of the commits you want to squash.</li>
  <li>Use <code class="language-plaintext highlighter-rouge">git rebase -i HEAD~&lt;number of commits&gt;</code> to start an interactive rebase.</li>
  <li>In the interactive rebase, change <code class="language-plaintext highlighter-rouge">pick</code> to <code class="language-plaintext highlighter-rouge">squash</code> for the commits you want to squash. You can also edit the commit messages if needed.</li>
  <li>Save and close the file to complete the rebase.</li>
</ol>

<p>After squashing the commits, youâ€™ll have a single commit that contains all the changes from the original commits. This can be helpful for keeping your commit history clean and organized, especially when collaborating with others on a project.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Rebase last four commits onto the same branch</span>
<span class="c"># but with the opportunity to modify them</span>
git rebase <span class="nt">-i</span> HEAD~4

pick 81a73ff Redesign
squash b2baf90 Change image sizes
fixup c0261b3 Bug fix to the design
squash 0f7760e Adjust styles
</code></pre></div></div>

<h3 id="pull-rebase">Pull Rebase</h3>

<p>Pull rebase is a way to fetch changes from a remote repository and then rebase them onto the local branch instead of merging them. This helps to keep the commit history cleaner by reducing the number of merge commits. However, it should only be used for local commits that are not shared to a remote branch.</p>

<p><img src="https://media.geeksforgeeks.org/wp-content/uploads/20200415234509/Rebasing-in-git.png" alt="" /></p>

<p><em>Fig: Rebasing <a href="geeksforgeeks.org">Credit: GFG</a></em></p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull -r</code></td>
      <td>Pull with rebase</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull --rebase</code></td>
      <td>Pull with rebase</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull --rebase=preserve</code></td>
      <td>Pull with rebase and preserve merge commits</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull --rebase=interactive</code></td>
      <td>Pull with interactive rebase</td>
    </tr>
  </tbody>
</table>

<h2 id="track-down-problems">Track Down Problems</h2>

<h3 id="log-options">Log Options</h3>

<p><code class="language-plaintext highlighter-rouge">git log</code> is a command in Git that displays the commit history for a repository. It shows the SHA-1 hash, author, date, and commit message for each commit in reverse chronological order. By default, it shows the entire commit history for the current branch.</p>

<p>However, there are many options to customize the output, such as sorting, filtering, and formatting. Some common options are <code class="language-plaintext highlighter-rouge">--oneline</code> to show each commit on one line, <code class="language-plaintext highlighter-rouge">--graph</code> to display the commit history as a graph, and <code class="language-plaintext highlighter-rouge">--since</code> or <code class="language-plaintext highlighter-rouge">--until</code> to filter the commit history by date. You can also use <code class="language-plaintext highlighter-rouge">git log</code> to show the commit history for a specific file or directory, or to show the changes made by a specific commit.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git log filename.txt</td>
      <td>List commits that changed filename.txt</td>
    </tr>
    <tr>
      <td>git log -p or git log â€“patch</td>
      <td>List commits as patches (with diffs)</td>
    </tr>
    <tr>
      <td>git log -L 100,150:filename.txt or git log -L 100,+50:filename.txt</td>
      <td>List changes (as patches) to lines 100-150 in filename.txt</td>
    </tr>
    <tr>
      <td>git log -S â€œMaxConnectionsâ€</td>
      <td>List all commits that add or change the string</td>
    </tr>
    <tr>
      <td>git log â€“pretty=format:â€%h %cn %cd %s %anâ€</td>
      <td>Show commit hash, committer name, commit date, commit message, author name</td>
    </tr>
    <tr>
      <td>git reflog</td>
      <td>Used to recover lost commits and branches</td>
    </tr>
    <tr>
      <td>git log â€“since=yesterday</td>
      <td>Show commits since yesterday (midnight)</td>
    </tr>
    <tr>
      <td>git log â€“since=â€May 1, 2021â€</td>
      <td>Show commits since a specific date</td>
    </tr>
    <tr>
      <td>git log â€“since=â€May 1, 2021 14:23:45â€</td>
      <td>Show commits since a specific date and time</td>
    </tr>
    <tr>
      <td>git log â€“since=â€3 days agoâ€</td>
      <td>Show commits since a certain number of days ago</td>
    </tr>
    <tr>
      <td>git log â€“since=â€2 hours agoâ€</td>
      <td>Show commits since a certain number of hours ago</td>
    </tr>
  </tbody>
</table>

<p><strong>Git diff</strong></p>

<p>Git uses standard UNIX less program do show the git diff.</p>

<p><img src="/assets/2024/September/git%20diff.png" alt="Untitled" /></p>

<p><strong>Git pager</strong> (used with diff)</p>

<p>The <code class="language-plaintext highlighter-rouge">core.pager</code> setting determines the pager used when Git pages output. This setting can be configured globally or per-repository.</p>

<p>To set the pager globally, use the following command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git config --global core.pager &lt;pager&gt;
</code></pre></div></div>

<p>Replace <code class="language-plaintext highlighter-rouge">&lt;pager&gt;</code> with the name of the pager you want to use, such as <code class="language-plaintext highlighter-rouge">less</code> or <code class="language-plaintext highlighter-rouge">more</code>.</p>

<p>To set the pager per-repository, use the same command without the <code class="language-plaintext highlighter-rouge">--global</code> option, inside the repository directory.</p>

<p>Git comes with a default pager, which is <code class="language-plaintext highlighter-rouge">less</code>. If you havenâ€™t set a pager explicitly, <code class="language-plaintext highlighter-rouge">less</code> will be used as the default.</p>

<h3 id="blame">Blame</h3>

<p><code class="language-plaintext highlighter-rouge">git blame</code> is a command in Git that allows you to see who made changes to a file, which lines were changed, and when the changes were made. It can be helpful for understanding the history of a file, tracking down the source of a bug, or determining who to contact with questions about a particular piece of code. The output of <code class="language-plaintext highlighter-rouge">git blame</code> includes the commit SHA, author name, date, and the specific line of code that was changed. By default, <code class="language-plaintext highlighter-rouge">git blame</code> shows the annotations for the entire file, but you can also specify a specific range of lines or a specific revision to show annotations for.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git blame filename.txt</td>
      <td>Annotate file with commit details</td>
    </tr>
    <tr>
      <td>git blame -w filename.txt</td>
      <td>Annotate file with commit details, ignoring whitespace</td>
    </tr>
    <tr>
      <td>git blame -L 100,150 filaname.txt</td>
      <td>Annotate lines 100-150</td>
    </tr>
    <tr>
      <td>git blame -L 100,+50 filename.txt</td>
      <td>Annotate lines 100-150</td>
    </tr>
    <tr>
      <td>git blame d9dba0 filename.txt</td>
      <td>Annotate file at revision d9dba0</td>
    </tr>
    <tr>
      <td>git blame d9dba0 â€“ filename.txt</td>
      <td>Same as previous command</td>
    </tr>
    <tr>
      <td>git config â€“global alias.praise blame</td>
      <td>Add a global alias for â€œpraiseâ€ (if blame sounds negative)</td>
    </tr>
    <tr>
      <td>git annotate filename.txt</td>
      <td>Annotate file with commit details, different output format</td>
    </tr>
  </tbody>
</table>

<h3 id="bisect">Bisect</h3>

<p>If youâ€™re trying to find a bug in your Git project, binary search is your friend! Hereâ€™s how it works: first, find the commit that introduced the bug or regression. Then, mark the last good revision and the first bad revision. Reset your code to the midpoint between these two revisions and test it out. If the code is still broken, mark the midpoint as bad. If itâ€™s fixed, mark it as good. Keep repeating this process, dividing the revisions in half each time, until you find the exact commit that introduced the bug. It may take a few tries, but itâ€™s worth it to squash that bug!</p>

<p><img src="/assets/2024/September/bisect.png" alt="Untitled" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git bisect start
git bisect good &lt;treeish&gt;
git bisect bad &lt;treeish&gt;
git bisect reset
</code></pre></div></div>

<p>Thatâ€™s all for todayâ€™s learning. ğŸ¥°</p>

<h2 id="references">References</h2>

<p><a href="https://github.com/LinkedInLearning/git-intermediate-techniques-3082618">LinkedIn Learning</a></p>]]></content><author><name></name></author><category term="Web" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Generative Pre-training</title><link href="http://localhost:4000/ai/2023/08/13/Generative_pre_training.html" rel="alternate" type="text/html" title="Generative Pre-training" /><published>2023-08-13T10:00:10+05:30</published><updated>2023-08-13T10:00:10+05:30</updated><id>http://localhost:4000/ai/2023/08/13/Generative_pre_training</id><content type="html" xml:base="http://localhost:4000/ai/2023/08/13/Generative_pre_training.html"><![CDATA[<h1 id="introduction-">Introduction ğŸš€</h1>

<p>In this blog, we will explore the main idea behind chat-GPT, which is generative pre-training, and create our own smaller version of a question-answering model using generative pre-training. ğŸ¤–ğŸ’¬</p>

<p>The research paper we will be referencing is â€œImproving Language Understanding by Generative Pre-Training.â€ ğŸ“šğŸ”¬</p>

<h1 id="generative-pre-trained-transformer-gpt-">Generative Pre-Trained Transformer (GPT) ğŸ§ </h1>

<h4 id="transfer-learning-">Transfer Learning ğŸ”„</h4>

<p>Transfer learning is a machine learning technique in which a model trained on a large dataset is adapted for a different but related task. ğŸ“â¡ï¸ğŸ†•</p>

<p>The concept behind transfer learning is that the pre-trained model has learned general patterns and can be adjusted to specific domains or tasks with minimal additional training data. This saves time and resources compared to training a model from scratch. â³ğŸ’°</p>

<h4 id="generative-pre-training-">Generative Pre-training ğŸ”®</h4>

<p>In the field of natural language processing, generative pre-training is an example of transfer learning. A language model is pre-trained on a large corpus of text data using self-supervised learning, and then fine-tuned on a smaller, labeled dataset for a specific task. ğŸ“šâ¡ï¸ğŸ¯</p>

<p>The Generative Pre-trained Transformer (GPT) is a state-of-the-art deep learning architecture developed by OpenAI for natural language processing tasks, such as text generation, text completion, and text classification. ğŸŒŸğŸ¤–</p>

<p>GPT models are usually pre-trained on a large corpus of text data from the internet to learn general language patterns. Then, they are fine-tuned on specific domains or tasks using smaller, domain-specific datasets to adapt them to the specific context and language patterns of the target domain. ğŸŒâ¡ï¸ğŸ¯</p>

<p>This is a semi-supervised approach that involves unsupervised pre-training and supervised fine-tuning. ğŸ”„ğŸ‹ï¸</p>

<p>During pre-training in generative pre-training, the model is trained to predict missing words or generate new text based on the input context. The goal is to learn a universal representation that transfers with little adaptation to a wide range of tasks. ğŸ§©ğŸ”®</p>

<p>In the context of generative pre-training, â€œgenerativeâ€ refers to the ability of the model to generate new output based on the input it has learned. In other words, the model is capable of generating new text that is similar to the text it was trained on, but not identical. This is distinct from discriminative models, which are used for tasks such as classification and are designed to distinguish between different input classes. ğŸ¨ğŸ†šğŸ”</p>

<h4 id="self-supervised-learning-">Self-Supervised Learning ğŸ¤–ğŸ”„</h4>

<p>Self-supervised learning is a type of machine learning in which the model is trained to predict or generate missing information in the data without explicitly being told what the missing information is. This is different from supervised learning, where the model is given labeled data to learn from. ğŸ•µï¸â€â™‚ï¸ğŸ§ </p>

<p>An example of self-supervised learning is image inpainting, where the model is trained to fill in missing pixels in an image based on the context of the surrounding pixels. In this case, the model is not explicitly told which pixels are missing, but rather it learns to infer the missing pixels based on the patterns it has learned in the input image. ğŸ–¼ï¸ğŸ”</p>

<p>Self-supervised learning is a powerful approach because it allows the model to learn from large amounts of unlabeled data, which is often easier to obtain than labeled data. This can be especially useful in domains where labeled data is scarce or expensive to obtain. ğŸ“ŠğŸ’¡</p>

<h1 id="training-framework-ï¸ï¸">Training Framework ğŸ‹ï¸â€â™‚ï¸</h1>

<p>In the context of generative pre-training, the training framework typically involves two stages: pre-training and fine-tuning. ğŸ”„</p>

<ol>
  <li>
    <p>Pre-training ğŸ“</p>

    <p>During pre-training, the model is trained on a large, unlabeled corpus of text data using a self-supervised learning approach. This involves predicting missing words or generating new text based on the context of the input. ğŸ”®</p>

    <p>The goal of pre-training is to learn a general representation of language that can be fine-tuned for specific tasks. ğŸŒ</p>
  </li>
  <li>
    <p>Fine-tuning ğŸ¯</p>

    <p>During fine-tuning, the pre-trained model is further trained on a smaller, labeled dataset specific to the task at hand. This involves adjusting the parameters of the pre-trained model to better fit the specific context and language patterns of the target domain. ğŸ”§</p>

    <p>Fine-tuning allows the model to adapt to the specific task and improve its performance. ğŸ“ˆ</p>
  </li>
</ol>

<p>Overall, the goal of the training framework in generative pre-training is to learn a general representation of language that can be fine-tuned for a wide range of tasks with minimal additional training data. ğŸš€</p>

<h2 id="unsupervised-pre-training-">Unsupervised Pre-Training ğŸ¤–ğŸ”®</h2>

<p>To perform generative pre-training, an unsupervised corpus of tokens $\mu = (u_1, â€¦, u_n)$ is required. The language modeling objective in this context refers to predicting the next word in a sequence given the previous words. The goal is to maximize the probability of the next word in the sequence given the preceding words.</p>

<p>To achieve this, we use the standard language modeling objective and maximize:</p>

<p>$L_1(U) = \sum_i log P(u_i \lvert u_{iâˆ’k}, . . . , u_{iâˆ’1}; Î˜)$</p>

<p>where k is the size of the context window. The conditional probability is modeled using a neural network with parameters $Î˜$, which are trained using stochastic gradient descent.</p>

<p>We use a multilayer transformer decoder for the language model, this is used to calculate the probability of next token given a sequence of tokens.</p>

<p>$h_0 = UW_e +W_p$, calculate the initial hidden state of the model.</p>

<p>where:</p>

<p>$U = (u_{-k}, . . . , u_{âˆ’1})$ is the context vector of tokens.</p>

<p>$W_e$ is the token embedding matrix, which maps each token to a high-dimensional vector representation.</p>

<p>$W_p$ is the position embedding matrix, which encodes the relative position of each token in the input sequence.</p>

<p>This hidden state is then processed through multiple layers of transformer blocks to produce the final output of the model. Each layer producing a new block of data $h_l$ that serves as the input to the next layer.</p>

<p>$h_l = transformer_block(h_{lâˆ’1})âˆ€i âˆˆ [1, n]$</p>

<p>where:</p>

<p>n is the number of layers in the transformer block.</p>

<p>We then calculate the probability distribution of the next word in a sequence given the previous words. The softmax function is applied to the dot product of the hidden state vector ($h_n$) and the transpose of the word embedding matrix ($W_e$) to obtain the probabilities of the next word.</p>

<p>$P(u) = softmax(h_nW^T_e )$</p>

<h2 id="supervised-fine-tuning-ï¸ï¸">Supervised Fine-Tuning ğŸ¯ğŸ‹ï¸â€â™‚ï¸</h2>

<p>We use a labeled dataset C and a sequence of input tokens $x^1, x^2, â€¦., x^m$ and a label y. These inputs are passed through the pre-trained model to obtain the final output $h_l^m$, which is then fed to a linear output layer with parameter $W_y$.</p>

<p>This equation $P(y\lvert x^1, . . . , x^m) = softmax(h_l^m W_y)$ calculates the probability of target output y given a set of input tokens $x^1, . . . , x^m$.</p>

<p>where:</p>

<p>$h_l^m$ represents the hidden state of the model after processing the input sequence (of size m) through l layers of transformer blocks.</p>

<p>$W_y$ is the parameter matrix of the fine-tuned model.</p>

<p>The final objective is to maximize:</p>

<p>$L_2(C) = \sum_{(x, y)}log P(y\lvert x^1,â€¦,x^m)$ i.e. the objective is to maximize a function $L_2(C)$, which is a sum of logarithmic probabilities.</p>

<p>Including language modeling as an auxiliary objective to fine-tuning helps learning by improving the generalization of the supervised model and accelerating convergence. To achieve this, we add $L_1(C)$ language modeling objective with weight $\lambda$. Therefore, the final objective to maximize is:</p>

<p>$L_3(C) = L_2(C) + \lambda * L_1(C)$</p>

<h1 id="task-specific-input-transformations-">Task-specific Input Transformations ğŸ”„</h1>

<p>We use a traversal-style approach to convert structured inputs into an ordered sequence that our pre-trained model can process.</p>

<p><img src="/assets/2024/September/gpt.png" alt="Fig: **(Left) Transformer architecture and training objectives used in this work.
      (Right) Input transformations for fine-tuning on different tasks. We convert all structured inputs into token sequences to be processed by our pre-trained model, followed by a linear + softmax layer.**" /></p>

<p><em>Fig: <strong>(Left) Transformer architecture and training objectives used in this work.
      (Right) Input transformations for fine-tuning on different tasks. We convert all structured inputs into token sequences to be processed by our pre-trained model, followed by a linear + softmax layer.</strong></em></p>

<ol>
  <li>
    <p>Textual Entailment ğŸ§©</p>

    <p>For entailment tasks, we concatenate the token sequences of the premise p and hypothesis h, with a delimiter token ($) in between.</p>
  </li>
  <li>
    <p>Similarity ğŸª</p>

    <p>For similarity tasks, the input sequence contains both possible sentence orderings (with a delimiter in between). We process each independently to produce two sequence representations $h_l^m$.</p>
  </li>
  <li>
    <p>Question Answering and Commonsense Reasoning ğŸ’¡</p>

    <p>For these tasks, we are given a context document z, a question q, and a set of possible answers ${a_k}$. We create a sequence of [z;q;$;a_k].</p>
  </li>
</ol>

<p>Each of these sequences is processed independently with our model and then normalized via a softmax layer to produce an output distribution over possible answers.</p>

<h3 id="implementation">Implementation</h3>

<p>You can find the Implementation of fine Tuning this GPT2 model on question-answering dataset here .</p>

<p><a href="https://www.kaggle.com/code/dsmeena/pytorch-fine-tuning-gpt2">Kaggle</a></p>

<h3 id="references">References</h3>

<p><a href="https://paperswithcode.com/method/gpt">Papers with Code - GPT Explained</a></p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Introduction ğŸš€]]></summary></entry></feed>