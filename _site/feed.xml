<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-09-25T18:04:05+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">dsm Blogs</title><subtitle>This is a blog about Data Science and Machine Learning. I write about all the things I learn in this domain. I also share my knowledge with you.</subtitle><entry><title type="html">Q-Learning</title><link href="http://localhost:4000/ai/2024/09/23/Q_learning.html" rel="alternate" type="text/html" title="Q-Learning" /><published>2024-09-23T10:00:10+05:30</published><updated>2024-09-23T10:00:10+05:30</updated><id>http://localhost:4000/ai/2024/09/23/Q_learning</id><content type="html" xml:base="http://localhost:4000/ai/2024/09/23/Q_learning.html"><![CDATA[<h1 id="introduction">Introduction</h1>

<p>In this blog, we will learn about the fundamental algorithms used in reinforcement learning. It’s not about neural networks but the mathematical algorithms involved in learning.</p>

<h1 id="markov-decision-process-">Markov Decision Process 🤔</h1>

<p>Let’s understand the problem, we are trying to solve here. The environment of an agent can be modelled as a Markov decision process, where the agent can choose one of several actions and the transition probabilities depend on the chosen action. 🤖</p>

<p>Our aim is to find an optimal policy for the agent, by following that agent can maximize the rewards earned in the enviornment.</p>

<p><img src="/assets/2024/September/markov%20decision%20chain.png" alt="alt text" />
<em>Fig: Example of Markov chain  <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">credit for image</a></em></p>

<p>Let’s learn some of the algorithms that are used to find the optimal policy for the agent.</p>

<h2 id="state-value-iteration-algorithm-">(State) Value Iteration algorithm 🔄</h2>

<p>In this algorithm, we calcualte the state value $V(s)$ for all states.</p>

<p>Optimal state value $V^*(s)$ of any state s, is the sum of all discounted future rewards the agent can expect on average after it reaches a state s, assuming it acts optimally. 🎯</p>

<p>$V\star(s) = max_a \sum_sP(s,a,s\prime)[R(s,a,s\prime)+\gamma.V^*(s\prime)]$  for all s</p>

<p><em>Eq: Bellman Optimality Equation</em></p>

<p>where,</p>

<ul>
  <li>$P(s,a,s’)$ = transition probability from state s to state s’, given that agent chose action a [conditional probability]. 🎲</li>
  <li>$R(s,a,s’)$ = reward the agent gets when it goes from state s to state s’, given that agent chose action a 🏆</li>
  <li>$\gamma$ = discount factor 🈹</li>
</ul>

<p>If we increase discount factor, we will value the future rewards more.
Bellman optimality equation assumes, that we already have the optimal state value for next state s’. Since, we don’t have future value; we update state values iteratively as follows:</p>

<ol>
  <li>First initialize all the state value estimates to 0.</li>
  <li>
    <p>Iteratively update them using recurrent relation</p>

    <p>$V_{k+1}(s) \leftarrow  \underset{a}{\max} \underset{s’}{\sum}P(s,a,s’) [R(s,a,s’) + \gamma.V_k(s’)]$ for all s</p>

    <p><em>Eq: Value Iteration algorithm</em> 🔁</p>

    <p>where</p>

    <ul>
      <li>$V_k(s)$ = estimated value of state s at the $k^{th}$ iteration</li>
    </ul>
  </li>
</ol>

<p>After the Value Iteration algorithm converges, we can derive the optimal policy $π^\star$ for each state s: 🥳</p>

\[\pi^*(s) = \underset{a}{argmax} \sum_{s'} P(s, a, s')[R(s,a,s') + \gamma V^*(s')]\]

<p>This means that for each state, the optimal action is the one that maximizes the expected sum of the immediate reward and the discounted optimal value of the next state. 💰</p>

<h2 id="q-value-iteration-algorithm-">Q-Value Iteration algorithm 🎲</h2>

<p>This algorithm is used to find the optimal state-action values, genreally called Q-values (Quality values). 💡</p>

<p>Optimal Q-value of state-action pair (s, a), $Q^*(s, a)$, is the sum of discounted future rewards the agent can expect on average after it reaches state s and chooses an action a. 💰</p>

<p>It involves following steps:</p>
<ol>
  <li>Initialize all Q-values estimates to 0.</li>
  <li>
    <p>Then update them using below recurrence relation. 🔄</p>

    <p>$Q_{k+1}(s,a) \leftarrow \underset{s’}{\sum}T(s,a,s’)[R(s,a,s’)+\gamma.\underset{a’}{max} \space Q_k(s’,a’)]$</p>

    <p><em>Eq: Q-Value Iteration algorithm</em></p>

    <p>where:</p>
    <ul>
      <li>$\underset{a’}{max} \space Q_k(s’, a’)$ is the maximum Q-value for the next state s’ and all possible actions a’ at $k_{th}$ iteratin</li>
    </ul>
  </li>
</ol>

<p>After the Q-Value Iteration algorithm converges, we can derive the optimal policy $\pi^*(s)$ for each state s.</p>

\[\pi^*(s) = \underset{a}{argmax} \space Q^\star(s,a)\]

<p>That means, when the agent is in state s it should choose the action with the highest Q-Value for that state. 🏆</p>

<p>Let’s apply the Q-Value Iteration algorithm to MDP given in above image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># shape=[s, a, s']  # row - current state, column = action
# s2 to s0 given action a1 transition probability = [2][1][0]
</span><span class="n">transition_probabilities</span> <span class="o">=</span> <span class="p">[</span> 
		<span class="p">[[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]],</span> 
		<span class="p">[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="bp">None</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span> 
		<span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="bp">None</span><span class="p">]</span>
	<span class="p">]</span>

<span class="c1"># shape=[s, a, s']
</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">[</span>  
		<span class="p">[[</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> 
		<span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">50</span><span class="p">]],</span> 
		<span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">+</span><span class="mi">40</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
	<span class="p">]</span>

<span class="c1"># from s0, s1, s2
</span><span class="n">possible_actions</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>   

<span class="c1"># Initialize Q-Values
</span><span class="n">Q_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="p">)</span>  <span class="c1"># -np.inf for impossible actions
</span><span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">actions</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">possible_actions</span><span class="p">):</span>
	<span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">actions</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>     <span class="c1"># 0 for possible actions
</span>	
<span class="c1"># Q-Value Iteration algorithm
</span><span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.90</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
	<span class="n">Q_prev</span> <span class="o">=</span> <span class="n">Q_values</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
	
	<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
		<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">possible_actions</span><span class="p">[</span><span class="n">s</span><span class="p">]:</span>

			<span class="n">Q_values</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">([</span><span class="n">transition_probabilities</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="n">a</span><span class="p">][</span><span class="n">sp</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">rewards</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="n">a</span><span class="p">][</span><span class="n">sp</span><span class="p">]</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">Q_prev</span><span class="p">[</span><span class="n">sp</span><span class="p">]))</span>
				<span class="k">for</span> <span class="n">sp</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)])</span>
                        
<span class="nf">print</span><span class="p">(</span><span class="n">Q_values</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Best action for each state: </span><span class="sh">"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">Q_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># [[18.91891892 17.02702702 13.62162162]
#  [ 0.                -inf -4.87971488]
#  [       -inf 50.13365013        -inf]]
# Best action for each state  [0 0 1]
</span></code></pre></div></div>

<p>Using above algorithm we can find the best policy for the agent.</p>

<h1 id="q-learning-">Q-Learning 🤖</h1>

<p>If you notice in the above MDP diagram, the transition probabilities and rewards are given us in advance. That’s not the case in real word 🌍, now comes the role of Q-Learning algorithm. <strong>Q-Learning algorithm</strong> is an adaptation of the Q-Value Iteration algorithm to the situation where the transition probabilities and the rewards are initially unknown.</p>

<p>This algorithm is useful for problems where the environment is fully observable, and the agent can learn by trial and error. Q-learning has been successfully applied to problems such as game playing, robotics, and natural language processing. 🧠🤖</p>

<p>This is an example of <strong>model-free reinforcement learning</strong>, where the transition probabilities and the rewards are initially unknown and agent has to learn these by direct interactions and experiences.</p>

<p>$Q(s,a) \underset {\alpha}{\leftarrow} r + \gamma.\underset{a’}{max} \space Q(s’, a’)$</p>

<p><em>Eq: Q-Learning algorithm</em></p>

<p>$ old \underset {\alpha}{\leftarrow} new ⇒ old(1-a) + a*new$ [This is how be interpret the above equation]</p>

<h2 id="q-learning-algorithm-">Q-learning algorithm 🧠</h2>

<ol>
  <li>Initialize the Q-table with arbitrary values for all state-action pairs.</li>
  <li>Observe the current state.</li>
  <li>Select an action to take based on the current state and the values in the Q-table. This can be done using an exploration-exploitation strategy such as epsilon-greedy.</li>
  <li>Take the selected action and observe the reward and the new state. (a, r, s’)</li>
  <li>
    <p>Update the Q-value for the state-action pair that was just taken based on the observed reward and the maximum Q-value for the new state.</p>

    <p>The Q-learning algorithm uses the following equation to update the Q-value for a state-action pair:</p>

    <p>$Q(s,a) {\leftarrow} (1-\alpha)Q(s,a) + \alpha(  r + \gamma.\underset{a’}{max} \space Q(s’, a’))$</p>

    <p>Where:</p>

    <ul>
      <li>Q(s, a) is the Q-value for state s and action a</li>
      <li>α is the learning rate, which determines how much the Q-value is updated in each iteration</li>
      <li>r is the reward received for taking action a in state s</li>
      <li>γ is the discount factor, which determines the importance of future rewards</li>
      <li>$\underset{a’}{max} \space Q(s’, a’)$ is the maximum Q-value for the next state s’ and all possible actions a’ (maximum future reward estimate)</li>
      <li>s’ is the next state reached after taking action a in state s</li>
    </ul>
  </li>
  <li>Repeat 🔄 steps 2-5 until the algorithm converges or a maximum number of iterations is reached.</li>
</ol>

<p>The optimal policy 🏆 can be derived by selecting the action with the highest Q-value for each state as in Q-value Iteration algorithm.</p>

<p>Let’s implement Q-Learning algorithm using open AI gym environment (Taxi-v3). 🚕</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="nf">make</span><span class="p">(</span><span class="sh">'</span><span class="s">Taxi-v3</span><span class="sh">'</span><span class="p">)</span>

<span class="n">Q_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="n">env</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">n</span><span class="p">,</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span><span class="p">])</span>

<span class="c1"># exploration policy
</span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Exploration rate
</span>
<span class="k">def</span> <span class="nf">exploration_policy</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="nf">sample</span><span class="p">()</span>  <span class="c1"># Explore
</span>    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">])</span>  <span class="c1"># Exploit
</span></code></pre></div></div>

<p>Q-Learning algorithm with learning rate decay: ☢️</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Hyperparameters
</span><span class="n">alpha0</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Initial learning rate
</span><span class="n">decay</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>  <span class="c1"># Discount factor
</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">reset</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
    
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="nf">exploration_policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        
        <span class="c1"># Q-learning update
</span>        <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">episode</span> <span class="o">*</span> <span class="n">decay</span><span class="p">)</span>
        
        <span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">*=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span>
        <span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">+=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">Q_values</span><span class="p">[</span><span class="n">next_state</span><span class="p">]))</span>
        
        <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
</code></pre></div></div>

<p><img src="/assets/2024/September/Q_learning.png" alt="Fig: The Q-Value Iteration algorithm (left) versus the Q-Learning algorithm (don’t know anything) (right)" /></p>

<p><em>Fig: The Q-Value Iteration algorithm (left) versus the Q-Learning algorithm (don’t know anything) (right) <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">credit for image</a></em></p>

<p>Obviously, not knowing the transition probabilities or the rewards makes finding the optimal policy significantly harder!</p>

<h3 id="advantage">Advantage</h3>

<p>It can learn optimal policies without requiring a model of the environment. (Model-free reinforcement learning algorithm).  Instead, it learns directly from experience by updating the Q-values based on observed rewards and transitions between states.</p>

<h3 id="disadvantage">Disadvantage</h3>

<p>It can be computationally expensive and may require a large amount of data to converge to an optimal solution.</p>

<p>Overall, Q-learning is a powerful technique with many potential applications, but it is important to carefully consider the problem and the available data before choosing a Q-learning approach.</p>

<h2 id="references">References</h2>

<ol>
  <li>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Buy here</a></li>
</ol>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2024/09/15/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2024-09-15T15:08:10+05:30</published><updated>2024-09-15T15:08:10+05:30</updated><id>http://localhost:4000/jekyll/update/2024/09/15/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/09/15/welcome-to-jekyll.html"><![CDATA[<p>You’ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>Jekyll requires blog post files to be named according to the following format:</p>

<p><code class="language-plaintext highlighter-rouge">YEAR-MONTH-DAY-title.MARKUP</code></p>

<p>Where <code class="language-plaintext highlighter-rouge">YEAR</code> is a four-digit number, <code class="language-plaintext highlighter-rouge">MONTH</code> and <code class="language-plaintext highlighter-rouge">DAY</code> are both two-digit numbers, and <code class="language-plaintext highlighter-rouge">MARKUP</code> is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span></code></pre></figure>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll’s GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.]]></summary></entry><entry><title type="html">Just machine learning</title><link href="http://localhost:4000/ai/2023/10/29/Just_machine_learning.html" rel="alternate" type="text/html" title="Just machine learning" /><published>2023-10-29T15:08:10+05:30</published><updated>2023-10-29T15:08:10+05:30</updated><id>http://localhost:4000/ai/2023/10/29/Just_machine_learning</id><content type="html" xml:base="http://localhost:4000/ai/2023/10/29/Just_machine_learning.html"><![CDATA[<p>In this blog post, we’re going to talk about machine learning and its different types.</p>

<p>Artificial intelligence (AI) refers to machines that are programmed to learn and perform tasks that usually require human thinking, like recognizing images, understanding speech, making decisions, and translating languages.</p>

<p>Machine learning is a branch of AI that allows computers to learn and make predictions or decisions based on data. It uses algorithms and statistical models to analyze data, find patterns, and make predictions on new data.</p>

<h1 id="supervised-learning">Supervised Learning</h1>

<p>Supervised learning is a machine learning technique where a model is trained on labeled data. The model is presented with inputs and corresponding outputs, and it learns to make predictions based on those inputs.</p>

<p>This technique is used for tasks such as classification, regression, and prediction.</p>

<p>Some common types of supervised learning include:</p>

<ul>
  <li><strong>Classification:</strong> the model learns to classify inputs into different categories or classes.</li>
  <li><strong>Regression:</strong> the model learns to predict a continuous output based on the input.</li>
  <li><strong>Time Series Prediction:</strong> the model learns to make predictions based on time series data.</li>
  <li><strong>Anomaly Detection:</strong> the model learns to identify unusual or unexpected data points.</li>
</ul>

<h2 id="classification">Classification</h2>

<p>Classification is a type of supervised learning in machine learning where the model learns to put inputs into different categories or classes.</p>

<p>Examples → Image recognition, sentiment analysis, and speech recognition.</p>

<p>There are a bunch of algorithms that can be used for classification, including decision trees, random forests, and support vector machines (SVMs).</p>

<p>The choice of algorithm depends on the specific problem and the characteristics of the data. For example, decision trees are great for problems with just a few features, while SVMs are awesome when there are lots of features and the data isn’t linearly separable.</p>

<p>There are many algorithms that can be used for classification, including:</p>

<ul>
  <li>Decision trees</li>
  <li>Random forests (Ensemble method)</li>
  <li>Support vector machines (SVMs)</li>
  <li>Nearest neighbor</li>
  <li>K-nearest neighbors (KNN)</li>
  <li>Naive Bayes</li>
</ul>

<p>Let’s Discuss some of these techniques:</p>

<h3 id="decision-trees">Decision Trees</h3>

<p>Decision trees are a type of classification algorithm used in machine learning. They are especially handy for problems with just a few features and a ton of training examples.</p>

<p>The basic idea behind decision trees is to split up the input space into different regions, where each region represents a different class or category. This is done by recursively splitting up the input space over and over again based on the values of the input features.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>![Fig: Decision Tree](https://static.javatpoint.com/tutorial/machine-learning/images/decision-tree-classification-algorithm.png)

Fig: Decision Tree

At each level of the tree, the algorithm picks the input feature that separates the training examples into different classes the best. This feature is used to make a decision node, which splits the input space into two or more regions. The process is repeated on each of the resulting regions until a stopping criterion is met, like reaching the maximum depth or having a minimum number of examples in each region.

Decision trees are super easy to understand and interpret, and they can be used for both classifying and regression problems. They can also handle non-linear relationships between the input features and the target variable.

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

model = DecisionTreeClassifier(random_state=0)
model.fit(X_train, Y_train)

score = cross_val_score(model, X, Y, cv=10)
```

Decision trees can also be used for regression problems, where the goal is to predict a continuous output variable based on the input features. The decision tree algorithm works in the same way as for classification problems, but instead of predicting a class label, it predicts a numeric value.

Here is an example of a decision tree for a regression problem:

- **Regression Decision Tree**
    
    ![Fig: Regression Decision Tree](https://scikit-learn.org/stable/_images/sphx_glr_plot_tree_regression_001.png)
    
    Fig: Regression Decision Tree
    
    In this example, the decision tree is used to fit a sine curve as a result it learns linear regression approximating the sine curve. We can see in this example, that if max depth of the tree is set to high, it can overfit the training data by learning the noise observations also.
    
    The algorithm chooses the feature that results in the best split of the data based on a measure of the variance reduction. The prediction for each leaf node is the average of the target values of the training examples that fall within that leaf node.
    

However, decision trees can be sensitive to small changes in the input data and may overfit the training data if not properly regularized. To address these issues, ensemble methods such as random forests and gradient boosting are often used.

Overall, decision trees are a simple and effective technique for classification and regression problems, particularly when the decision boundary is simple or linear.
</code></pre></div></div>

<ul>
  <li>
    <p><strong>Nearest-neighbor classification</strong></p>

    <p>In this algorithm, the model given an input chooses the class of the nearest data point to that point.</p>

    <p>This technique is useful for problems where the decision boundary between classes is complex or nonlinear. However, it can be computationally expensive and may not perform well on high-dimensional data.</p>
  </li>
  <li>
    <p><strong>K-Nearest Neighbor Classification (KNN)</strong></p>

    <p>In this algorithm, the model assigns a class to a new data point based on the classes of the k nearest data points in the training data set. The value of k is a hyperparameter that can be tuned to optimize the model’s performance.</p>

    <p>This technique is often used for problems with a small number of classes and a large number of features. However, it can be sensitive to the choice of distance metric used to calculate the distance between data points.</p>

    <p><a href="https://miro.medium.com/v2/resize:fit:1100/0*ItVKiyx2F3ZU8zV5">Fig: KNN Example</a></p>

    <p>Fig: KNN Example</p>

    <p>Overall, k-nearest neighbor classification is a simple and effective technique for classification problems, particularly when the decision boundary is complex or nonlinear.</p>
  </li>
</ul>

<h3 id="regression">Regression</h3>

<p>Regression is a type of supervised learning in machine learning. It involves the use of algorithms and statistical models to predict a continuous output based on input data.</p>

<p>This is useful when trying to predict a value that falls within a range, such as the price of a house based on its size, location, and other factors.</p>

<p>Example → f(size, location, architecture) = price
                   f(1200, Delhi, 2 story building) = 1 million</p>

<h3 id="types-of-regression">Types of Regression</h3>

<p>There are several types of regression, including:</p>

<ul>
  <li>
    <p><strong>Linear Regression:</strong> the model learns to predict a continuous output based on a linear relationship between the input and output variables.</p>

    <p>!https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-in-machine-learning.png</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># using skitit learn
</span>  <span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Linear</span> <span class="n">Regression</span>
    
  <span class="n">model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    
  <span class="c1"># Print coefficients and accuracy
</span>  <span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
    
  <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Logistic Regression:</strong> the model learns to predict a binary output based on the input variables.</li>
  <li><strong>Polynomial Regression:</strong> the model learns to predict a continuous output based on a polynomial relationship between the input and output variables.</li>
  <li><strong>Ridge Regression:</strong> a regularization technique used to prevent overfitting in linear regression models.</li>
  <li><strong>Lasso Regression:</strong> a regularization technique used to prevent overfitting in linear regression models, but with a different approach than Ridge Regression.</li>
  <li><strong>Elastic Net Regression:</strong> a combination of Ridge and Lasso Regression, which balances their strengths and weaknesses.</li>
</ul>

<p>Each type of regression is suited for different types of data and problems, and choosing the right type of regression is an important part of building an accurate machine learning model.</p>

<p><strong>Logistic Regression</strong></p>

<p>Logistic regression is a type of supervised learning in machine learning that is used for binary classification tasks. In this technique, the model learns to predict a binary output (0 or 1) based on the input variables.</p>

<p>It is commonly used in applications such as fraud detection, spam filtering, and medical diagnosis.</p>

<p>The logistic regression algorithm uses a sigmoid function to map the input values to a range between 0 and 1 (generate probabilities), which represents the probability of the input data belonging to one of the two categories. The algorithm then makes a binary decision based on this probability.</p>

<p>!https://static.javatpoint.com/tutorial/machine-learning/images/logistic-regression-in-machine-learning.png</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Logistic Regression
</span><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">Y_test</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Ridge Regression</strong></p>

<p>Ridge regression is a type of linear regression that adds a regularization term (L2) to the cost function to prevent overfitting. The cost function for ridge regression is:</p>

<p>The Ridge Regression Equation is given by:</p>

<p>$J(w) = \sum_{i=1}^{m} [y^{(i)} - \hat{y}^{(i)}]^2 + \alpha\sum_{j=1}^{n} w_j^2$</p>

<p>where:</p>

<ul>
  <li>J(w) is the cost function</li>
  <li>m is the number of training examples</li>
  <li>n is the number of features</li>
  <li>y is the target variable</li>
  <li>w is the vector of coefficients</li>
  <li>α is the regularization parameter</li>
</ul>

<p>The first term in the equation is the mean squared error (MSE) between the predicted values and the true values. The second term is the L2 regularization term, which penalizes the magnitude of the coefficients.</p>

<p><strong>Lasso Regression</strong></p>

<p>Lasso regression is another type of linear regression that adds a regularization term (L1) to the cost function. The cost function for lasso regression is:</p>

<table>
  <tbody>
    <tr>
      <td>$J(w) = \sum_{i=1}^{m} [y^{(i)} - \hat{y}^{(i)}]^2 + \alpha\sum_{j=1}^{n}</td>
      <td>w_j</td>
      <td>$</td>
    </tr>
  </tbody>
</table>

<p>Where:</p>

<ul>
  <li>$J(w)$ is the cost function</li>
  <li>$m$ is the number of training examples</li>
  <li>$n$ is the number of features</li>
  <li>$y$ is the target variable</li>
  <li>$w$ is the vector of coefficients</li>
  <li>$\alpha$ is the regularization parameter (hyperparameter)</li>
</ul>

<p>The first term in the equation is the mean squared error (MSE) between the predicted values and the true values. The second term is the L1 regularization term, which penalizes the absolute value of the coefficients.</p>

<p>Lasso regression is useful for feature selection, as it tends to set the coefficients of less important features to zero. This can lead to a more interpretable model and improve its generalization performance.</p>

<h2 id="unsupervised-learning">Unsupervised Learning</h2>

<hr />

<p>Unsupervised learning is a type of machine learning where the model is trained on unlabeled data. The model is not given any specific outputs to learn from, but instead must identify patterns and relationships in the input data on its own.</p>

<p>This technique is used for tasks such as clustering, anomaly detection, and dimensionality reduction.</p>

<p>Some common types of unsupervised learning include:</p>

<ul>
  <li>
    <p><strong>Clustering:</strong> the model learns to group similar inputs into clusters or categories.</p>

    <p><a href="https://www.notion.so/But-how-you-do-clustering-d6b2d75d69204bf0a78f8df5548f7fc8?pvs=21">But how you do clustering?</a></p>
  </li>
  <li><strong>Anomaly Detection:</strong> the model learns to identify unusual or unexpected data points.</li>
  <li><strong>Dimensionality Reduction:</strong> the model learns to identify the most important features or variables in the input data.</li>
  <li><strong>Density estimation</strong> involves a model learning a probability density function (PDF), which is used in anomaly detection. Instances found in very-low density regions are considered anomalies.</li>
</ul>

<p><a href="https://www.notion.so/Gaussian-Mixtures-b0c8ae93678d4590a12aeb3e42f68240?pvs=21">Gaussian Mixtures</a></p>

<p>Unsupervised learning is useful when working with large amounts of data that may not be well understood or labeled. By identifying patterns and relationships in the data, unsupervised learning can help to uncover insights and guide further analysis.</p>

<h2 id="reinforcement-learning">Reinforcement learning</h2>

<hr />

<p><a href="https://www.notion.so/Learn-by-Reinforcement-e811c0c2b34c47abb946dc90b59749fe?pvs=21">Learn by Reinforcement</a></p>

<p><strong>Convergence Rate</strong></p>

<p>The convergence rate of a model refers to how quickly the model is able to converge to an optimal solution during training.</p>

<p>A faster convergence rate means that the model is able to reach a good solution more quickly, while a slower convergence rate means that the model may require more time and resources to reach a good solution.</p>

<p>The convergence rate can be affected by various factors, such as the choice of optimization algorithm, the learning rate, the size of the training data, and the complexity of the model architecture. A well-designed model with appropriate hyperparameters can achieve a faster convergence rate and better performance.</p>

<h2 id="ensemble-methods">Ensemble Methods</h2>

<hr />

<p>A group of predictors is called ensemble and an ensemble learning algorithm is called Ensemble method.</p>

<p>In other words, Ensemble methods are a type of machine learning technique that involve combining multiple models to improve their performance.</p>

<p>Ensemble has a similar bias but a lower variance than a single predictor trained on a the original training set.</p>

<p>There are several types of ensemble methods, including:</p>

<ul>
  <li>
    <p><strong>Bagging:</strong> the model combines the predictions of multiple models trained on different subsets of the training data. This can help to reduce overfitting and improve the accuracy of the model.</p>

    <p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/5989232b-4798-4c63-ac9f-04cb2f5fb1a8/48745c7a-5e51-4186-8452-6647e672a3f6/Untitled.png" alt="Fig: Bagging and pasting involves training several predictors on different random samples of the training set" /></p>

    <p>Fig: Bagging and pasting involves training several predictors on different random samples of the training set</p>

    <p>Bagging - sampling is performed with replacement (bootstrap=True)</p>

    <p>Pasting - sampling is performed without replacement (bootstrap=False)</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
  <span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
    
  <span class="n">bag_clf</span> <span class="o">=</span> <span class="nc">BaggingClassifier</span><span class="p">(</span>
      <span class="nc">DecisionTreeClassifier</span><span class="p">(),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
      <span class="n">max_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">bootstrap</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
  <span class="p">)</span>
  <span class="n">bag_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag_clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</code></pre></div>    </div>

    <p>n_estimators = number of decision trees</p>

    <p>max_samples = 100 training samples randomly sampled from training set</p>

    <p>bootstrap = True, with replacement</p>

    <p>n_jobs = number of CPU cores to use for training and predictions, -1 means use all available</p>

    <p>Bootstrapping introduces more diversity into the predictor, means it is more biased than pasting; but the diversity also means the predictors are less correlated and ensemble variance is reduced.</p>
  </li>
  <li>
    <p><strong>Boosting:</strong> the model combines the predictions of multiple weak models to create a strong model. This can help to improve the accuracy of the model and reduce bias.</p>
  </li>
  <li>
    <p><strong>Stacking:</strong> the model combines the predictions of multiple models using a meta-model (blender). This can help to improve the accuracy of the model and reduce overfitting.</p>

    <p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/5989232b-4798-4c63-ac9f-04cb2f5fb1a8/8984dd70-5bb4-482c-8329-825d5ce887ba/Untitled.png" alt="Fig: Aggregating predictions using a blending predictor" /></p>

    <p>Fig: Aggregating predictions using a blending predictor</p>
  </li>
</ul>

<p>Ensemble methods are particularly useful when working with complex data or when the performance of a single model is not sufficient. By combining the predictions of multiple models, ensemble methods can help to improve the accuracy and reliability of the model.</p>

<p>Some common ensemble methods include:</p>

<h3 id="random-forests"><strong>Random Forests</strong></h3>

<hr />

<p>Random Forest is an ensemble of Decision trees, generally trained via the bagging method (or sometimes pasting), typically with <em>max_samples</em> set to the size of training set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">rnd_clf</span> <span class="o">=</span> <span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rnd_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">y_pred_rf</span> <span class="o">=</span> <span class="n">rnd_clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</code></pre></div></div>

<p>Random Forest algorithm introduces extra randomness when growing trees; instead of searching for the best feature when splitting a node, it searches for the best feature among a random subset of features.</p>

<p><strong>Feature Importance</strong></p>

<p>Random forests allow us to measure the relative importance of each feature. Feature importance is calculated by how much tree nodes that use that use that feature reduce impurity on average.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># feature importance
</span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="sh">"</span><span class="s">feature_names</span><span class="sh">"</span><span class="p">],</span> <span class="n">rnd_clf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>

<span class="c1"># output
# sepal length (cm) 0.10109300798027078
# sepal width (cm) 0.031280365249363895
# petal length (cm) 0.3941268382545283
# petal width (cm) 0.47349978851583696
</span></code></pre></div></div>

<p>Random forests are particularly useful for high-dimensional data and problems with complex decision boundaries. They can also handle missing values and noisy data.</p>

<p>Overall, random forests are a powerful and versatile technique for solving a wide range of machine learning problems.</p>

<h3 id="adaboost"><strong>AdaBoost</strong></h3>

<hr />

<p>A type of boosting ensemble method used for classification problems. AdaBoost combines the predictions of multiple weak models using a weighted sum, where the relative weight of misclassified instances increased (boost).</p>

<p>The algorithm increases the relative weight of the misclassified training instances.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>

<span class="n">ada_clf</span> <span class="o">=</span> <span class="nc">AdaBoostClassifier</span><span class="p">(</span>
    <span class="nc">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
    <span class="n">algorithm</span><span class="o">=</span><span class="sh">"</span><span class="s">SAMME.R</span><span class="sh">"</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<span class="n">ada_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="gradient-boosting"><strong>Gradient Boosting</strong></h3>

<hr />

<p>A type of boosting ensemble method used for classification and regression problems. Gradient boosting tries to fit the new predictor to the residual errors (literally) made by the previous predictor.</p>

<p>The basic idea behind gradient boosting is to build a sequence of models, each of which tries to correct the errors of the previous models. The final prediction is the weighted sum of the predictions of all the models in the sequence.</p>

<p>For example, in a binary classification problem, the first model might predict the probability of the positive class for each example. The second model would then focus on the examples that were misclassified by the first model, and try to improve the predictions for those examples. The third model would then focus on the examples that were still misclassified by the first two models, and so on.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</code></pre></div></div>

<p>Gradient boosting with early stopping:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">xgboost</span>

<span class="n">xgb_reg</span> <span class="o">=</span> <span class="n">xgboost</span><span class="p">.</span><span class="nc">XGBRegressor</span><span class="p">()</span>
<span class="n">xgb_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">xgb_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
           <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)],</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">2</span>
           <span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">xgb_reg</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</code></pre></div></div>

<p>Gradient boosting is a powerful technique for improving the performance of machine learning models, particularly when working with complex data or when the performance of a single model is not sufficient. However, it can be computationally intensive and may require careful tuning of hyperparameters to achieve good performance.</p>

<p>Overall, ensemble methods are a powerful technique for improving the performance of machine learning models, and they are widely used in industry and research. However, it is important to carefully consider the problem and the available data before choosing an ensemble method.</p>

<p><a href="https://www.kaggle.com/code/dsmeena/ch-7-ensemble-learning-and-random-forests"></a></p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[In this blog post, we’re going to talk about machine learning and its different types.]]></summary></entry><entry><title type="html">Start a Webserver with aws</title><link href="http://localhost:4000/cloud/2023/10/22/Start-a-webserver-with-aws.html" rel="alternate" type="text/html" title="Start a Webserver with aws" /><published>2023-10-22T15:08:10+05:30</published><updated>2023-10-22T15:08:10+05:30</updated><id>http://localhost:4000/cloud/2023/10/22/Start-a-webserver-with-aws</id><content type="html" xml:base="http://localhost:4000/cloud/2023/10/22/Start-a-webserver-with-aws.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>In this blog, we are gonna try to create our own webserver in aws. We will follow operation Excellence principle by designing it failure by using multi-AZ architecture or extending it to more than 1 availability zones. We will use load balancer to uniformly distribute the requests coming to our webserver to different EC2 instances. and If you have a domain we will learn how to create DNS records so that your domain points to this newly created webserver. While doing all of this we will not forget the security principle of well-architected framework.</p>

<h3 id="create-an-ec2-instance">Create an EC2 Instance</h3>

<p>Let’s first create an EC2 instance to run our webserver. Amazon Elastic compute cloud (EC2) is a web service that provides resizable computing capacity in the cloud.</p>

<p>EC2 offers a wide range of <a href="https://aws.amazon.com/ec2/instance-types/">instance types</a> to cater to different workload requirements. Here are some commonly used EC2 instance types:</p>

<ul>
  <li>General Purpose Instances</li>
  <li>Compute-Optimized Instances</li>
  <li>Memory-Optimized Instances</li>
  <li>Storage-Optimized Instances</li>
</ul>

<p>For creating a new EC2 instance follow the steps</p>

<ol>
  <li>Go to EC2 service, then go instances and click Launch an Instance.</li>
  <li>Give a name to your instance and choose an ubuntu AMI (Amazon Machine Image), its similar to docker images.</li>
  <li>Choose an Instance type, there are different instance families including General Purpose, compute-optimized, memory-optimized and storage-optimized. For now just choose t2.micro.</li>
  <li>Amazon recommends to use a key pair to securely connect to your instance. If you already have one use that otherwise you can easily create a new one.</li>
  <li>Leave other settings to default.</li>
  <li>Then click Launch Instance.</li>
</ol>

<p><img src="/assets/2024/September/start%20ec2%20instance.png" alt="Fig: Creating a new EC2 Instance" /></p>

<p><em>Fig: Creating a new EC2 Instance</em></p>

<h3 id="set-up-a-web-server">Set up a web server</h3>

<p>For this connect to your EC2 instance, by choosing your newly created instance and then click on connect. Make sure it’s in running state.</p>

<p><img src="/assets/2024/September/connect%20to%20ec2%20instance.png" alt="Fig: Connecting to EC2 Instance" /></p>

<p><em>Fig: Connecting to EC2 Instance</em></p>

<p>After connecting, run the following commands:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt update
<span class="nb">sudo </span>apt upgrade

<span class="c"># This will instance apache web server</span>
<span class="nb">sudo </span>apt <span class="nb">install </span>apache2
</code></pre></div></div>

<p>If you see something like this after running upgrade, then you need to reboot your system. The different between rebooting and Start/stop is that on start/stop the hardware running your instance is changed but on rebooting the hardware is the same.</p>

<p><img src="/assets/2024/September/start%20ec2%20instance2.png" alt="Untitled" /></p>

<p>In the next screen, select via tab then click enter.</p>

<p><img src="/assets/2024/September/reboot%20instance.png" alt="Fig: Rebooting Instance" /></p>

<p><em>Fig: Rebooting Instance</em></p>

<p>Again connect to your instance and install the Apache webserver. If at this time you try to connect to your apache webserver via your EC2 pubic IP, it will be timed out.  because currently your EC2 instance does not allow http traffic.  For that we need to modify security group.</p>

<h3 id="using-security-group-as-firewall">Using security group as firewall</h3>

<p>Security groups in AWS are virtual firewalls that control inbound and outbound traffic for EC2 instances. They act as a protective layer around instances, allowing you to define rules that specify the protocols, ports, and IP ranges that are allowed to access the instances.</p>

<p>We will create a custom security group for our EC2 instance.  Inside EC2 service go to Network &amp; security panel and click on Create security group.</p>

<p>Add following inbound rules to the security group.</p>

<p><img src="/assets/2024/September/inbound%20rules.png" alt="Fig: Inbound rules to allow http traffic" /></p>

<p><em>Fig: Inbound rules to allow http traffic</em></p>

<p>To change add this newly created security group to your EC2 instance following the steps:</p>

<p>Instances → select instance → Action → security → change security group</p>

<p>Add the newly created security group and remove the old security group, then save it.</p>

<p><img src="/assets/2024/September/change%20security%20group.png" alt="Fig: Adding security group to EC2 instance" /></p>

<p><em>Fig: Adding security group to EC2 instance</em></p>

<p>Now, you will be able to send request to your webserver over http connection. To confirm, type the IPv4 address of your EC2 instance in browser and you will see the default Apache web server page.</p>

<p>Hooray, but that’s not it we are gonna do more than this to improve the architecture of our web server.</p>

<h3 id="create-backups-with-ami-snapshot">Create backups with AMI snapshot</h3>

<p>You can create the backup of your current webserver by creating an Image that contains all the information required to launch more EC2 instances with same configuration.</p>

<p>To create an image of your webserver follow the steps:</p>

<p>Instances → select Instance → Action → Image and templates → Create Image</p>

<p>Give some appropriate name to your image and keep the rest settings default. Click on create Image.</p>

<p>It will take some time to create the Image or we can say Amazon Machine Image (AMI). You will be able to check this AMI under AMI section of EC2 instance.</p>

<p><img src="/assets/2024/September/create%20ami%20snapshot.png" alt="Fig: Amazon Machine Images" /></p>

<p><em>Fig: Amazon Machine Images</em></p>

<p>After the status is changed to Available, click on Launch Instance from AMI to create your duplicate web servers. Prefer to select same key-pair, security group and under network settings choose a subnet (Availability zone) other than that your current EC2 instance is using to design for failures.</p>

<p><img src="/assets/2024/September/create%20new%20instance%20from%20ami.png" alt="Fig: Creating new instance from AMI" /></p>

<p><em>Fig: Creating new instance from AMI</em></p>

<p>After this you will have 2 EC2 instances running your webserver in two different availability zones. You can create as many as you want but for now let’s keep it two and try some more things.</p>

<p>If you try to access the IPv4 of your new instance, you will see the default Apache page.</p>

<h3 id="scaling-with-elastic-load-balancer-elb">Scaling with Elastic Load Balancer (ELB)</h3>

<p>We will create an Elastic Load balancer (ELB) to uniformly route the incoming requests to healthy instances.</p>

<p>There are three types of load balancers that AWS provides:</p>

<ol>
  <li><strong>Application Load Balancer (ALB)</strong>: This load balancer operates at the application layer and is best suited for applications that require advanced routing capabilities. It can distribute traffic based on URL paths or HTTP headers, making it ideal for routing requests to different microservices or handling multiple domains. ALBs are commonly used for web applications, API gateways, and container-based architectures.</li>
  <li><strong>Network Load Balancer (NLB)</strong>: This load balancer operates at the transport layer (Layer 4) and is designed for applications that require ultra-high performance and low latency. It can handle extremely high volumes of traffic and is suitable for TCP/UDP-based applications, gaming, and real-time streaming.</li>
  <li><strong>Gateway Load Balancer (GLB)</strong>: This load balancer is designed to handle traffic at the edge of the AWS network and is used for scenarios where you need to distribute traffic across multiple virtual appliances, such as firewalls, intrusion detection systems, or deep packet inspection systems.</li>
</ol>

<p>For our task application load balancer is best choice. To create ALB go to EC2 dashboard then to Load Balancing section.</p>

<ol>
  <li>Click on Create new load balancer.</li>
  <li>Choose Application load balancer.</li>
  <li>Add security group that allows inbound traffic over internet.</li>
  <li>
    <p>Create a target group and add the EC2 instances → Include as pending below → Register pending targets.</p>

    <p><img src="/assets/2024/September/register%20target%20group.png" alt="Untitled" /></p>
  </li>
  <li>
    <p>Click Create Load balancer.</p>

    <p><img src="/assets/2024/September//create%20load%20balancer.png" alt="Fig: Application load balancer" /></p>

    <p><em>Fig: Application load balancer</em></p>
  </li>
</ol>

<p>If you go to the DNS name of the elb, you will be routed to one of the healthy EC2 instances.</p>

<p>But this domain doesn’t look good, if you already have a domain or want to buy a domain in that case you use Route 53.</p>

<h3 id="route-53">Route 53</h3>

<p>Amazon Route 53 is a highly available and scalable Domain Name System (DNS) web service.</p>

<p>You can buy a domain from here also in around $12.</p>

<p>Pricing:</p>

<ul>
  <li>$0.50 per hosted zone / month for the first 25 hosted zones</li>
  <li>$0.10 per hosted zone / month for additional hosted zones</li>
</ul>

<p>If hosted zone deleted within 12 hours of creation then no charge.</p>

<h3 id="create-a-hosted-zone">Create a Hosted zone</h3>

<p>In Amazon Route 53, a hosted zone is a container for a collection of DNS records that define how domain names are resolved. It is a way to manage the DNS records for a domain. Each hosted zone represents a domain and contains the DNS records that specify how traffic for that domain is routed.</p>

<p>Create a hosted zone by going to Route 53 → Hosted zones. In the domain add you own domain like <a href="http://abc.com">abc.com</a> Keep the rest default and click create Hosted zone.</p>

<p><img src="/assets/2024/September/create%20hosted%20zone.png" alt="Fig: Hosted zone for my website" /></p>

<p><em>Fig: Hosted zone for my website</em></p>

<p>Nameservers are part of the Domain Name System (DNS) infrastructure and are responsible for translating domain names into IP addresses</p>

<p>Replace your domain name server urls with hosted zone urls.</p>

<p><img src="/assets/2024/September/hostinger.png" alt="Fig: Added Route 53 Name servers" /></p>

<p><em>Fig: Added Route 53 Name servers</em></p>

<p>It might take few hours until the changes reflect for your domain. Till then lets add the record for our ALB.</p>

<p>1st record: It will point to the application load balancer.</p>

<p><img src="/assets/2024/September/create%20record.png" alt="Untitled" /></p>

<p>Create another record with subdomain www, this will point to the our first record.</p>

<p><img src="/assets/2024/September/create%20another%20record.png" alt="Fig: Creating record with www. and routing to dsm-blogs.in" /></p>

<p><em>Fig: Creating record with www. and routing to dsm-blogs.in</em></p>

<p>Now, if you try to access your domain you will see the default Apache web server page.</p>

<p><img src="/assets/2024/September/apache%20running.png" alt="Fig: Now, [dsm-blogs.in](http://dsm-blogs.in) is point to lba which directs to one of EC2 instances" /></p>

<p>Fig: Now, <a href="http://dsm-blogs.in">dsm-blogs.in</a> is point to lba which directs to one of EC2 instances</p>

<p>Hurray, we come really far starting from just EC2 instance to our own domain.</p>

<p>That’s enough for this blog post. We will continue developing our webserver in future blog posts, by adding storage services like EBS, EFS and S3 and distributing content with CloudFront. Our aim is better understand the usage of services and when to use which service for our application.</p>

<p>Hope you learnt something useful from this blog. See ya in next blog posts ❤️❤️.</p>]]></content><author><name></name></author><category term="cloud" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Advancing in Git</title><link href="http://localhost:4000/web/2023/09/23/Advancing-git.html" rel="alternate" type="text/html" title="Advancing in Git" /><published>2023-09-23T15:08:10+05:30</published><updated>2023-09-23T15:08:10+05:30</updated><id>http://localhost:4000/web/2023/09/23/Advancing-git</id><content type="html" xml:base="http://localhost:4000/web/2023/09/23/Advancing-git.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>This blog post discusses intermediate techniques for using Git, a version control system commonly used in software development. Topics covered include branch management, interactive staging, cherry-picking commits, creating and applying diff patches, and rebasing. The post also explains the use of pre-receive hooks and the Git Rerere feature.</p>

<h2 id="branch-management">Branch Management</h2>

<h3 id="git-reset">Git reset</h3>

<p>If you’re using Git and you need to undo changes you made to files, you can use the <code class="language-plaintext highlighter-rouge">git reset</code> command. Basically, it resets your working directory and staging area to a previous commit. So, let’s say you made some changes to files that you haven’t committed yet, you can undo those changes with <code class="language-plaintext highlighter-rouge">git reset</code>.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git reset</td>
      <td>reset your working directory and staging area to a previous commit</td>
    </tr>
    <tr>
      <td>git reset –soft HEAD^</td>
      <td>reset your working directory to the previous commit but keep your changes in the staging area</td>
    </tr>
    <tr>
      <td>git reset –hard HEAD^</td>
      <td>reset both your working directory and staging area to the previous commit</td>
    </tr>
    <tr>
      <td>git reset <file></file></td>
      <td>unstage a file that you accidentally added to the staging area</td>
    </tr>
    <tr>
      <td>git clean -f</td>
      <td>remove untracked files</td>
    </tr>
    <tr>
      <td>git rm –cached testfile.js</td>
      <td>no longer track the file</td>
    </tr>
    <tr>
      <td>git restore –staged file.txt</td>
      <td>unstage the changes made to file</td>
    </tr>
    <tr>
      <td>git restore file.txt</td>
      <td>restore the file to its previous state</td>
    </tr>
  </tbody>
</table>

<p>Just keep in mind that <code class="language-plaintext highlighter-rouge">git reset</code> can be a bit risky since it can permanently discard changes and commits. So be careful when using it, alright?</p>

<h3 id="fetch">Fetch</h3>

<p><code class="language-plaintext highlighter-rouge">git fetch</code> is a command in Git that downloads new changes from a remote repository without merging them into the local branch. It updates the remote-tracking branch, which is a local branch that tracks changes in the remote repository.</p>

<p>After running <code class="language-plaintext highlighter-rouge">git fetch</code>, you can use <code class="language-plaintext highlighter-rouge">git merge</code> or <code class="language-plaintext highlighter-rouge">git rebase</code> to integrate the changes from the remote repository into your local branch. Alternatively, you can use <code class="language-plaintext highlighter-rouge">git checkout</code> to switch to the remote-tracking branch and inspect the changes without merging them.</p>

<p><code class="language-plaintext highlighter-rouge">git fetch</code> is a useful command to use when collaborating with others on a project. It allows you to keep your local repository up-to-date with changes made by others, without affecting your working directory.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git fetch</td>
      <td>Downloads new changes from a remote repository without merging them into the local branch.</td>
    </tr>
    <tr>
      <td>git fetch –tags</td>
      <td>Fetches all tags from the remote repository that are not already present in the local repository.</td>
    </tr>
    <tr>
      <td>git fetch –prune</td>
      <td>Deletes any remote-tracking branches that are no longer on the remote repository.</td>
    </tr>
    <tr>
      <td>git fetch -p</td>
      <td>Shortcut for <code class="language-plaintext highlighter-rouge">git fetch --prune</code>.</td>
    </tr>
  </tbody>
</table>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># command to overwrite of your local files with the master branch</span>
git fetch <span class="nt">--all</span>
git reset <span class="nt">--hard</span> origin/master
</code></pre></div></div>

<p>The git amend command allows you to modify the most recent commit on your branch. You can use it to add changes you forgot to include in the commit, or to modify the commit message. When you run <code class="language-plaintext highlighter-rouge">git commit --amend</code>, Git will open up your default text editor and allow you to edit the commit message. Once you save and close the editor, the commit message on your most recent commit will be updated.</p>

<p>If you have staged changes that were not included in the previous commit, running <code class="language-plaintext highlighter-rouge">git commit --amend</code> will add those changes to the previous commit. You can also use the <code class="language-plaintext highlighter-rouge">-m</code> flag to modify the commit message without opening the text editor.</p>

<p>To remove a file from the previous commit, you can use <code class="language-plaintext highlighter-rouge">git rm --cached &lt;file&gt;</code> and then run <code class="language-plaintext highlighter-rouge">git commit --amend</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># change the previous commit</span>
git add
git commit <span class="nt">--amend</span> <span class="c"># will add the staged changes to previous commit</span>

git commit <span class="nt">--amend</span> <span class="nt">-m</span> <span class="s2">"New commit message"</span>  <span class="c"># modify commit message</span>

<span class="c"># remove file from staging </span>
git <span class="nb">rm</span> <span class="nt">--cached</span> testfile.js    <span class="c"># no longer tracked</span>
</code></pre></div></div>

<h3 id="force-push-to-a-remote">Force push to a remote</h3>

<p>Reasons to use force push:</p>

<ul>
  <li>Local version is preferable to the remote version</li>
  <li>The remote version went wrong and needs repair</li>
  <li>Versions have diverged and merging is undesirable</li>
  <li>Force push replaces the remote branch with your local branch</li>
  <li>Use with caution</li>
  <li>Commits may disappear</li>
  <li>It can be disruptive for others using the remote branch</li>
  <li>It’s an easy way to frustrate your development team</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push -f</code> or <code class="language-plaintext highlighter-rouge">git push --force</code></td>
      <td>Force push the changes to the remote repository, replacing the commits that are already there and not in the local repository.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push --force-with-lease</code></td>
      <td>Allow force push if no one else has pushed changes to that branch since you pulled.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git commit -am "Add salsa to shopping list"</code></td>
      <td>Automatically add changed files to the staging area and add the message.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git log</code></td>
      <td>Show the commits in the local repository.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git log origin/main</code></td>
      <td>Show the commits in the <code class="language-plaintext highlighter-rouge">origin/main</code> branch.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git show origin/main</code></td>
      <td>Show the changes done in commits in the <code class="language-plaintext highlighter-rouge">origin/main</code> branch.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git reset --hard origin/main</code></td>
      <td>Replace the local repository with the remote repository. Collaborators can use this command to replace their local repository with the remote repository.</td>
    </tr>
  </tbody>
</table>

<h3 id="identify-merged-branches">Identify Merged branches</h3>

<p>Here’s a cool trick for Git! You can use the command <code class="language-plaintext highlighter-rouge">git branch --merged</code> to see which branches have been merged into your current branch. This is really useful if you want to keep track of what features have been incorporated or if you need to do some cleanup after merging a bunch of features. By default, the command uses your current branch, but you can specify other branch names or commits too. Basically, it shows you all the branches whose tips are reachable from the specified commit (or HEAD if you don’t specify anything). So, if you’re working on a project with multiple branches, give this command a try!</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git branch –merged</td>
      <td>List branches that have been merged to the current branch</td>
    </tr>
    <tr>
      <td>git branch –no-merged</td>
      <td>List branches that haven’t been merged to the current branch</td>
    </tr>
    <tr>
      <td>git branch -r –merged</td>
      <td>Show results for remote branches that have been merged</td>
    </tr>
    <tr>
      <td>git merge main</td>
      <td>Merge the main branch into the current branch</td>
    </tr>
    <tr>
      <td>git branch –merged july_release</td>
      <td>Show what branches are merged into the specified branch</td>
    </tr>
    <tr>
      <td>git branch –merged origin/july_release</td>
      <td>Show what branches are merged into the specified remote branch</td>
    </tr>
    <tr>
      <td>git branch –merged b325a7c49</td>
      <td>Show what branches have this commit</td>
    </tr>
  </tbody>
</table>

<h3 id="prune-stale-branches">Prune Stale Branches</h3>

<p>To keep your Git repository organized, it’s important to delete stale branches. A stale branch is a remote-tracking branch that no longer tracks anything because the actual branch in the remote repository has been deleted. To delete a remote branch, you must also delete your remote-tracking branch. However, if another collaborator deletes a remote branch, your remote-tracking branch remains. Fetching does not automatically delete remote-tracking branches, so you must manually prune them.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git branch -d bugfix</code></td>
      <td>Delete local branch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push -d origin bugfix</code></td>
      <td>Delete remote branch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git remote prune origin</code></td>
      <td>Delete stale remote-tracking branches</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git remote prune origin --dry-run</code></td>
      <td>Demo which branch would be pruned or removed</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git branch -r</code></td>
      <td>Show remote-tracking branches</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git fetch --prune</code> or <code class="language-plaintext highlighter-rouge">git fetch -p</code></td>
      <td>Shortcut to prune, then fetch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git config --global fetch.prune true</code></td>
      <td>Always prune before fetch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git prune</code></td>
      <td>Prune all unreachable objects</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git gc</code></td>
      <td>Part of garbage collection</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git prune --expire &lt;time&gt;</code></td>
      <td>Prune unreachable objects older than specified time</td>
    </tr>
  </tbody>
</table>

<h2 id="taging">Taging</h2>

<h3 id="create-tags">Create Tags</h3>

<p>Tags in Git are like bookmarks, marking important points in the history of a repository. They can be used to mark software versions or to highlight key features or changes. You can also use tags to mark points for discussion with collaborators, like bugs or issues. So, if you’re working on a project in Git, don’t forget to use tags to help keep track of important points in your repository’s history!</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git tag issue_136 655da716e7</code></td>
      <td>Add lightweight tag (using hash or branch name)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git tag -am "Version 1.0" v1.0 dd5c49428a0</code></td>
      <td>Add annotated tag (most common)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git tag -d v1.0</code> or <code class="language-plaintext highlighter-rouge">git tag --delete v1.0</code></td>
      <td>Delete a tag</td>
    </tr>
  </tbody>
</table>

<h3 id="list-tags">List Tags</h3>

<p>| Command | Description |
| — | — |
| git tag
git tag –list
git tag -l | List tags alphabetically |
| git tag -l “v2*” | List tags beginning with “v2” |
| git tag -n | List tags with first line of each annotation |
| git tag -n5 | List tags with five lines of each annotation |
| git show v1.1 | Show changes made in the commits tagged with v1.1 |
| git diff v1.0..v1.1 | Show all differences from v1.0 to v1.1 |
| git switch v1.0 | Switch to the commit or branch labeled as v1.0 |
| git switch -c branch_v1 v1.0 | Create a new branch from a tag |</p>

<h3 id="push-tags-to-a-remote">Push Tags to a Remote</h3>

<p>Like branches, tags are local unless shared to a remote. Git push does not transfer tags, so they must be explicitly transferred. However, git fetch automatically retrieves shared tags. So, if you’re collaborating with others on a project, make sure to share your tags to keep everyone in the loop!</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push origin v1.0</code></td>
      <td>Push a tag to a remote repository</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push origin --tags</code></td>
      <td>Push all tags to a remote repository</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git fetch</code></td>
      <td>Fetch commits and tags</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git fetch --tags</code></td>
      <td>Fetch only tags (with necessary commits) (rarely used)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push -d origin v1.0</code></td>
      <td>Delete remote tags like remote branches</td>
    </tr>
  </tbody>
</table>

<h2 id="interactive-staging">Interactive Staging</h2>

<h3 id="interactive-mode">Interactive Mode</h3>

<p>Interactive staging is a cool feature in Git that lets you pick and choose which changes you want to stage. This means you can make smaller, focused commits and avoid committing changes you’re not sure about. It’s also a feature of many Git GUI tools. So, next time you’re using Git, give interactive staging a try!</p>

<p>To enter into interactive mode, use:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git add <span class="nt">-i</span>
git add <span class="nt">--interactive</span>
</code></pre></div></div>

<p><img src="/assets/2024/September/interactive%20mode.png" alt="Untitled" /></p>

<p>In interactive mode, you can stage changes, unstage changes, and add untracked files. You can choose options either by clicking on the corresponding number or the first letter of the option:</p>

<ul>
  <li>s: Status of the repository</li>
  <li>u: Add files to the staging area</li>
  <li>r: Remove files from the staging area</li>
  <li>a: Add untracked files</li>
  <li>d: Differences in file</li>
  <li>q: Quit interactive mode</li>
  <li>h: Help</li>
</ul>

<h3 id="patch-mode">Patch mode</h3>

<p>In Git, you can pick and choose which changes you want to stage using interactive staging. This means you can make smaller, focused commits and avoid committing changes you’re not sure about. You can stage each hunk (chunk of changes) separately. It’s really useful!</p>

<p>To enter patch mode, go to interactive mode and enter “p”, followed by the file number.</p>

<p><img src="/assets/2024/September/patch%20mode.png" alt="Untitled" /></p>

<p>Other ways to use patch mode</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git add –patch or git add -p</td>
      <td>Interactively choose which changes you want to add to the staging area.</td>
    </tr>
    <tr>
      <td>git stash -p</td>
      <td>Interactively choose which changes you want to stash.</td>
    </tr>
    <tr>
      <td>git reset -p</td>
      <td>Interactively choose which changes you want to unstage.</td>
    </tr>
    <tr>
      <td>git restore -p</td>
      <td>Interactively choose which changes you want to discard from your working directory.</td>
    </tr>
    <tr>
      <td>git commit -p</td>
      <td>Interactively choose which changes you want to include in your commit.</td>
    </tr>
  </tbody>
</table>

<h3 id="split-a-hunk">Split a Hunk</h3>

<p>When using Git’s interactive staging feature, you can split a hunk further by using the “s” option in patch mode. This is useful when a hunk contains multiple changes and requires one or more unchanged lines between them.</p>

<h3 id="edit-a-hunk">Edit a Hunk</h3>

<p>When editing a hunk in Git, you can do it manually if needed. This is especially useful when a hunk cannot be split automatically. However, make sure to pay attention to the prefixes (+, -, space) while editing, or the hunk might not be staged correctly. So, take your time and give them the respect they deserve!</p>

<h2 id="share-select-changes">Share Select Changes</h2>

<h3 id="cherry-picking-commits">Cherry-Picking Commits</h3>

<p>Cherry-picking commits is like copying and pasting code from one branch to another. Each commit becomes a new commit on the current branch, and they’ll have different SHA codes. You can cherry-pick commits from any branch, but you can’t do it with merge commits. You can use the –edit or -e flag to edit the commit message if you need to. However, conflicts can arise that you’ll need to resolve. It’s a useful feature to have in your Git toolkit!</p>

<p><img src="/assets/2024/September/cherry%20pick.png" alt="Untitled" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git cherry-pick d4e8411d09
git cherry-pick d438411d09..57d290ec44
</code></pre></div></div>

<p>Resolve cherry-picking conflicts is similar to resolving merge conflicts. Just edit in editor and try again!</p>

<h3 id="diff-patches">Diff Patches</h3>

<p>If you want to share changes with collaborators but the changes aren’t ready for a public branch or your collaborators don’t share a remote, you can use diff patches to share the changes via files. It’s useful for discussing bugs or issues with collaborators or for sharing changes that need further testing before merging into the main branch.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff from-commit to-commit <span class="o">&gt;</span> output.diff
</code></pre></div></div>

<p>Use following common to apply changes in a diff patch file to the working directory. But remember, apply diff patches does not transfer commit history.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git apply output.diff 
</code></pre></div></div>

<h3 id="formatted-patches">Formatted Patches</h3>

<p>In Git, you can export each commit in Unix mailbox format using formatted patches. It’s a great way to distribute changes via email and includes commit messages. You can apply formatted patches using the <code class="language-plaintext highlighter-rouge">git am</code> command. It’s similar to cherry-picking, which copies and pastes code from one branch to another. However, formatted patches are better for sharing changes that aren’t ready for a public branch or when collaborators don’t share a remote. Keep in mind that applying formatted patches transfers the commit history.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch 2e33d..655da</code></td>
      <td>Creates patch files for all commits in the range</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch main</code> or <code class="language-plaintext highlighter-rouge">git format-patch main..HEAD</code></td>
      <td>Creates patch files for all commits on the current branch that are not in the <code class="language-plaintext highlighter-rouge">main</code> branch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-path -1 655da</code></td>
      <td>Creates a patch file for a single commit with hash <code class="language-plaintext highlighter-rouge">655da</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch 2e33d..655da -o ~/feature_patches</code></td>
      <td>Creates patch files for all commits in the range and puts them into a directory named <code class="language-plaintext highlighter-rouge">feature_patches</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch 2e33d..655da --stdout &gt; feature.patch</code></td>
      <td>Outputs patch files as a single file named <code class="language-plaintext highlighter-rouge">feature.patch</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git am feature/0001-some-name.patch</code></td>
      <td>Applies a single patch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git am feature/*.patch</code></td>
      <td>Applies all patches in a directory</td>
    </tr>
  </tbody>
</table>

<p>In the command <code class="language-plaintext highlighter-rouge">git am feature/*.patch</code>, <code class="language-plaintext highlighter-rouge">am</code> stands for “apply mailbox”. This command applies a mailbox-style patch to the current branch.</p>

<h2 id="rebasing">Rebasing</h2>

<h3 id="rebase-commits">Rebase Commits</h3>

<p>Rebasing is a way to move commits from one branch to another. It’s useful when you want to integrate recent commits without merging and to maintain a clearer, more linear project history. It also ensures that topic branch commits apply cleanly. So, if you’re working on a project and want to keep your commits organized, give rebasing a try!</p>

<p><img src="/assets/2024/September/rebase.svg" alt="Untitled" /></p>

<p><em>Fig: Rebasing Feature branch <a href="www.atlassian.com">Credit</a></em></p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git rebase main</td>
      <td>Rebase current branch on tip of main (from feature branch)</td>
    </tr>
    <tr>
      <td>git rebase main new_feature</td>
      <td>Rebase new_feature to tip of main (from main)</td>
    </tr>
    <tr>
      <td>git rebase –onto newbase upstream branch</td>
      <td>Rebase branch onto newbase</td>
    </tr>
    <tr>
      <td>git rebase –onto target main new_feature</td>
      <td>Rebase new_feature commits on target branch that are not on main (merged)</td>
    </tr>
  </tbody>
</table>

<h4 id="handle-rebase-conflicts">Handle Rebase Conflicts</h4>

<p>When you rebase commits, it can cause conflicts with existing code. Git will pause the rebase before each conflicting commit, and you’ll need to resolve the conflicts. This process is similar to resolving merge conflicts. It’s important to be patient and take your time to ensure that the conflicts are resolved correctly.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git rebase –continue</td>
      <td>Continue the rebase after resolving conflicts</td>
    </tr>
    <tr>
      <td>git rebase –skip</td>
      <td>Skip the current commit during the rebase process</td>
    </tr>
    <tr>
      <td>git log –graph –all –decorate –oneline</td>
      <td>Visualize the branch history as a graph</td>
    </tr>
    <tr>
      <td>git merge-base main new_feature</td>
      <td>Return the commit SHA where the topic branch diverges from main</td>
    </tr>
    <tr>
      <td>git rebase -i</td>
      <td>Open an interactive rebase prompt to choose which commits to move</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/2024/September/diverges.png" alt="Fig: The branch test diverges from main" /></p>

<p><em>Fig: The branch test diverges from main</em></p>

<h3 id="merging-vs-rebasing">Merging vs. Rebasing</h3>

<ul>
  <li>Two ways to incorporate changes from one branch into another branch</li>
  <li>Similar ends but the means are different</li>
  <li>Side effects are important to understand</li>
</ul>

<p><img src="https://www.edureka.co/blog/wp-content/uploads/2022/01/fig13.png" alt="Edureak" />
<em>Fig: Git Merge vs Git Rebase <a href="">Credit: Edureka</a></em></p>

<table>
  <thead>
    <tr>
      <th>Merging</th>
      <th>Rebasing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Adds a merge commit</td>
      <td>No additional merge commit</td>
    </tr>
    <tr>
      <td>Nondestructive</td>
      <td>Destructive: SHA changes, commits are rewritten</td>
    </tr>
    <tr>
      <td>Complete record of what happened and when</td>
      <td>No longer a complete record of what happened and when</td>
    </tr>
    <tr>
      <td>Easy to undo</td>
      <td>Tricky to undo</td>
    </tr>
    <tr>
      <td>Logs can become cluttered and nonlinear</td>
      <td>Logs are cleaner and more linear</td>
    </tr>
  </tbody>
</table>

<p><strong>The Golden Rule of Rebasing</strong></p>

<ul>
  <li>Thou Shalt not rebase a public branch</li>
  <li>Rebase abandons existing, shared commits and creates new, similar commits instead</li>
  <li>Collaborators would see project history vanish</li>
  <li>Getting all collaborators back in sync can be hassle</li>
</ul>

<p><strong>How to Choose</strong></p>

<ul>
  <li>Merge to allow commits to stand out or to be clearly grouped</li>
  <li>Merge to bring large topic branches back into main</li>
  <li>Rebase to add minor commits in main to a topic branch</li>
  <li>Rebase to move commits from one branch to another</li>
  <li>Merge anytime the topic branch is already public and being used by others (The Golden Rule of Rebasing).</li>
</ul>

<h3 id="interactive-rebasing">Interactive Rebasing</h3>

<p>Interactive rebasing is a feature in Git that allows you to modify commits as they’re being replayed. When you run <code class="language-plaintext highlighter-rouge">git rebase -i</code>, Git will open up the git-rebase-todo file for editing. In this file, you can reorder, skip, or edit commits. The options available to you in interactive rebasing include:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">pick</code>: include the commit</li>
  <li><code class="language-plaintext highlighter-rouge">drop</code>: remove the commit</li>
  <li><code class="language-plaintext highlighter-rouge">reword</code>: edit the commit message</li>
  <li><code class="language-plaintext highlighter-rouge">edit</code>: pause the rebasing process to allow you to make changes to the commit</li>
  <li><code class="language-plaintext highlighter-rouge">squash</code>: combine the commit with the one immediately before it</li>
  <li><code class="language-plaintext highlighter-rouge">fixup</code>: combine the commit with the one immediately before it, but discard its commit message</li>
</ul>

<p>Interactive rebasing is useful when you want to modify the history of a branch before sharing it with others. It can also be helpful for cleaning up your commit history by grouping related changes or removing unnecessary commits. However, be careful when using interactive rebasing, as it can be risky if not done properly. It’s always a good idea to make a backup copy of your branch before rebasing it.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Interactive rebase</span>
git rebase <span class="nt">-i</span> main new_feature

<span class="c"># Rebase last three commits onto the same branch</span>
<span class="c"># but with the opportunity to modify them</span>
git rebase <span class="nt">-i</span> HEAD~3
</code></pre></div></div>

<p><img src="/assets/2024/September/rebase.png" alt="Untitled" /></p>

<h3 id="squash-commits">Squash Commits</h3>

<p>Squash commits is a way to combine multiple commits into one. It’s useful for when you have several small commits that are related to each other and you want to make them into a single, cohesive commit. This can help to keep your commits organized and make it easier to understand the history of your code.</p>

<p>When squashing commits, you’ll take the changes from each commit and combine them into a single commit. The commit message for the new commit will be a combination of the commit messages from the original commits. You can use the <code class="language-plaintext highlighter-rouge">git rebase -i</code> command to interactively rebase your branch and squash commits.</p>

<p>To squash commits, follow these steps:</p>

<ol>
  <li>Use <code class="language-plaintext highlighter-rouge">git log</code> to find the SHA IDs of the commits you want to squash.</li>
  <li>Use <code class="language-plaintext highlighter-rouge">git rebase -i HEAD~&lt;number of commits&gt;</code> to start an interactive rebase.</li>
  <li>In the interactive rebase, change <code class="language-plaintext highlighter-rouge">pick</code> to <code class="language-plaintext highlighter-rouge">squash</code> for the commits you want to squash. You can also edit the commit messages if needed.</li>
  <li>Save and close the file to complete the rebase.</li>
</ol>

<p>After squashing the commits, you’ll have a single commit that contains all the changes from the original commits. This can be helpful for keeping your commit history clean and organized, especially when collaborating with others on a project.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Rebase last four commits onto the same branch</span>
<span class="c"># but with the opportunity to modify them</span>
git rebase <span class="nt">-i</span> HEAD~4

pick 81a73ff Redesign
squash b2baf90 Change image sizes
fixup c0261b3 Bug fix to the design
squash 0f7760e Adjust styles
</code></pre></div></div>

<h3 id="pull-rebase">Pull Rebase</h3>

<p>Pull rebase is a way to fetch changes from a remote repository and then rebase them onto the local branch instead of merging them. This helps to keep the commit history cleaner by reducing the number of merge commits. However, it should only be used for local commits that are not shared to a remote branch.</p>

<p><img src="https://media.geeksforgeeks.org/wp-content/uploads/20200415234509/Rebasing-in-git.png" alt="" /></p>

<p><em>Fig: Rebasing <a href="geeksforgeeks.org">Credit: GFG</a></em></p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull -r</code></td>
      <td>Pull with rebase</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull --rebase</code></td>
      <td>Pull with rebase</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull --rebase=preserve</code></td>
      <td>Pull with rebase and preserve merge commits</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull --rebase=interactive</code></td>
      <td>Pull with interactive rebase</td>
    </tr>
  </tbody>
</table>

<h2 id="track-down-problems">Track Down Problems</h2>

<h3 id="log-options">Log Options</h3>

<p><code class="language-plaintext highlighter-rouge">git log</code> is a command in Git that displays the commit history for a repository. It shows the SHA-1 hash, author, date, and commit message for each commit in reverse chronological order. By default, it shows the entire commit history for the current branch.</p>

<p>However, there are many options to customize the output, such as sorting, filtering, and formatting. Some common options are <code class="language-plaintext highlighter-rouge">--oneline</code> to show each commit on one line, <code class="language-plaintext highlighter-rouge">--graph</code> to display the commit history as a graph, and <code class="language-plaintext highlighter-rouge">--since</code> or <code class="language-plaintext highlighter-rouge">--until</code> to filter the commit history by date. You can also use <code class="language-plaintext highlighter-rouge">git log</code> to show the commit history for a specific file or directory, or to show the changes made by a specific commit.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git log filename.txt</td>
      <td>List commits that changed filename.txt</td>
    </tr>
    <tr>
      <td>git log -p or git log –patch</td>
      <td>List commits as patches (with diffs)</td>
    </tr>
    <tr>
      <td>git log -L 100,150:filename.txt or git log -L 100,+50:filename.txt</td>
      <td>List changes (as patches) to lines 100-150 in filename.txt</td>
    </tr>
    <tr>
      <td>git log -S “MaxConnections”</td>
      <td>List all commits that add or change the string</td>
    </tr>
    <tr>
      <td>git log –pretty=format:”%h %cn %cd %s %an”</td>
      <td>Show commit hash, committer name, commit date, commit message, author name</td>
    </tr>
    <tr>
      <td>git reflog</td>
      <td>Used to recover lost commits and branches</td>
    </tr>
    <tr>
      <td>git log –since=yesterday</td>
      <td>Show commits since yesterday (midnight)</td>
    </tr>
    <tr>
      <td>git log –since=”May 1, 2021”</td>
      <td>Show commits since a specific date</td>
    </tr>
    <tr>
      <td>git log –since=”May 1, 2021 14:23:45”</td>
      <td>Show commits since a specific date and time</td>
    </tr>
    <tr>
      <td>git log –since=”3 days ago”</td>
      <td>Show commits since a certain number of days ago</td>
    </tr>
    <tr>
      <td>git log –since=”2 hours ago”</td>
      <td>Show commits since a certain number of hours ago</td>
    </tr>
  </tbody>
</table>

<p><strong>Git diff</strong></p>

<p>Git uses standard UNIX less program do show the git diff.</p>

<p><img src="/assets/2024/September/git%20diff.png" alt="Untitled" /></p>

<p><strong>Git pager</strong> (used with diff)</p>

<p>The <code class="language-plaintext highlighter-rouge">core.pager</code> setting determines the pager used when Git pages output. This setting can be configured globally or per-repository.</p>

<p>To set the pager globally, use the following command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git config --global core.pager &lt;pager&gt;
</code></pre></div></div>

<p>Replace <code class="language-plaintext highlighter-rouge">&lt;pager&gt;</code> with the name of the pager you want to use, such as <code class="language-plaintext highlighter-rouge">less</code> or <code class="language-plaintext highlighter-rouge">more</code>.</p>

<p>To set the pager per-repository, use the same command without the <code class="language-plaintext highlighter-rouge">--global</code> option, inside the repository directory.</p>

<p>Git comes with a default pager, which is <code class="language-plaintext highlighter-rouge">less</code>. If you haven’t set a pager explicitly, <code class="language-plaintext highlighter-rouge">less</code> will be used as the default.</p>

<h3 id="blame">Blame</h3>

<p><code class="language-plaintext highlighter-rouge">git blame</code> is a command in Git that allows you to see who made changes to a file, which lines were changed, and when the changes were made. It can be helpful for understanding the history of a file, tracking down the source of a bug, or determining who to contact with questions about a particular piece of code. The output of <code class="language-plaintext highlighter-rouge">git blame</code> includes the commit SHA, author name, date, and the specific line of code that was changed. By default, <code class="language-plaintext highlighter-rouge">git blame</code> shows the annotations for the entire file, but you can also specify a specific range of lines or a specific revision to show annotations for.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git blame filename.txt</td>
      <td>Annotate file with commit details</td>
    </tr>
    <tr>
      <td>git blame -w filename.txt</td>
      <td>Annotate file with commit details, ignoring whitespace</td>
    </tr>
    <tr>
      <td>git blame -L 100,150 filaname.txt</td>
      <td>Annotate lines 100-150</td>
    </tr>
    <tr>
      <td>git blame -L 100,+50 filename.txt</td>
      <td>Annotate lines 100-150</td>
    </tr>
    <tr>
      <td>git blame d9dba0 filename.txt</td>
      <td>Annotate file at revision d9dba0</td>
    </tr>
    <tr>
      <td>git blame d9dba0 – filename.txt</td>
      <td>Same as previous command</td>
    </tr>
    <tr>
      <td>git config –global alias.praise blame</td>
      <td>Add a global alias for “praise” (if blame sounds negative)</td>
    </tr>
    <tr>
      <td>git annotate filename.txt</td>
      <td>Annotate file with commit details, different output format</td>
    </tr>
  </tbody>
</table>

<h3 id="bisect">Bisect</h3>

<p>If you’re trying to find a bug in your Git project, binary search is your friend! Here’s how it works: first, find the commit that introduced the bug or regression. Then, mark the last good revision and the first bad revision. Reset your code to the midpoint between these two revisions and test it out. If the code is still broken, mark the midpoint as bad. If it’s fixed, mark it as good. Keep repeating this process, dividing the revisions in half each time, until you find the exact commit that introduced the bug. It may take a few tries, but it’s worth it to squash that bug!</p>

<p><img src="/assets/2024/September/bisect.png" alt="Untitled" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git bisect start
git bisect good &lt;treeish&gt;
git bisect bad &lt;treeish&gt;
git bisect reset
</code></pre></div></div>

<p>That’s all for today’s learning. 🥰</p>

<h2 id="references">References</h2>

<p><a href="https://github.com/LinkedInLearning/git-intermediate-techniques-3082618">LinkedIn Learning</a></p>]]></content><author><name></name></author><category term="Web" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Generative Pre-training</title><link href="http://localhost:4000/ai/2023/08/13/Generative_pre_training.html" rel="alternate" type="text/html" title="Generative Pre-training" /><published>2023-08-13T10:00:10+05:30</published><updated>2023-08-13T10:00:10+05:30</updated><id>http://localhost:4000/ai/2023/08/13/Generative_pre_training</id><content type="html" xml:base="http://localhost:4000/ai/2023/08/13/Generative_pre_training.html"><![CDATA[<h1 id="introduction-">Introduction 🚀</h1>

<p>In this blog, we will explore the main idea behind chat-GPT, which is generative pre-training, and create our own smaller version of a question-answering model using generative pre-training. 🤖💬</p>

<p>The research paper we will be referencing is “Improving Language Understanding by Generative Pre-Training.” 📚🔬</p>

<h1 id="generative-pre-trained-transformer-gpt-">Generative Pre-Trained Transformer (GPT) 🧠</h1>

<h4 id="transfer-learning-">Transfer Learning 🔄</h4>

<p>Transfer learning is a machine learning technique in which a model trained on a large dataset is adapted for a different but related task. 🎓➡️🆕</p>

<p>The concept behind transfer learning is that the pre-trained model has learned general patterns and can be adjusted to specific domains or tasks with minimal additional training data. This saves time and resources compared to training a model from scratch. ⏳💰</p>

<h4 id="generative-pre-training-">Generative Pre-training 🔮</h4>

<p>In the field of natural language processing, generative pre-training is an example of transfer learning. A language model is pre-trained on a large corpus of text data using self-supervised learning, and then fine-tuned on a smaller, labeled dataset for a specific task. 📚➡️🎯</p>

<p>The Generative Pre-trained Transformer (GPT) is a state-of-the-art deep learning architecture developed by OpenAI for natural language processing tasks, such as text generation, text completion, and text classification. 🌟🤖</p>

<p>GPT models are usually pre-trained on a large corpus of text data from the internet to learn general language patterns. Then, they are fine-tuned on specific domains or tasks using smaller, domain-specific datasets to adapt them to the specific context and language patterns of the target domain. 🌐➡️🎯</p>

<p>This is a semi-supervised approach that involves unsupervised pre-training and supervised fine-tuning. 🔄🏋️</p>

<p>During pre-training in generative pre-training, the model is trained to predict missing words or generate new text based on the input context. The goal is to learn a universal representation that transfers with little adaptation to a wide range of tasks. 🧩🔮</p>

<p>In the context of generative pre-training, “generative” refers to the ability of the model to generate new output based on the input it has learned. In other words, the model is capable of generating new text that is similar to the text it was trained on, but not identical. This is distinct from discriminative models, which are used for tasks such as classification and are designed to distinguish between different input classes. 🎨🆚🔍</p>

<h4 id="self-supervised-learning-">Self-Supervised Learning 🤖🔄</h4>

<p>Self-supervised learning is a type of machine learning in which the model is trained to predict or generate missing information in the data without explicitly being told what the missing information is. This is different from supervised learning, where the model is given labeled data to learn from. 🕵️‍♂️🧠</p>

<p>An example of self-supervised learning is image inpainting, where the model is trained to fill in missing pixels in an image based on the context of the surrounding pixels. In this case, the model is not explicitly told which pixels are missing, but rather it learns to infer the missing pixels based on the patterns it has learned in the input image. 🖼️🔍</p>

<p>Self-supervised learning is a powerful approach because it allows the model to learn from large amounts of unlabeled data, which is often easier to obtain than labeled data. This can be especially useful in domains where labeled data is scarce or expensive to obtain. 📊💡</p>

<h1 id="training-framework-️️">Training Framework 🏋️‍♂️</h1>

<p>In the context of generative pre-training, the training framework typically involves two stages: pre-training and fine-tuning. 🔄</p>

<ol>
  <li>
    <p>Pre-training 🎓</p>

    <p>During pre-training, the model is trained on a large, unlabeled corpus of text data using a self-supervised learning approach. This involves predicting missing words or generating new text based on the context of the input. 🔮</p>

    <p>The goal of pre-training is to learn a general representation of language that can be fine-tuned for specific tasks. 🌐</p>
  </li>
  <li>
    <p>Fine-tuning 🎯</p>

    <p>During fine-tuning, the pre-trained model is further trained on a smaller, labeled dataset specific to the task at hand. This involves adjusting the parameters of the pre-trained model to better fit the specific context and language patterns of the target domain. 🔧</p>

    <p>Fine-tuning allows the model to adapt to the specific task and improve its performance. 📈</p>
  </li>
</ol>

<p>Overall, the goal of the training framework in generative pre-training is to learn a general representation of language that can be fine-tuned for a wide range of tasks with minimal additional training data. 🚀</p>

<h2 id="unsupervised-pre-training-">Unsupervised Pre-Training 🤖🔮</h2>

<p>To perform generative pre-training, an unsupervised corpus of tokens $\mu = (u_1, …, u_n)$ is required. The language modeling objective in this context refers to predicting the next word in a sequence given the previous words. The goal is to maximize the probability of the next word in the sequence given the preceding words.</p>

<p>To achieve this, we use the standard language modeling objective and maximize:</p>

<p>$L_1(U) = \sum_i log P(u_i \lvert u_{i−k}, . . . , u_{i−1}; Θ)$</p>

<p>where k is the size of the context window. The conditional probability is modeled using a neural network with parameters $Θ$, which are trained using stochastic gradient descent.</p>

<p>We use a multilayer transformer decoder for the language model, this is used to calculate the probability of next token given a sequence of tokens.</p>

<p>$h_0 = UW_e +W_p$, calculate the initial hidden state of the model.</p>

<p>where:</p>

<p>$U = (u_{-k}, . . . , u_{−1})$ is the context vector of tokens.</p>

<p>$W_e$ is the token embedding matrix, which maps each token to a high-dimensional vector representation.</p>

<p>$W_p$ is the position embedding matrix, which encodes the relative position of each token in the input sequence.</p>

<p>This hidden state is then processed through multiple layers of transformer blocks to produce the final output of the model. Each layer producing a new block of data $h_l$ that serves as the input to the next layer.</p>

<p>$h_l = transformer_block(h_{l−1})∀i ∈ [1, n]$</p>

<p>where:</p>

<p>n is the number of layers in the transformer block.</p>

<p>We then calculate the probability distribution of the next word in a sequence given the previous words. The softmax function is applied to the dot product of the hidden state vector ($h_n$) and the transpose of the word embedding matrix ($W_e$) to obtain the probabilities of the next word.</p>

<p>$P(u) = softmax(h_nW^T_e )$</p>

<h2 id="supervised-fine-tuning-️️">Supervised Fine-Tuning 🎯🏋️‍♂️</h2>

<p>We use a labeled dataset C and a sequence of input tokens $x^1, x^2, …., x^m$ and a label y. These inputs are passed through the pre-trained model to obtain the final output $h_l^m$, which is then fed to a linear output layer with parameter $W_y$.</p>

<p>This equation $P(y\lvert x^1, . . . , x^m) = softmax(h_l^m W_y)$ calculates the probability of target output y given a set of input tokens $x^1, . . . , x^m$.</p>

<p>where:</p>

<p>$h_l^m$ represents the hidden state of the model after processing the input sequence (of size m) through l layers of transformer blocks.</p>

<p>$W_y$ is the parameter matrix of the fine-tuned model.</p>

<p>The final objective is to maximize:</p>

<p>$L_2(C) = \sum_{(x, y)}log P(y\lvert x^1,…,x^m)$ i.e. the objective is to maximize a function $L_2(C)$, which is a sum of logarithmic probabilities.</p>

<p>Including language modeling as an auxiliary objective to fine-tuning helps learning by improving the generalization of the supervised model and accelerating convergence. To achieve this, we add $L_1(C)$ language modeling objective with weight $\lambda$. Therefore, the final objective to maximize is:</p>

<p>$L_3(C) = L_2(C) + \lambda * L_1(C)$</p>

<h1 id="task-specific-input-transformations-">Task-specific Input Transformations 🔄</h1>

<p>We use a traversal-style approach to convert structured inputs into an ordered sequence that our pre-trained model can process.</p>

<p><img src="/assets/2024/September/gpt.png" alt="Fig: **(Left) Transformer architecture and training objectives used in this work.
      (Right) Input transformations for fine-tuning on different tasks. We convert all structured inputs into token sequences to be processed by our pre-trained model, followed by a linear + softmax layer.**" /></p>

<p><em>Fig: <strong>(Left) Transformer architecture and training objectives used in this work.
      (Right) Input transformations for fine-tuning on different tasks. We convert all structured inputs into token sequences to be processed by our pre-trained model, followed by a linear + softmax layer.</strong></em></p>

<ol>
  <li>
    <p>Textual Entailment 🧩</p>

    <p>For entailment tasks, we concatenate the token sequences of the premise p and hypothesis h, with a delimiter token ($) in between.</p>
  </li>
  <li>
    <p>Similarity 🪞</p>

    <p>For similarity tasks, the input sequence contains both possible sentence orderings (with a delimiter in between). We process each independently to produce two sequence representations $h_l^m$.</p>
  </li>
  <li>
    <p>Question Answering and Commonsense Reasoning 💡</p>

    <p>For these tasks, we are given a context document z, a question q, and a set of possible answers ${a_k}$. We create a sequence of [z;q;$;a_k].</p>
  </li>
</ol>

<p>Each of these sequences is processed independently with our model and then normalized via a softmax layer to produce an output distribution over possible answers.</p>

<h3 id="implementation">Implementation</h3>

<p>You can find the Implementation of fine Tuning this GPT2 model on question-answering dataset here .</p>

<p><a href="https://www.kaggle.com/code/dsmeena/pytorch-fine-tuning-gpt2">Kaggle</a></p>

<h3 id="references">References</h3>

<p><a href="https://paperswithcode.com/method/gpt">Papers with Code - GPT Explained</a></p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Introduction 🚀]]></summary></entry><entry><title type="html">Attention in DL</title><link href="http://localhost:4000/ai/2023/06/25/Attention_in_DL.html" rel="alternate" type="text/html" title="Attention in DL" /><published>2023-06-25T10:00:10+05:30</published><updated>2023-06-25T10:00:10+05:30</updated><id>http://localhost:4000/ai/2023/06/25/Attention_in_DL</id><content type="html" xml:base="http://localhost:4000/ai/2023/06/25/Attention_in_DL.html"><![CDATA[<p>Welcome to this blog post on attention in deep learning! In this post, we will explore the concept of attention and its importance in the field of deep learning. We will start by explaining what attention is and how it works, and then move on to different types of attention mechanisms and their applications. Whether you are new to deep learning or an experienced practitioner 🧑‍⚕️, this post is sure to provide valuable insights into one of the most important concepts in modern machine learning.</p>

<h1 id="attention">Attention</h1>

<p>Attention is a mechanism in neural networks that allows the model to focus 🔍 on specific parts of the input sequence when making predictions. It has been a breakthrough in natural language processing and computer vision.</p>

<p>Attention was first introduced in 2014 by Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio, and since then, it has become a fundamental concept in deep learning.</p>

<p><img src="/assets/2024/September/attention%20mechanism.png" alt="Fig: The attention mechanism improves model’s prediction. Taken from Show, Attend and Tell: Neural Image Caption Generation with Visual Attention" /></p>

<p><em>Fig: The attention mechanism improves model’s prediction. Taken from Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</em></p>

<h2 id="working-of-attention-">Working of Attention 👷</h2>

<p>The attention mechanism assigns weights to each element in the input sequence, indicating their relevance to the current output. Here’s how it works:</p>

<ol>
  <li>The attention weights 🏋️‍♀️ are computed based on the current state of the model and the entire input sequence.</li>
  <li>The input sequence is multiplied ❌ element-wise by the attention weights, producing a sequence of weighted vectors. These vectors are then summed ➕ to obtain a single vector or context vector that captures the most relevant parts of the input sequence.</li>
  <li>
    <p>This weighted sum of the input sequence or context vector is then used to compute the next state of the model.</p>

    <p>How? by concatenating 🔗 the context vector with the decoder output and passing through a feedforward neural network to get the final output sequence which is again used to update decoder hidden state.</p>
  </li>
</ol>

<p>By focusing on specific parts of the input sequence that are most relevant to the current output, the attention mechanism improves the model’s performance.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  Input Sequence  --&gt; Encoder --&gt; Attention --&gt; Decoder --&gt; Output Sequence
</code></pre></div></div>

<p>In this diagram, the input sequence is first passed through an encoder, which produces a set of encoded representations. The attention mechanism then computes weights for each encoded representation, indicating its relevance 🤔 to the current output. The weighted sum of the encoded representations is then passed through a decoder, which produces the final output sequence.</p>

<h2 id="coding-view-">Coding View 🧑‍💻</h2>

<p>To write an attention model from scratch, you would need to define the input and output shapes of the model, as well as the layers to be used. The model would then need to be trained using a suitable loss function and optimizer.</p>

<p>Here is an example of how to implement an attention model using TensorFlow 🌊:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">dot</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">concatenate</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="n">tensorflow.keras.backend</span> <span class="k">as</span> <span class="n">K</span>

<span class="c1"># Define the input sequence shape and size
</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1"># Define the encoder and decoder layers using LSTM cells
</span><span class="n">encoder_inputs</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
<span class="n">encoder_lstm</span> <span class="o">=</span> <span class="nc">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span> <span class="o">=</span> <span class="nf">encoder_lstm</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">)</span>
<span class="n">encoder_states</span> <span class="o">=</span> <span class="p">[</span><span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span><span class="p">]</span>

<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
<span class="n">decoder_lstm</span> <span class="o">=</span> <span class="nc">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">decoder_lstm</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_states</span><span class="p">)</span>

<span class="c1"># Compute attention weights
</span><span class="n">attention</span> <span class="o">=</span> <span class="nf">dot</span><span class="p">([</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">attention</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)(</span><span class="n">attention</span><span class="p">)</span>

<span class="n">context</span> <span class="o">=</span> <span class="nf">dot</span><span class="p">([</span><span class="n">attention</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">decoder_combined_context</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">context</span><span class="p">,</span> <span class="n">decoder_outputs</span><span class="p">])</span>

<span class="c1"># Define the output layer
</span><span class="n">output_layer</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="nf">output_layer</span><span class="p">(</span><span class="n">decoder_combined_context</span><span class="p">)</span>

<span class="c1"># Define the model
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">([</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">],</span> <span class="n">output</span><span class="p">)</span>

</code></pre></div></div>

<p>In this example, we first define the shape and size of the input sequence. The input vectors have a dimensionality of 32 and input sequence has a length of 10.</p>

<p>Let’s take a quick glance, at these terms. 🧐</p>

<table>
  <thead>
    <tr>
      <th>Term</th>
      <th>Definition</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Input Vectors</td>
      <td>Represent the elements of the input sequence</td>
    </tr>
    <tr>
      <td>Input Sequence</td>
      <td>Input of the model</td>
    </tr>
    <tr>
      <td>Input size</td>
      <td>Refers to the dimensionality of the input vectors</td>
    </tr>
    <tr>
      <td>Input sequence length</td>
      <td>Refers to the number of elements in the input sequence.</td>
    </tr>
  </tbody>
</table>

<p>We then define the encoder and decoder layers 🧱 using LSTM cells, similar to the previous example.</p>

<p>We then compute the attention weights by taking the dot product of the decoder outputs and encoder outputs, and passing the result through a softmax activation function 🥎 to obtain the attention weights.</p>

<p>We then compute the context vector 📃 by taking the dot product of the attention weights and the encoder outputs.</p>

<p>Finally, we concatenate 🔗 the context vector and the decoder outputs, and pass the result through the output layer to obtain the final output.</p>

<p>There are many variations and improvements that can be made depending on the specific task and dataset being used.</p>

<h2 id="mathematical-view-">Mathematical View 👩‍🔬</h2>

<p>Here are the mathematical equations for the attention mechanism:</p>

<p>Let $h_t$ be the hidden state of the decoder at time $t$, and let $e_{i,j}$ be a score that measures the relevance of the ith encoder output ($h_i$) and the jth decoder hidden state ($h_j$).</p>

<p>The attention scores $e_{i,j}$ can be computed using various methods, such as dot product, additive, and multiplicative attention.</p>

<p>In the <strong>dot product method 🔵</strong>, the scores are computed as the dot product of the encoder outputs and the decoder hidden state:</p>

<p>$e_{i,j} = h_i^T h_j$</p>

<p>In the <strong>additive method ➕</strong>, the scores are computed as the sum of two feedforward neural networks:</p>

<p>$e_{i,j} = v_a^T \tanh(W_a h_i + U_a h_j)$</p>

<p>where $v_a$, $W_a$, and $U_a$ are learnable weight matrices.</p>

<p>In the <strong>multiplicative method ✖️</strong>, the scores are computed as the dot product of the decoder hidden state and a learnable weight matrix, which is then multiplied element-wise with the encoder outputs:</p>

<p>$e_{i,j} = h_i^T W_a h_j$</p>

<p>where $W_a$ is a learnable weight matrix.</p>

<p>In all cases, the attention mechanism allows the model to focus 🔍 on specific parts of the input sequence that are most relevant to the current output, improving the performance of the model.</p>

<p>The attention weights $\alpha_{i,j}$ are computed using the softmax function 🥎:</p>

<p>$\alpha_{i,j} = \frac{\exp(e_{i,j})}{\sum_{k=1}^{T_x} \exp(e_{i,k})}$</p>

<p>where $T_x$ is the length of the input sequence,</p>

<p>The exponential function: $\exp(x) = e^x$</p>

<p>The context vector $c_t$ is then computed as a weighted sum ➕ of the encoder outputs, using the attention weights:</p>

<p>$c_t = \sum_{i=1}^{T_x} \alpha_{i,t} h_i$</p>

<p>Finally, the context vector is concatenated 🔗 with the decoder hidden state $h_t$ and passed through a feedforward neural network to obtain the final output.</p>

<p>This output represents the model’s prediction or the next state of the model.</p>

<h2 id="self-attention-">Self-Attention 🤳</h2>

<p>Self-attention, also known as intra-attention, is a type of attention mechanism where the input sequence is compared 🪞 to itself to obtain a set of attention weights. This allows the model to attend to different parts of the input sequence when making predictions, without requiring any additional context.</p>

<h3 id="working-of-self-attention-">Working of self-attention 👷</h3>

<p>In self-attention, the input sequence is first passed through three linear transformations to obtain query, key 🗝️, and value vectors.</p>

<p>Let’s say we have an input sequence of length $T_x$ and input size $d$.</p>

<p>Then, we define three weight matrices $W_q$, $W_k$, and $W_v$, each of shape $d \times d$.</p>

<p>We use these weight matrices to transform the input sequence into query, key, and value vectors:</p>

<ul>
  <li>
    <p>The query ❓ vector $q_i$ for the ith element of the input sequence is obtained by multiplying the input sequence by $W_q$:</p>

    <p>$q_i = W_q x_i$</p>
  </li>
  <li>
    <p>The key 🗝️ vector $k_j$ for the jth element of the input sequence is obtained by multiplying the input sequence by $W_k$:</p>

    <p>$k_j = W_k x_j$</p>
  </li>
  <li>
    <p>The value ⚖️ vector $v_t$ for the th element of the input sequence is obtained by multiplying the input sequence by $W_v$:</p>

    <p>$v_t = W_v x_t$</p>
  </li>
</ul>

<p>where $x_i$, $x_j$, and $x_t$ are the embeddings of the ith, jth, and th elements of the input sequence, respectively.</p>

<p>These vectors are then used to compute the attention scores as the dot product 🔵 of the query and key vectors, which is then scaled by the square root of the dimensionality $d$ to prevent the scores from becoming too large:</p>

<p>$e_{i,j} = \frac{q_i^T k_j}{\sqrt{d}}$</p>

<p>where $q_i$ and $k_j$ are the query and key vectors for the ith and jth elements of the input sequence, respectively.</p>

<p>The attention scores are then normalized using the softmax function 🥎 to get attention weights:</p>

<p>$\alpha_{i,j} = \frac{\exp(e_{i,j})}{\sum_{k=1}^{T_x} \exp(e_{i,k})}$</p>

<p>where $T_x$ is the length of the input sequence.</p>

<p>The context vector $c_i$ for the ith element of the input sequence is then computed as the weighted sum ➕ of the value vectors, using the attention weights:</p>

<p>$c_i = \sum_{j=1}^{T_x} \alpha_{i,j} v_j$</p>

<p>where $v_j$ is the value vector for the jth element of the input sequence.</p>

<p>Finally, the context vectors are concatenated 🔗 and passed through a feedforward neural network to obtain the final output.</p>

<p>It represents the model’s prediction or the next state of the model. The specific details of the final output would depend on the architecture and task of the deep learning model being used.</p>

<p>However, self-attention is particularly useful in natural language processing tasks, where the input sequence is often a sequence of words or tokens, and the model needs to capture long-range dependencies between them.</p>

<p>Self-attention has been a breakthrough in natural language processing and has been used in many state-of-the-art models such as BERT and GPT-2.</p>

<h3 id="differences-">Differences 🔎</h3>

<p>In Generic attention, on the other hand, the input sequence is compared to some additional context to obtain a set of attention weights.</p>

<p>The additional context can be the current state of the model (like decoder outputs), image or another sequence.</p>

<p>For example,</p>

<p>In image captioning, 📸 the model uses both the image and the previously generated words as additional context to generate a caption. The attention mechanism can then focus on different parts of the image when generating each word of the caption.</p>

<p>Similarly, in machine translation 🤖, the model can use the previously generated words as additional context when generating the next word. The attention mechanism can then focus on different parts of the source sentence when generating each word of the target sentence.</p>

<p>So, the additional context can be any sequence or vector that is relevant to the task being performed by the model, including the output of the model itself.</p>

<p>The key difference between the two is that in <strong>scaled dot product attention</strong> 🔵, the query, key, and value matrices are all derived from different sources, while in self-attention, they are all derived from the same input sequence.</p>

<p>Scaled dot product attention is commonly used in transformer-based models, while self-attention is commonly used in recurrent neural networks and other models for natural language processing tasks.</p>

<p>This differences will help you better understand the attention mechanism.</p>

<h2 id="types-of-attention-mechanism">Types of Attention Mechanism</h2>

<p>There are several types of attention mechanisms, including:</p>

<h3 id="global-attention-">Global attention 🌍</h3>

<p>In this type of attention, the model considers all the input elements when computing the attention weights. It is also known as hard attention or window-based attention.</p>

<p>For example, in image captioning, global attention can be used to attend to all the regions of the image when generating the corresponding caption.</p>

<p>However, global attention can be computationally expensive when dealing with long input sequences, as it requires computing the attention weights for all the input elements.</p>

<h3 id="local-attention-">Local attention 🏠</h3>

<p>In this type of attention, the model only considers a subset of the input elements when computing the attention weights. This subset can be determined based on the current state of the model or other factors. It is also known as soft attention or content-based attention.</p>

<p>For example, in machine translation, local attention can be used to attend to a subset of the source sentence when generating the corresponding target sentence.</p>

<h3 id="multi-head-attention-">Multi-head attention 🤹</h3>

<p>In this type of attention, the model computes multiple sets of attention weights, each focusing on a different part of the input sequence. 
In multi-head attention, the input is split into multiple heads, each of which is processed using self-attention. The outputs of the multiple heads are then concatenated and passed through a linear layer to produce the final output.</p>

<p>This allows the model to capture different aspects of the input sequence simultaneously.</p>

<p>One example of a complex task that requires multi-head attention is language modeling 🔮, where the model is trained to predict the next word in a sentence given the previous words. In this task, the model needs to capture both local dependencies between adjacent words and long-range dependencies between distant words. Multi-head attention can be used to capture both types of dependencies by allowing the model to attend to different parts of the input sequence in parallel. This has been demonstrated in models such as GPT-2 and BERT, which have achieved state-of-the-art performance on a wide range of natural language processing tasks.</p>

<p><img src="/assets/2024/September/soft-hard.png" alt="Fig: As the model generates each word, its attention changes to reflect the relevant parts of the image. “soft” (top row) vs “hard” (bottom row) attention. 
Taken From Show, Attend and Tell: Neural Image Caption Generation with Visual Attention" /></p>

<p><em>Fig: As the model generates each word, its attention changes to reflect the relevant parts of the image. “soft” (top row) vs “hard” (bottom row) attention. 
Taken From Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</em></p>

<p>Each type of attention mechanism has its own advantages and disadvantages, and the choice of which one to use depends on the specific task and dataset being used.</p>

<h2 id="applications">Applications</h2>

<p>Attention has been used in various applications in deep learning, such as machine translation, speech recognition, image captioning, and question answering.</p>

<p>One of the most popular models that use attention is the Transformer, which was introduced in 2017 by Vaswani et al.</p>

<p>Overall, attention has proven to be a powerful mechanism in deep learning that allows the model to focus on specific parts of the input sequence, improving the performance of various deep learning models.</p>

<h2 id="references-">References 👏</h2>

<p><a href="https://towardsdatascience.com/transformers-89034557de14">Data science</a></p>

<p><a href="https://arxiv.org/pdf/1502.03044.pdf">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention → Image captioning using Attention</a></p>

<p><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is All you Need → Self-Attention, Multi-Head Attention, Transformers</a></p>

<p>That’s it for this blog, hope this was will help you better understand the concepts of deep learning ❤️❤️.</p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Welcome to this blog post on attention in deep learning! In this post, we will explore the concept of attention and its importance in the field of deep learning. We will start by explaining what attention is and how it works, and then move on to different types of attention mechanisms and their applications. Whether you are new to deep learning or an experienced practitioner 🧑‍⚕️, this post is sure to provide valuable insights into one of the most important concepts in modern machine learning.]]></summary></entry><entry><title type="html">Improving command line skills</title><link href="http://localhost:4000/linux/2023/06/25/Improving_command_line_skills.html" rel="alternate" type="text/html" title="Improving command line skills" /><published>2023-06-25T10:00:10+05:30</published><updated>2023-06-25T10:00:10+05:30</updated><id>http://localhost:4000/linux/2023/06/25/Improving_command_line_skills</id><content type="html" xml:base="http://localhost:4000/linux/2023/06/25/Improving_command_line_skills.html"><![CDATA[<p>Welcome to our comprehensive guide on improving your Command Line skills, where we primarily focus on the Linux-based command line. This emphasises Linux because most commands are identical across Linux and Windows, with just a few exceptions. This blog will explore various commands related to the Linux file system, their applications, and how to use them effectively to enhance your navigation and manipulation of the Linux operating system.</p>

<h2 id="linux-file-system">Linux File System</h2>

<p>This section focuses on commands used in Linux for working with files and directories – we will discuss some less-discussed commands. I hope that you are already aware of the primary file system commands like ‘pwd’ for printing the current directory, ‘cd’ for changing directories, ‘ls’ for listing directory contents, and shortcuts for navigation ‘.’ (current folder), ‘..’ (parent folder), ‘~’ (current user’s home directory) and wildcard symbols for matching patterns (*, ?), creating new files and directories using ‘touch’ and ‘mkdir’.</p>

<p>The Linux File System follows a tree-like structure starting at a base (or root) directory, indicated by the slash (/). Locations on the file system are shown using file paths. Paths that start at the base directory (/) are known as absolute paths. Paths that start from the shell’s current working directory are known as relative paths.
Absolute: /home/sarah/Documents/file1.txt
Relative: Documents/file1.txt</p>

<h3 id="editing-files">Editing Files📝</h3>

<h4 id="nano">Nano</h4>

<p>Nano is a simple, user-friendly text editor for the terminal. It is ideal for creating and editing text files and scripts. Here are some basic commands:</p>

<ul>
  <li>To open or create a file, use <code class="language-plaintext highlighter-rouge">nano &lt;filename&gt;</code>. If the file already exists, it will open for editing. If not, a new file will be created.</li>
  <li>To save changes, press <code class="language-plaintext highlighter-rouge">Ctrl+O</code>. This will prompt you for a filename for the file. Press <code class="language-plaintext highlighter-rouge">Enter</code> to save.</li>
  <li>To exit Nano, press <code class="language-plaintext highlighter-rouge">Ctrl+X</code>. If there are unsaved changes, Nano will ask if you want to save changes before exiting.</li>
  <li>To cut and paste text, use <code class="language-plaintext highlighter-rouge">Ctrl+K</code> to cut a line and <code class="language-plaintext highlighter-rouge">Ctrl+U</code> to paste it back.</li>
</ul>

<p><img src="/assets/2024/September/nano.png" alt="Untitled" /></p>

<p>It comes with a built-in toolbar of various commands and all one needs to know in order to use these options are the meaning of 2 special symbols.</p>

<table>
  <thead>
    <tr>
      <th>Character</th>
      <th>Meaning</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>^</td>
      <td>This is the CTRL key on your keyboard. For example, ^O is CTRL + O.</td>
    </tr>
    <tr>
      <td>M-</td>
      <td>This is the “meta” key on your keyboard. Depending on your keyboard layout this may be the ALT, ESC, CMD key. Try it out 😄 Assuming M- is the ALT key, then M-X is ALT + X</td>
    </tr>
  </tbody>
</table>

<p>If want to learn more about nano, then read this page <a href="https://www.nano-editor.org/docs.php">nano.</a></p>

<h4 id="vim">Vim</h4>

<p>Vim is a highly configurable text editor for efficiently creating and changing any kind of text. It is especially useful for editing programs. Here are some basics:</p>

<ul>
  <li>To start Vim and open a file, use <code class="language-plaintext highlighter-rouge">vim &lt;filename&gt;</code>. If the file does not exist, it will be created.</li>
  <li>Vim operates in different modes, primarily command mode and insert mode.</li>
  <li>To switch to insert mode, press <code class="language-plaintext highlighter-rouge">i</code>. You can now enter and edit text.</li>
  <li>To switch back to command mode, press <code class="language-plaintext highlighter-rouge">Esc</code>.</li>
  <li>In command mode:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">:w</code> will save the file without exiting.</li>
      <li><code class="language-plaintext highlighter-rouge">:q</code> will quit Vim. If there are unsaved changes, Vim will not exit and will warn about unsaved changes.</li>
      <li><code class="language-plaintext highlighter-rouge">:wq</code> will save changes and then exit.</li>
      <li><code class="language-plaintext highlighter-rouge">:q!</code> will exit without saving changes.</li>
    </ul>
  </li>
  <li>To cut and paste text in Vim, use <code class="language-plaintext highlighter-rouge">dd</code> to delete a line in command mode and <code class="language-plaintext highlighter-rouge">p</code> to paste it back.</li>
</ul>

<p>Here are some common commands used in Vim:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">i</code> - enter insert mode</li>
  <li><code class="language-plaintext highlighter-rouge">:q</code> - quit</li>
  <li><code class="language-plaintext highlighter-rouge">esc + :wq</code> - save and quit</li>
  <li><code class="language-plaintext highlighter-rouge">esc + :q!</code> - quit without saving</li>
  <li><code class="language-plaintext highlighter-rouge">dd</code> - delete a line</li>
  <li><code class="language-plaintext highlighter-rouge">#dd</code> - delete # lines</li>
  <li><code class="language-plaintext highlighter-rouge">U</code> - undo</li>
  <li><code class="language-plaintext highlighter-rouge">Ctrl+r</code> - redo</li>
  <li><code class="language-plaintext highlighter-rouge">:/search</code> - search for a word</li>
  <li><code class="language-plaintext highlighter-rouge">n,N</code> - move to the next/previous search result</li>
  <li><code class="language-plaintext highlighter-rouge">:%s/word/to_word/gc</code> - replace all occurrences of “word” with “to_word” in the entire file, prompting for confirmation
    <ul>
      <li>Use g only if don’t want to prompt for confirmation.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">:set number</code> - display line numbers</li>
  <li><code class="language-plaintext highlighter-rouge">:$</code> - go to last line</li>
  <li><code class="language-plaintext highlighter-rouge">tail -f filename</code> - output the last 10 lines of a file and continue to output as new lines are added</li>
</ul>

<h3 id="the-locate-command">The Locate Command</h3>

<p>The locate command searches a database on your file system for the files that match the text (or regular expression) that you provide it as a command line argument.</p>

<p>If results are found, the locate command will return the absolute path to all matching files.</p>

<p>For example:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>locate <span class="k">*</span>.txt
</code></pre></div></div>

<p>will find all files with filenames ending in .txt that are registered in the database.</p>

<p>The locate command is fast, but because it relies on a database it can be error prone if the database isn’t kept up to date.</p>

<p>Below are some commands to update the database and some reassuring procedures in case one cannot access administrator privileges.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>locate -S or —statistics</td>
      <td>Print information about the database file.</td>
    </tr>
    <tr>
      <td>sudo updatedb</td>
      <td>Update the database. As the updatedb command is an administrator command, the sudo command is used to run updatedb as the root user (the administrator)</td>
    </tr>
    <tr>
      <td>Locate —existing or -e</td>
      <td>Check whether a result actually exists before returning it. (Inspite of being present in database, cross check)</td>
    </tr>
    <tr>
      <td>locate —limit 5 or -l</td>
      <td>Limit the output to only show 5 results</td>
    </tr>
  </tbody>
</table>

<p>Examples →</p>

<p><img src="/assets/2024/September/locate.png" alt="locate command with limit and existing options and -S option" /></p>

<p>locate command with limit and existing options and -S option</p>

<h3 id="the-find-command-">The Find Command 🔎</h3>

<p>The find command can be used for more sophisticated search tasks than the locate command.</p>

<p>This is made possible due to the many powerful options that the find command has.</p>

<p>The first thing to note is that the find command will list both files and directories, below the</p>

<p>point the file tree that it is told to start at.</p>

<p>For example: <code class="language-plaintext highlighter-rouge">find .</code> will list all files and directories below the current working directory (which is denoted by the .)</p>

<p><img src="/assets/2024/September/find.png" alt="Untitled" /></p>

<p>While <code class="language-plaintext highlighter-rouge">find /</code> will list all files and directories below the base directory (/); thereby listing everything on the entire file system!</p>

<p>By default, the find command will list everything on the file system below its starting point, to an infinite depth.</p>

<p>The search depth can however be limited using the –maxdepth option.</p>

<p>For example</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>find / <span class="nt">-maxdepth</span> 4
</code></pre></div></div>

<p>Will list everything on the file system below the base directory, provided that it is within 4 levels of the base directory.</p>

<p>There are many other options for the find command. Some of the most useful are tabulated below:</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>-type</td>
      <td>Only list items of a certain type. <code class="language-plaintext highlighter-rouge">–type f</code> restricts the search to file and <code class="language-plaintext highlighter-rouge">–type d</code> restricts the search to directories.</td>
    </tr>
    <tr>
      <td>-name “*.txt”</td>
      <td>Search for items matching a certain name. This name may contain a regular expression and should be enclosed in double quotes as shown. In this example, the find command will return all items with names ending in .txt.</td>
    </tr>
    <tr>
      <td>-iname</td>
      <td>Same as  <code class="language-plaintext highlighter-rouge">–name</code> but uppercase and lowercase do not matter.</td>
    </tr>
    <tr>
      <td>-size</td>
      <td>Find files based on their size. e.g <code class="language-plaintext highlighter-rouge">–size +100k</code> finds files over 100 KiB in size <code class="language-plaintext highlighter-rouge">–size -5M</code> finds files less than 5MiB in size. Other units include G for GiB and c for bytes**.</td>
    </tr>
  </tbody>
</table>

<p><strong>Note:</strong> 1 Kibibyte (KiB) = 1024 bytes. 1 Mebibyte (MiB) = 1024 KiB. 1 Gibibyte = 1024 MiB.</p>

<h4 id="exec--ok">Exec &amp; ok</h4>

<p>A supremely useful feature of the find command is the ability to execute another command on each of the results.</p>

<p>For example</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>find /etc –exec <span class="nb">cp</span> <span class="o">{}</span> ~/Desktop <span class="se">\;</span>
</code></pre></div></div>

<p>will copy every item below the /etc folder on the file system to the ~/Desktop directory.</p>

<p>The argument to the <code class="language-plaintext highlighter-rouge">–exec</code> option is the command you want to execute on each item found by the find command.</p>

<p>Commands should be written as they would normally, with <strong>{} used as a placeholder for the results of the find command.</strong></p>

<p>Be sure to terminate the <code class="language-plaintext highlighter-rouge">–exec</code> option using \; (a backslash then a semicolon).</p>

<p>The <code class="language-plaintext highlighter-rouge">–ok</code> option can also be used, to prompt the user for permission before each action.</p>

<p>This can be tedious for a large number of files, but provides an extra layer of security of a small number of files; especially when doing destructive processes such as deletion.</p>

<p>An example may be:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>find /etc –ok <span class="nb">cp</span> <span class="o">{}</span> ~/Desktop <span class="se">\;</span>
</code></pre></div></div>

<p><img src="/assets/2024/September/find%20and%20ok.png" alt="Find command within current directory with name option and remove operation for each result " /></p>

<p>Find command within current directory with name option and remove operation for each result</p>

<p>exec → just execute the command</p>

<p>ok → ask at each step 🌇</p>

<h3 id="viewing-file-content-">Viewing File Content 🪟</h3>

<p>There exist commands to open files and print their contents to standard output. One such example is the cat command. Let’s say we have a file called hello.txt on the Desktop.</p>

<p>By performing: <code class="language-plaintext highlighter-rouge">cat ~/Desktop/hello.txt</code></p>

<p>This will print out the contents of hello.txt to standard output where it can be viewed or piped to other commands if required.</p>

<p>One such command to pipe to would be the less command. The less command is known as a “pager” program and excels at allowing a user to page through large amounts of output in a more user-friendly manner than just using the terminal.</p>

<p>An example may be:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> ~/Desktop/hello.txt | less
</code></pre></div></div>

<p>Or more simply:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>less ~/Desktop/hello.txt
</code></pre></div></div>

<p>By pressing the q key, the less command can be terminated and control regained over the shell.</p>

<p>Here are some other ways to view file contents:</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>tac &lt;path/to/file&gt;</td>
      <td>Print a file’s contents to standard output, reversed vertically.</td>
    </tr>
    <tr>
      <td>rev &lt;path/to/file&gt;</td>
      <td>Print a file’s content to standard output, reversed horizontally (along rows).</td>
    </tr>
    <tr>
      <td>head -n 15 &lt;path/to/file&gt;</td>
      <td>Read the first 15 lines from a file (10 by default if -n option not provided.)</td>
    </tr>
    <tr>
      <td>tail -n 15 &lt;path/to/file&gt;</td>
      <td>Read the bottom 15 lines from a file (10 by default if -n option not provided.)</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/2024/September/cat,rev.png" alt="Usage of cat, tac and rev command." /></p>

<p><em>Fig: Usage of cat, tac and rev command.</em></p>

<h3 id="searching-file-contents">Searching File Contents</h3>

<p>The ability to search for and filter out what you want from a file or standard output makes working with the command line a much more efficient process.</p>

<p>The command for this is called the grep command.</p>

<p>The grep command will return all lines that match the particular piece of text (or regular expression) provided as a search term.</p>

<p>For example: <code class="language-plaintext highlighter-rouge">grep hello myfile.txt</code> will return all lines containing the word “hello” in myfile.txt and <code class="language-plaintext highlighter-rouge">ls /etc | grep *.conf</code> will return all lines with anything ending in “.conf” in data piped from the ls command.</p>

<p>Some common options when working with the grep command include:</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>grep -i</td>
      <td>Search in a case insensitive manner. (upper case and lowercase don’t matter).</td>
    </tr>
    <tr>
      <td>grep -v</td>
      <td>Invert the search. i.e return all lines that DON’T contain a certain search term.</td>
    </tr>
    <tr>
      <td>grep -c</td>
      <td>Return the number of lines (count) that match a search term rather than the lines themselves.</td>
    </tr>
    <tr>
      <td>grep -n</td>
      <td>return the line no’s also</td>
    </tr>
  </tbody>
</table>

<h2 id="file-archiving-and-compression-️">File Archiving and Compression 🗃️</h2>

<p>In this section, we will delve into how we can archive and compress files. This process is crucial to not only save space on your system but also make file transfer more efficient. Stay tuned as we explore various commands and techniques for this task.</p>

<h3 id="the-overall-process">The Overall Process</h3>

<p>Archiving and compressing files in Linux is a two-step process.</p>

<p>1) Create a Tarball</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>First, you will create what is known as a tar file or “tarball”. A tarball is a way of bundling together the files that you want to archive.
</code></pre></div></div>

<p>2) Compress the tarball with a compression algorithm</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Secondly, you will then compress that tarball with one of a variety of compression algorithms; leaving you with a compressed archive.
</code></pre></div></div>

<h3 id="1-creating-a-tarball">1. Creating a Tarball</h3>

<p>Tarballs are created using the tar command
<code class="language-plaintext highlighter-rouge">tar –cvf &lt;name of tarball&gt; &lt;file&gt;... </code></p>

<p><code class="language-plaintext highlighter-rouge">The –c option</code>: “create”. This allows us to create a tarball. [required]</p>

<p><code class="language-plaintext highlighter-rouge">The –v option</code>: “verbose”. This makes tar give us feedback on its progress. [optional]</p>

<p><code class="language-plaintext highlighter-rouge">The –f option</code>: Tells tar that the next argument is the name of the tarball. [required]</p>

<p><code class="language-plaintext highlighter-rouge">&lt;name of tarball&gt;</code>: The absolute or relative file path to where you want the tarball to be placed;</p>

<p>e.g. ~/Desktop/myarchive.tar. It is recommended that you add .tar to your proposed filename for clarity.</p>

<p><code class="language-plaintext highlighter-rouge">&lt;file&gt;</code>: The absolute or relative file paths to files that you want to insert into the tarball. You can have as many as you like and wildcards are accepted.</p>

<h3 id="11-checking-a-tarballs-contents">1.1 Checking a Tarball’s Contents</h3>

<p>Once the tarball has been created, you can check what is inside it using the tar command.</p>

<p><code class="language-plaintext highlighter-rouge">tar –tf &lt;name of tarball&gt;</code></p>

<p><code class="language-plaintext highlighter-rouge">The –t option</code>: “test-label”. This allows us to check the contents of a tarball. [required]</p>

<p><code class="language-plaintext highlighter-rouge">The –f option</code>: Tells tar that the next argument is the name of the tarball. [required]</p>

<p><code class="language-plaintext highlighter-rouge">&lt;name of tarball&gt;</code>: The absolute or relative file path to where you want the tarball to be placed;</p>

<p>e.g. ~/Desktop/myarchive.tar</p>

<h3 id="12-extracting-from-a-tar-ball">1.2 Extracting From a Tar ball</h3>

<p>Let’s say that you download a tar file from the internet and you want to extract its contents using the command line. How can you do that?</p>

<p>For this you would again use the tar command <code class="language-plaintext highlighter-rouge">tar –xvf &lt;name of tarball&gt;</code></p>

<p><code class="language-plaintext highlighter-rouge">The –x option</code>: “extract”. This allows us to extract a tarball’s contents. [required]</p>

<p><code class="language-plaintext highlighter-rouge">The –v option</code>: “verbose”. This makes tar give us feedback on its progress. [optional]</p>

<p><code class="language-plaintext highlighter-rouge">The –f option:</code> Tells tar that the next argument is the name of the tarball. [required]</p>

<p><code class="language-plaintext highlighter-rouge">&lt;name of tarball&gt;</code>: The absolute or relative file path to where the tarball is located;</p>

<p>e.g. ~/Desktop/myarchive.tar</p>

<p>cool 😎 → Extracting a tarball does not empty the tarball. You can extract from a tarball as many times as you want without affecting the tarball’s contents.</p>

<h3 id="2-compressing-tarballs">2. Compressing Tarballs</h3>

<p>Tarballs are just containers for files. They don’t by themselves do any compression, but the can be compressed using a variety of compression algorithms.</p>

<p>The main types of compression algorithms are gzip and bzip2.</p>

<p>The gzip compression algorithm tends to be faster than bzip2 but, as a trade-off, gzip usually offers less compression.</p>

<p>You can find a comparison of various compression algorithms using this excellent blog post.</p>

<h3 id="21-compressing-and-decompressing-with-gzip">2.1 Compressing and Decompressing with gzip</h3>

<table>
  <thead>
    <tr>
      <th>Comand</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Compressing with gzip</td>
      <td>gzip <name of="" tarball=""></name></td>
    </tr>
    <tr>
      <td>Decompressing with gzip</td>
      <td>gunzip <name of="" tarball=""></name></td>
    </tr>
  </tbody>
</table>

<p>When compressing with gzip, the file extension .gz is automatically added to the .tar archive.</p>

<p>Therefore, the gzip compressed tar archive would, by convention, have the file extension .tar.gz</p>

<h3 id="22-compressing-and-decompressing-with-bzip2">2.2 Compressing and Decompressing with bzip2</h3>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Compressing with bzip2</td>
      <td>bzip2 <name of="" tarball=""></name></td>
    </tr>
    <tr>
      <td>Decompressing with bzip2</td>
      <td>bunzip2 <name of="" tarball=""></name></td>
    </tr>
  </tbody>
</table>

<p>When compressing with bzip2, the file extension .bz2 is automatically added to the .tar archive.</p>

<p>Therefore, the bzip2 compressed tar archive would, by convention, have the file extension .tar.bz2</p>

<h3 id="3-doing-it-all-in-one-step">3. Doing it all in one step</h3>

<p>Because compressing tar archives is such a common function, it is possible to create a tar archive and compress it all in one step using the tar command. It is also possible to decompress and extract a compressed archive in one step using the tar command too.</p>

<p>To perform compression/decompression using gzip compression algorithm in the tar command, you provide the z option in addition to the other options required. [<strong>Just add z to the basic commands</strong>]</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Creating a tarball and compressing via gzip</td>
      <td>tar –cvzf <name of="" tarball=""> <file>...</file></name></td>
    </tr>
    <tr>
      <td>Decompressing a tarball and extracting via xzip</td>
      <td>tar –xvzf <name of="" tarball=""></name></td>
    </tr>
  </tbody>
</table>

<p>To perform compression/decompression using bzip2 compression algorithm in the tar command, you provide the j option to the other options required. <strong>[Just add j to the basic commands]</strong></p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Creating a tarball and compressing via bzip2</td>
      <td>tar –cvjf <name of="" tarball=""> <file>…</file></name></td>
    </tr>
    <tr>
      <td>Decompressing a tarball and extracting via bzip2</td>
      <td>tar –xvjf <name of="" tarball=""></name></td>
    </tr>
  </tbody>
</table>

<p>To perform compression/decompression using the xzip compression algorithm in the tar command, you provide the J option to the other options required.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Creating a tarball and compressing via xzip</td>
      <td>tar –cvJf <name of="" tarball=""> <file>...</file></name></td>
    </tr>
    <tr>
      <td>Decompressing a tarball and extracting via xzip</td>
      <td>tar –xvJf <name of="" tarball=""></name></td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/2024/September/zip-unzip.png" alt="Creating tarballs using different compression algorithms" /></p>

<p><em>Fig: Creating tarballs using different compression algorithms</em></p>

<h3 id="4-creating-zip-files">4. Creating .zip files</h3>

<p>Although .tar.gz and .tar.bz2 archives are the archives of choice on Linux, .zip archives are common on other operating systems such as Windows and Mac OSX.</p>

<p>In order to create such archives, you can use the following commands.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Creating a .zip archive</td>
      <td>zip <name of="" zipfile=""> <file>...</file></name></td>
    </tr>
    <tr>
      <td>Extracting a .zip archive</td>
      <td>unzip <name of="" zipfile=""></name></td>
    </tr>
  </tbody>
</table>

<p><code class="language-plaintext highlighter-rouge">&lt;name of zipfile&gt;</code>: The absolute or relative file path to the .zip file e.g. ~/ myarchive.zip</p>

<p><code class="language-plaintext highlighter-rouge">&lt;file&gt;</code>: The absolute or relative file paths to files that you want to insert into the .zip file. You can have as many as you like and wildcards are accep</p>

<p><img src="/assets/2024/September/unzip.png" alt="Zipping and unzipping" /></p>

<p><em>Fig: Zipping and unzipping</em></p>

<p>That’s all for this blog, I hope you found this helpful. ❤️❤️</p>]]></content><author><name></name></author><category term="Linux" /><summary type="html"><![CDATA[Welcome to our comprehensive guide on improving your Command Line skills, where we primarily focus on the Linux-based command line. This emphasises Linux because most commands are identical across Linux and Windows, with just a few exceptions. This blog will explore various commands related to the Linux file system, their applications, and how to use them effectively to enhance your navigation and manipulation of the Linux operating system.]]></summary></entry><entry><title type="html">Transformer of AI World</title><link href="http://localhost:4000/ai/2023/06/23/Transformer_of_ai_world.html" rel="alternate" type="text/html" title="Transformer of AI World" /><published>2023-06-23T10:00:10+05:30</published><updated>2023-06-23T10:00:10+05:30</updated><id>http://localhost:4000/ai/2023/06/23/Transformer_of_ai_world</id><content type="html" xml:base="http://localhost:4000/ai/2023/06/23/Transformer_of_ai_world.html"><![CDATA[<h2 id="introduction-">Introduction 🚀</h2>

<p>Are you interested in natural language processing? 🤔 If so, you might have heard of the Transformer, a neural network architecture that has achieved state-of-the-art results in several NLP tasks 🏆, such as machine translation 🌍, text classification 📊, and language modeling 📚. In this blog, we’ll explore what the Transformer is, how it works, its advantages and disadvantages, and some of its applications. 🧐</p>

<h2 id="definition-">Definition 📖</h2>

<p>The Transformer is a type of neural network architecture that relies heavily on attention mechanisms 👀. It was introduced in 2017 by Vaswani et al. and has since become one of the most popular neural network architectures in the field of natural language processing. 🌟</p>

<p>Its success is largely due to its ability to leverage attention mechanisms, which enable the model to focus on specific parts of the input sequence 🔍. This allows the Transformer to process long sequences of text more efficiently than traditional recurrent neural networks. 🚀</p>

<h1 id="working-️">Working ⚙️</h1>

<p>The Transformer architecture is a powerful deep learning model used for natural language processing. It is composed of two main parts: an encoder 🔒 and a decoder 🔓.</p>

<p>The encoder, which is the first part of the model, processes the input sequence by encoding its information into a set of vectors 📊. These vectors capture the meaning of the input sequence and are then passed onto the decoder. 🔄</p>

<p>The decoder is responsible for generating the output sequence, such as a translation or a summary 📝. It does this by decoding the vectors produced by the encoder and generating a new sequence of words based on the encoded information. 🎨</p>

<p><img src="/assets/2024/September/transformers.png" alt="Fig: Transformer - model architecture [[Vaswani et al. (2017)](https://arxiv.org/pdf/1706.03762.pdf)]" /></p>

<p><em>Fig: Transformer - model architecture [<a href="https://arxiv.org/pdf/1706.03762.pdf">Vaswani et al. (2017)</a>]</em></p>

<h2 id="encoder-">Encoder 🔒</h2>

<p>The Encoder is made up of N=6 identical layers, each of which has 2 sub-layers. 🧱🔄</p>

<ol>
  <li><strong>Multi-Head Self-Attention Mechanism 🧠👀</strong>: This mechanism calculates multiple sets of attention weights using self-attention, with each set focusing on a different part of the input sequence.</li>
  <li>
    <p><strong>Feed Forward Network 🔄➡️</strong>: This is a fully connected feed-forward network that is applied to each position separately and identically. For this, two linear transformations are used with ReLU activation between them:</p>

    <p>$FFN(x) = \max(0, xW_1 + b_1)W_2 + b_2$</p>

    <p>Here, $x$ is the input vector, $W_1$ and $W_2$ are weight matrices, $b_1$ and $b_2$ are bias vectors, and $\max(0, x)$ is the ReLU activation function. 🧮📊</p>
  </li>
</ol>

<h2 id="decoder-">Decoder 🔓</h2>

<p>The decoder is also composed of N=6 identical layers. However, the decoder adds an extra layer: 🔓🔢</p>

<ol>
  <li><strong>Multi-Head Attention 🎭👥</strong>: This layer does not use self-attention, but instead calculates attention weights over the output of the encoder stack. Its keys and values come from the output of the encoder layer, while its queries come from the previous decoder layer.</li>
</ol>

<p>After each sub-layer, normalization is performed using layer normalization 📏. This process helps maintain stable activations throughout the network. 🧠</p>

<h4 id="normalization">Normalization</h4>

<p>Normalization involves scaling the input features to have zero mean and unit variance, which helps reduce the effect of differences in the scale of the input features. 📊🔍</p>

<p>Layer normalization is defined as: 🧮</p>

<p>$LayerNorm(x) = \gamma \odot \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta$</p>

<p>where $x$ is the input vector, $\mu$ and $\sigma$ are the mean and standard deviation of $x$, respectively, $\epsilon$ is a small constant to prevent division by zero, $\odot$ is element-wise multiplication, and $\gamma$ and $\beta$ are learnable scale and shift parameters, respectively. 🔬</p>

<p>In addition, positional encoding is added to the input embeddings of the encoder and decoder stacks. 🎯🔢</p>

<h4 id="positional-encoding">Positional encoding</h4>

<p>The positional encoding is defined as: 🧘🏽</p>

<p>$PE_{(pos,2i)} = \sin(pos / 10000^{2i/d_{model}})$</p>

<p>$PE_{(pos,2i+1)} = \cos(pos / 10000^{2i/d_{model}})$</p>

<p>where $pos$ is the position of the token in the sequence, $i$ is the dimension of the embedding vector, and $d_{model}$ is the total number of dimensions. 📐</p>

<p>These layers allow the model to learn complex patterns and relationships within the input and output sequences. 🕸️ The self-attention layers help the model focus on the most important parts of the input sequence 🔍, while the feed-forward layers help it make predictions based on the encoded information. 🎯</p>

<p>Think in context of training, both input and output are provided. During backpropagation, the weight matrices of the scaled dot-product attention are updated, as well as the parameters of the feedforward neural layers. This process aims to improve the accuracy of the next output and make the attention weights more reasonable. 🔄📈</p>

<p>Overall, the Transformer architecture is a highly effective model for a wide range of natural language processing tasks, including machine translation 🌍 and text summarization 📝. By using multiple layers of self-attention and feed-forward neural networks, it is able to capture complex relationships and patterns within the input and output sequences, making it a powerful tool for language understanding and generation. 🚀🗣️</p>

<p>Let’s dive into the attention mechanism used in transformers! 🤿🧠</p>

<h2 id="multi-head-attention-">Multi-Head Attention 🎭🔍</h2>

<p>The multi-head attention operation is like a symphony of smaller attention operations 🎻🎺. These mini-operations work together in parallel, creating a harmonious final output 🎵.</p>

<p>Here’s the magical equation for multi-head attention 🧙‍♂️:</p>

<p>$\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, …, \text{head}_h)W^O$</p>

<p>Each smaller operation is called an attention “head” 👤. The output of the $i$-th head is calculated like this 🧮:</p>

<p>$\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$</p>

<p>The weight matrices $W_i^Q$, $W_i^K$, and $W_i^V$ are unique to each $i$-th head, like fingerprints 👆🏼.</p>

<p><img src="/assets/2024/September/multi%20head.png" alt="Fig: Multi-Head Attention consists of several attention layers running in parallel. [[Vaswani et al. (2017)](https://arxiv.org/pdf/1706.03762.pdf)]" /></p>

<p><em>Fig: Multi-Head Attention consists of several attention layers running in parallel. [<a href="https://arxiv.org/pdf/1706.03762.pdf">Vaswani et al. (2017)</a>]</em></p>

<p>🔑 Q, 🗝️ K, and 💎 V are the query, key, and value matrices, respectively. The number of attention heads is represented by h 🧠. The final output of the multi-head attention operation is obtained by concatenating the output of each attention head and multiplying it by a weight matrix 🧮 W⁰.</p>

<h2 id="scaled-dot-product-attention-">Scaled Dot-Product Attention 🔍</h2>

<p>The scaled dot-product attention operation can be defined as: 🧮</p>

<p>$\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$</p>

<p>Here, 🔑 Q, 🗝️ K, and 💎 V are the query, key, and value matrices, respectively, and 📏 d_k is the dimension of the key vectors.</p>

<p>Self-attention 🧠👀 is a type of scaled dot-product attention. In self-attention, the query, key, and value vectors are all derived from the same sequence, allowing the model to focus on different parts of the sequence at different times. 🔍🔄</p>

<p>For example, in the case of an encoder, the keys 🗝️, values 💎, and queries 🔑 come from the output of the previous layer of the encoder. 🔁🧱</p>

<h3 id="coding-view">Coding View</h3>

<p>Here is an example of a Transformer architecture implemented in Python using PyTorch:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Transformer</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span><span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
        <span class="n">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span><span class="nc">DecoderLayer</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">output_seq</span><span class="p">):</span>
        <span class="n">enc_output</span> <span class="o">=</span> <span class="n">input_seq</span>

        <span class="k">for</span> <span class="n">enc_layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">:</span>
            <span class="n">enc_output</span> <span class="o">=</span> <span class="nf">enc_layer</span><span class="p">(</span><span class="n">enc_output</span><span class="p">)</span>

        <span class="n">dec_output</span> <span class="o">=</span> <span class="n">output_seq</span>

        <span class="k">for</span> <span class="n">dec_layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">:</span>
            <span class="n">dec_output</span> <span class="o">=</span> <span class="nf">dec_layer</span><span class="p">(</span><span class="n">dec_output</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">dec_output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>

</code></pre></div></div>

<p>The self-attention mechanism 🧠👀 is used in the <code class="language-plaintext highlighter-rouge">EncoderLayer</code> 🔒 and <code class="language-plaintext highlighter-rouge">DecoderLayer</code> 🔓 classes, which are used to define the encoder and decoder layers of the Transformer architecture, respectively.</p>

<p>Here are the <code class="language-plaintext highlighter-rouge">EncoderLayer</code> 🔒 and <code class="language-plaintext highlighter-rouge">DecoderLayer</code> 🔓 classes used to define the encoder and decoder layers of the Transformer architecture, respectively: 🏗️</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">multi_head_attention</span> <span class="o">=</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layer_norm1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layer_norm2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">):</span>
        <span class="n">attention_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">multi_head_attention</span><span class="p">(</span><span class="n">input_seq</span><span class="p">)</span>
        <span class="n">attention_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">attention_output</span><span class="p">)</span>
        <span class="n">norm_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">layer_norm1</span><span class="p">(</span><span class="n">input_seq</span> <span class="o">+</span> <span class="n">attention_output</span><span class="p">)</span>
        <span class="n">ff_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">feed_forward</span><span class="p">(</span><span class="n">norm_output</span><span class="p">)</span>
        <span class="n">ff_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">ff_output</span><span class="p">)</span>
        <span class="n">output_seq</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">layer_norm2</span><span class="p">(</span><span class="n">norm_output</span> <span class="o">+</span> <span class="n">ff_output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output_seq</span>

<span class="k">class</span> <span class="nc">DecoderLayer</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">DecoderLayer</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">self_attention</span> <span class="o">=</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">source_attention</span> <span class="o">=</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layer_norm1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layer_norm2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layer_norm3</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output_seq</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">):</span>
        <span class="n">self_attention_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">self_attention</span><span class="p">(</span><span class="n">output_seq</span><span class="p">)</span>
        <span class="n">self_attention_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">self_attention_output</span><span class="p">)</span>
        <span class="n">norm_output1</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">layer_norm1</span><span class="p">(</span><span class="n">output_seq</span> <span class="o">+</span> <span class="n">self_attention_output</span><span class="p">)</span>
        <span class="n">source_attention_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">source_attention</span><span class="p">(</span><span class="n">norm_output1</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">)</span>
        <span class="n">source_attention_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">source_attention_output</span><span class="p">)</span>
        <span class="n">norm_output2</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">layer_norm2</span><span class="p">(</span><span class="n">norm_output1</span> <span class="o">+</span> <span class="n">source_attention_output</span><span class="p">)</span>
        <span class="n">ff_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">feed_forward</span><span class="p">(</span><span class="n">norm_output2</span><span class="p">)</span>
        <span class="n">ff_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">ff_output</span><span class="p">)</span>
        <span class="n">output_seq</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">layer_norm3</span><span class="p">(</span><span class="n">norm_output2</span> <span class="o">+</span> <span class="n">ff_output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output_seq</span>

</code></pre></div></div>

<h3 id="advantages-and-disadvantages-">Advantages and Disadvantages 🌟🚫</h3>

<p>One advantage of the Transformer is its ability to process long sequences of text efficiently 🚀. This makes it well-suited for tasks such as machine translation 🌍 and language modeling 📚.</p>

<p>One disadvantage of the Transformer is its high computational cost 💻💰, which can make it difficult to train on large datasets 📊.</p>

<h3 id="applications-️">Applications 🛠️</h3>

<p>The Transformer has achieved state-of-the-art results in several natural language processing tasks, such as machine translation 🌐, text classification 📋, and language modeling 📝. It has also been used in various applications, such as speech recognition 🎙️, text generation ✍️, and image captioning 🖼️.</p>

<h3 id="useful-resources-">Useful Resources 📚</h3>

<p>If you’re interested in learning more about the Transformer, here are some useful resources to get you started:</p>

<ul>
  <li><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> 📄 - The original paper introducing the Transformer architecture.</li>
  <li><a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a> 🎨 - A visual guide to the Transformer architecture.</li>
  <li><a href="http://peterbloem.nl/blog/transformers">Transformers from Scratch</a> 🔨 - A step-by-step guide to implementing the Transformer from scratch.</li>
</ul>

<p>I hope you found this blog helpful in understanding the Transformer and its applications in natural language processing 🧠💬. If you have any questions or comments, feel free to leave them below! 💡💬</p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Introduction 🚀]]></summary></entry><entry><title type="html">Understanding git</title><link href="http://localhost:4000/web/2023/04/09/Understanding-Git.html" rel="alternate" type="text/html" title="Understanding git" /><published>2023-04-09T15:08:10+05:30</published><updated>2023-04-09T15:08:10+05:30</updated><id>http://localhost:4000/web/2023/04/09/Understanding-Git</id><content type="html" xml:base="http://localhost:4000/web/2023/04/09/Understanding-Git.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Git is a distributed version control system that enables developers to track changes in their code and collaborate on projects with others. Created by Linus Torvalds in 2005, Git has since become one of the most popular version control systems in use today.</p>

<p>GitHub is a web-based platform that uses Git for version control and collaboration. It provides hosting for software development and a range of features for managing projects, such as bug tracking, task management, and wikis.</p>

<p>GitHub was created by Tom Preston-Werner, Chris Wanstrath, and PJ Hyett in 2008. You can remember the basic difference by Dates.</p>

<h2 id="features-of-git">Features of Git</h2>

<p>Git has several features, including:</p>

<ul>
  <li><strong>Version control:</strong> Git allows developers to track changes in their code and easily revert to previous versions if necessary.</li>
  <li><strong>Collaboration:</strong> Git enables developers to work on projects with others by sharing their code and collaborating on changes.</li>
  <li><strong>Branching:</strong> Git allows developers to create separate lines of development, called branches, which can be used to work on new features or bug fixes without affecting the main codebase.</li>
  <li><strong>Command line interface:</strong> Git can be used through a series of commands, which can be accessed through the command line interface.</li>
</ul>

<h2 id="how-does-git-works">How does Git Works?</h2>

<p>Git works by creating a repository, which is a directory where all of the project’s files and history are stored. Whenever a change is made to a file in the repository, Git records that change and stores it as a new version of the file. Developers can then easily view and revert to previous versions of the code if necessary.</p>

<p>Git uses a series of commands that developers can use to interact with the repository.</p>

<p>Now, let’s read about different commands used in different tasks: -</p>

<h3 id="starting-new-project-in-git">Starting new Project in Git</h3>

<p>To start a new project in Git, you need to create a new repository. This can be done using the <code class="language-plaintext highlighter-rouge">git init</code> command. First, navigate to the directory where you want to create the repository using the <code class="language-plaintext highlighter-rouge">cd</code> command. Then, use the <code class="language-plaintext highlighter-rouge">git init</code> command to create a new repository in that directory.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd /path/to/your/directory
git init
</code></pre></div></div>

<p>Once the repository has been created, you can start adding files to it using the <code class="language-plaintext highlighter-rouge">git add</code> command, and then commit those changes using the <code class="language-plaintext highlighter-rouge">git commit</code> command.</p>

<p>You can also clone an existing project into your directory, using HTTPS, SSH or GitHub CLI.</p>

<p><img src="/assets/2024/September/clone_repo.png" alt="Fig: Ways to Clone an existing Project" /></p>

<p>Fig: Ways to Clone an existing Project</p>

<ul>
  <li>HTTPS → <code class="language-plaintext highlighter-rouge">git clone [HTTPS_link]</code></li>
  <li>
    <p>How to generate SSH (Secure Shell Protocol) Key</p>

    <p>To access a repository using SSH, you need to generate a public SSH key and add it to your GitHub account.</p>

    <ol>
      <li>Generate a new SSH key by running the following command in your terminal: <code class="language-plaintext highlighter-rouge">ssh-keygen -t rsa -b 4096 -C "your_email@example.com"</code></li>
      <li>
        <p>Follow the prompts to create a passphrase and save the key.</p>

        <p><img src="/assets/2024/September/Generate%20SSH%20Key.png" alt="Fig: Generating SSH Key" /></p>

        <p>Fig: Generating SSH Key</p>

        <p>Note → [Do not enter file name, we need files inside .ssh folder of User.]</p>
      </li>
      <li>Add the SSH key to your GitHub account by going to your account settings and selecting “SSH and GPG keys”. Click “New SSH key” and paste the contents of your public key into the text box.</li>
      <li>
        <p>Test your SSH connection by running the command <code class="language-plaintext highlighter-rouge">ssh -T git@github.com</code>. You should receive a message indicating that you’ve successfully authenticated.</p>

        <p><img src="/assets/2024/September/Generate%20SSH%20Key.png" alt="Fig: Authenticating SSH Key" /></p>

        <p>Fig: Authenticating SSH Key</p>

        <p>Note → [It shows shell access not provided because it is not necessary for most users. You can still use CMD.]</p>
      </li>
    </ol>

    <p>You can learn more about setting up SSH keys in GitHub by reading the <a href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account">official documentation</a> and <a href="https://www.youtube.com/watch?v=k805rTsX_iI">Youtube</a>.</p>
  </li>
  <li>SSH → <code class="language-plaintext highlighter-rouge">git clone ssh:[SSH_link]</code></li>
  <li>GitHub CLI → <code class="language-plaintext highlighter-rouge">gh repo clone [user_name]/[repo_name]</code></li>
</ul>

<h3 id="taking-snapshots-in-git">Taking Snapshots in Git</h3>

<p>A <strong>snapshot</strong> in Git refers to a saved version of the code at a specific point in time. Every time a change is made to a file in the repository, Git records a new snapshot of that file. Developers can then use Git to view and revert to previous snapshots if necessary. Snapshots are stored in the repository as commits, which are identified by a unique SHA-1 hash.</p>

<p>Snapshotting is a two-step process. The two-step process in Git consists of staging and committing changes.</p>

<ol>
  <li><strong>Staging changes</strong></li>
</ol>

<p>The staging area, also known as the index, is a feature in Git that allows developers to prepare changes for committing. Before changes can be committed to the repository, they must first be added to the staging area using the <code class="language-plaintext highlighter-rouge">git add</code> command.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git add [file-name]</td>
      <td>Add a file to the staging area</td>
    </tr>
    <tr>
      <td>git add -A</td>
      <td>Add all changed files to the staging area</td>
    </tr>
    <tr>
      <td>git rm -r [file_name]</td>
      <td>Remove a file from staging area</td>
    </tr>
    <tr>
      <td>git add -p</td>
      <td>Opens the patch mode</td>
    </tr>
  </tbody>
</table>

<ol>
  <li><strong>Committing changes</strong></li>
</ol>

<p>Once changes have been added to the staging area, they can be committed to the repository using the <code class="language-plaintext highlighter-rouge">git commit</code> command. This allows developers to selectively choose which changes to commit, rather than committing all changes at once.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git status</td>
      <td>Shows the status of changes as untracked, modified, or staged.</td>
    </tr>
    <tr>
      <td>git commit m “[commit message]”</td>
      <td>Saves the snapshot to the project-history and completes change-tracking process.</td>
    </tr>
  </tbody>
</table>

<h3 id="branching-and-merging">Branching and Merging</h3>

<p>Branching in Git allows developers to create separate lines of development, called branches, which can be used to work on new features or bug fixes without affecting the main codebase. This allows developers to experiment with new ideas and features without impacting the stability of the main codebase.</p>

<p>Here, you need to understand the difference between local branch and remote branch. A <strong>local branch</strong> is a branch that exists only on your local machine, while a <strong>remote branch</strong> is a branch that exists on a remote repository, such as on GitHub. Local branches can be used to work on new features or bug fixes without affecting the main codebase, and can later be merged into the main branch using Git. Remote branches can be used to collaborate with others on a project, and changes made to the remote branch can be pulled into your local branch using Git.</p>

<p>You can use following commands to deal with branches:</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git branch</td>
      <td>Lists all the branches for the current repository</td>
    </tr>
    <tr>
      <td>git branch -a</td>
      <td>Lists all branches, including local and remote</td>
    </tr>
    <tr>
      <td>git branch [branch_name]</td>
      <td>Creates a new branch</td>
    </tr>
    <tr>
      <td>git branch -d [branch_name]</td>
      <td>Deletes a branch</td>
    </tr>
    <tr>
      <td>git branch -D</td>
      <td>Deletes local branch regardless of push and merge status</td>
    </tr>
    <tr>
      <td>git push origin –delete [branch_name]</td>
      <td>Deletes a remote branch</td>
    </tr>
    <tr>
      <td>git checkout -b [branch_name]</td>
      <td>Creates a new branch and switches to it</td>
    </tr>
    <tr>
      <td>git checkout -b [branch_name] origin/[branch_name]</td>
      <td>Clones a remote branch and switches to it</td>
    </tr>
    <tr>
      <td>git branch -m [old_branch_name] [new_branch_name]</td>
      <td>Renames a local branch</td>
    </tr>
    <tr>
      <td>git checkout [branch_name]</td>
      <td>Switches to an existing branch</td>
    </tr>
    <tr>
      <td>git checkout -</td>
      <td>Switches to the last checked out branch</td>
    </tr>
    <tr>
      <td>git checkout .</td>
      <td>discards all changes made to the current directory and returns it to the last committed state.</td>
    </tr>
    <tr>
      <td>git branch –merged</td>
      <td>list the branches that have been merged into the currently checked-out branch</td>
    </tr>
  </tbody>
</table>

<p>Once you’ve made changes to the new branch, you can merge those changes back into the main branch using the <code class="language-plaintext highlighter-rouge">git merge [branch-name]</code> command. This combines the changes from the specified branch into the current branch.</p>

<p>When merging branches, Git will attempt to automatically merge the changes. However, if there are conflicts between the two branches, you may need to resolve those conflicts manually.</p>

<p>You can use following commands to do merge:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git merge <span class="o">[</span>branch-name]  <span class="c"># merge given branch into current branch</span>
git merge <span class="o">[</span>source-branch] <span class="o">[</span>target-branch]
git checkout <span class="nt">--</span><span class="o">[</span>file-name]  <span class="c"># discard the changes done in this file</span>

<span class="c"># when merge conflict arise - stop merging and return to pre-merge state</span>
git merge <span class="nt">--abort</span>  
</code></pre></div></div>

<p>In Git, you can use the <code class="language-plaintext highlighter-rouge">git stash</code> command to temporarily save changes that are not ready to be committed. This can be useful if you need to switch to a different branch or work on a different part of the project, but don’t want to commit your changes yet.</p>

<p>To stash changes, use the <code class="language-plaintext highlighter-rouge">git stash</code> command. To apply the stashed changes later, use the <code class="language-plaintext highlighter-rouge">git stash apply</code> command.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git stash</td>
      <td>Stashes changes</td>
    </tr>
    <tr>
      <td>git stash apply</td>
      <td>Applies top most stashed changes but leaves in stash</td>
    </tr>
    <tr>
      <td>git stash pop</td>
      <td>Applies top most stash changes and pop them</td>
    </tr>
  </tbody>
</table>

<p>You can also use the <code class="language-plaintext highlighter-rouge">git stash list</code> command to view a list of all stashed changes.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git stash list</td>
      <td>Lists all stashed changes</td>
    </tr>
    <tr>
      <td>git stash clear</td>
      <td>Clear all stashed changes</td>
    </tr>
    <tr>
      <td>git stash branch <branch_name></branch_name></td>
      <td>Restore previously stashed work to a new branch</td>
    </tr>
    <tr>
      <td>git stash show -p</td>
      <td>show the changes done</td>
    </tr>
  </tbody>
</table>

<p>Hey, remember branch and fork are not the same thing. A <strong>branch</strong> is a separate line of development with the same repository while A <strong>fork</strong> is a copy of the whole repository that allows you to make changes to the codebase without affecting the original repository. Forking is often used in open-source development, where developers can fork a repository, make their changes, and then submit a pull request to the original repository owner to incorporate their changes.</p>

<h3 id="updating-projects">Updating Projects</h3>

<p>To share your Git project with others, you can use the <code class="language-plaintext highlighter-rouge">git push</code> command to push your changes to a remote repository, such as on GitHub. This will allow others to access the latest version of your code and collaborate with you on the project.</p>

<p>To update your Git project with changes from a remote repository, you can use the <code class="language-plaintext highlighter-rouge">git pull</code> command. This will pull the latest changes from the remote repository and merge them with your local repository.</p>

<p>You can also use the <code class="language-plaintext highlighter-rouge">git fetch</code> command to fetch changes from a remote repository without merging them into your local repository. This can be useful if you want to review the changes before merging them.</p>

<p><strong>To push changes to a remote repository:</strong></p>

<ol>
  <li>First, add and commit your changes using the <code class="language-plaintext highlighter-rouge">git add</code> and <code class="language-plaintext highlighter-rouge">git commit</code> commands.</li>
  <li>Then, use the <code class="language-plaintext highlighter-rouge">git push</code> command to push your changes to the remote repository.</li>
</ol>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
      <th> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git push origin [branch_name]</td>
      <td>Push the changes to branch [branch_name] of remote repository [origin].</td>
      <td> </td>
    </tr>
    <tr>
      <td>git push [-u</td>
      <td>—set-upstream] origin [branch_name]</td>
      <td>Push changes to remote repository (and remember the branch)</td>
    </tr>
    <tr>
      <td>git push</td>
      <td>Push changes to the upstream branch [If set]</td>
      <td> </td>
    </tr>
    <tr>
      <td>git push origin [-d</td>
      <td>—delete] [branch_name]</td>
      <td>Delete a remote branch</td>
    </tr>
  </tbody>
</table>

<p>Remember in Git, the <strong>upstream branch</strong> refers to the branch on a remote repository that your local branch is tracking. Upstream branch works with both push and pull.</p>

<p>So when pushing changes to a remote repository, the <code class="language-plaintext highlighter-rouge">-u</code> flag or the <code class="language-plaintext highlighter-rouge">--set-upstream</code> flag sets the upstream branch for the current branch. This means that in the future, you can simply use the <code class="language-plaintext highlighter-rouge">git push</code> command without specifying the remote branch name, since Git will assume that you want to push to the upstream branch.</p>

<p>In summary, using the <code class="language-plaintext highlighter-rouge">-u</code> flag simplifies the process of pushing changes to the remote repository in the future, but is not necessary for pushing changes initially.</p>

<p>After pushing changes into remote repository, we can <strong>create a Pull request</strong>. A pull request in GitHub is a way for developers to propose changes to a repository hosted on GitHub. When a developer creates a pull request, they are essentially asking that their changes be reviewed and potentially merged into the main codebase. Other developers can review the changes and provide feedback before the pull request is merged. Pull requests are a key feature of the collaborative nature of GitHub, allowing developers to work together on open source projects and contribute to each other’s code. You can learn more about pull requests from the <a href="https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests">official GitHub documentation</a>.</p>

<p><img src="/assets/2024/September/branching.webp" alt="Branching" /></p>

<p><strong>To pull changes from a remote repository:</strong></p>

<ol>
  <li>Use the <code class="language-plaintext highlighter-rouge">git pull</code> command to pull the latest changes from the remote repository and merge them with your local repository.</li>
</ol>

<p>Similar to <code class="language-plaintext highlighter-rouge">git push</code>, when you use the <code class="language-plaintext highlighter-rouge">git pull</code> command, Git automatically pulls changes from the upstream branch if you have set upstream branch.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git pull</td>
      <td>Pull latest changes</td>
    </tr>
    <tr>
      <td>git pull origin [branch_name]</td>
      <td>Pull changes from given remote branch</td>
    </tr>
  </tbody>
</table>

<p><strong>To fetch changes from a remote repository:</strong></p>

<ol>
  <li>Use the <code class="language-plaintext highlighter-rouge">git fetch</code> command to fetch the latest changes from the remote repository.</li>
</ol>

<p>The <code class="language-plaintext highlighter-rouge">git fetch</code> command allows you to fetch the latest changes from the remote repository without merging them into your local repository. This can be useful if you want to review the changes before merging them.</p>

<p>In summary, the <code class="language-plaintext highlighter-rouge">pull</code> command is a combination of the <code class="language-plaintext highlighter-rouge">fetch</code> and <code class="language-plaintext highlighter-rouge">merge</code> commands, while the <code class="language-plaintext highlighter-rouge">fetch</code> command only downloads changes from the remote repository without merging them.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git fetch</td>
      <td>Download objects and refs from remote repository.</td>
    </tr>
  </tbody>
</table>

<h3 id="remote--remote-repository">Remote &amp; Remote Repository</h3>

<p>In Git, a remote is a version of your repository that is hosted on a remote server, such as on GitHub. A remote repository is the repository that is hosted on the remote server. Remote repositories can be used to collaborate with others on a project, and changes made to the remote repository can be pulled into your local repository using Git.</p>

<p>The <code class="language-plaintext highlighter-rouge">git remote</code> command is used to manage remote repositories. It allows you to view the remote repositories that are currently associated with your local repository, as well as add or remove remote repositories.</p>

<p>Here are some commonly used <code class="language-plaintext highlighter-rouge">git remote</code> commands:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">git remote</code>: Lists all the remote repositories that are currently associated with your local repository.</li>
  <li><code class="language-plaintext highlighter-rouge">git remote -v</code>: Lists all the remote repositories along with their corresponding URLs.</li>
  <li><code class="language-plaintext highlighter-rouge">git remote add &lt;name&gt; &lt;url&gt;</code>: Adds a new remote repository with the given name and URL to your local repository. By default, origin is the name of your remote repository [Main one].
Example →
    <ul>
      <li>git remote add origin <a href="https://github.com/user/repo.git">https://github.com/user/repo.git</a></li>
    </ul>

    <p>In this example, <code class="language-plaintext highlighter-rouge">origin</code> is the name of the remote repository, and <code class="language-plaintext highlighter-rouge">https://github.com/user/repo.git</code> is the URL of the remote repository. Once you’ve added the remote repository, you can push your changes to it using the <code class="language-plaintext highlighter-rouge">git push</code> command.</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">git remote remove &lt;name&gt;</code>: Removes the remote repository with the given name from your local repository.</li>
</ul>

<p>Overall, this allows you to work with more than one remote repository from single local repository. You can learn more about <code class="language-plaintext highlighter-rouge">git remote</code> command and its options from the <a href="https://git-scm.com/docs/git-remote">official Git documentation</a>.</p>

<h3 id="inspection-and-comparison">Inspection and Comparison</h3>

<p>Git provides several commands that allow developers to inspect and compare different versions of their code. These commands can be used to view the history of changes, identify differences between versions, and troubleshoot issues that may arise during development.</p>

<p>Here are some commonly used inspection and comparison commands:</p>

<table>
  <thead>
    <tr>
      <th>Commands</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git log</td>
      <td>Displays the commit history of the repository.</td>
    </tr>
    <tr>
      <td>git log —summary</td>
      <td>Displays detailed history</td>
    </tr>
    <tr>
      <td>git log —oneline</td>
      <td>Displays brief history</td>
    </tr>
    <tr>
      <td>git diff</td>
      <td>Shows the differences between the working directory and the most recent commit.</td>
    </tr>
    <tr>
      <td>git diff [source_branch] [target_branch]</td>
      <td>Shows difference between source and target branch.</td>
    </tr>
    <tr>
      <td>git blame</td>
      <td>Shows which commit and author last modified each line of a file.</td>
    </tr>
    <tr>
      <td>git blame -L 10, 20 [filename.txt]</td>
      <td>Will show information about line 10 to 20 only.</td>
    </tr>
    <tr>
      <td>git show</td>
      <td>Displays the details of a particular commit, including the changes that were made and the commit message.</td>
    </tr>
    <tr>
      <td>git show Head</td>
      <td>Displays details of latest commit</td>
    </tr>
    <tr>
      <td>git show [commit hash]</td>
      <td>Displays details about given commit.</td>
    </tr>
    <tr>
      <td>git show [commit hash]:[file_path]</td>
      <td>Displays details about the given file for this commit.</td>
    </tr>
    <tr>
      <td>git show <commit> --stat</commit></td>
      <td>Displays histogram</td>
    </tr>
    <tr>
      <td>git show-ref –head</td>
      <td>Find head of current branch</td>
    </tr>
  </tbody>
</table>

<p>These commands can be used in combination with one another to gain a better understanding of the history of the code and identify any issues that may need to be addressed.</p>

<p>You can learn more about Git commands from <a href="https://git-scm.com/docs">GitHub Docs</a>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In conclusion, Git is an essential tool for developers who want to keep track of changes in their code and collaborate with others. It allows developers to easily view the history of their code, revert to previous versions, and work on separate branches. By mastering the basics of Git, developers can become more efficient and effective in their work.</p>

<p>That’s all for this Blog. Hope this was worth your time. ❤️❤️</p>]]></content><author><name></name></author><category term="Web" /><summary type="html"><![CDATA[Introduction]]></summary></entry></feed>