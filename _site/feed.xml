<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-09-27T11:10:44+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">dsm Blogs</title><subtitle>This is a blog about Data Science and Machine Learning. I write about all the things I learn in this domain. I also share my knowledge with you.</subtitle><entry><title type="html">Q-Learning</title><link href="http://localhost:4000/ai/2024/09/23/Q_learning.html" rel="alternate" type="text/html" title="Q-Learning" /><published>2024-09-23T10:00:10+05:30</published><updated>2024-09-23T10:00:10+05:30</updated><id>http://localhost:4000/ai/2024/09/23/Q_learning</id><content type="html" xml:base="http://localhost:4000/ai/2024/09/23/Q_learning.html"><![CDATA[<h1 id="introduction">Introduction</h1>

<p>In this blog, we will learn about the fundamental algorithms used in reinforcement learning. It‚Äôs not about neural networks but the mathematical algorithms involved in learning.</p>

<h1 id="markov-decision-process-">Markov Decision Process ü§î</h1>

<p>Let‚Äôs understand the problem, we are trying to solve here. The environment of an agent can be modelled as a Markov decision process, where the agent can choose one of several actions and the transition probabilities depend on the chosen action. ü§ñ</p>

<p>Our aim is to find an optimal policy for the agent, by following that agent can maximize the rewards earned in the enviornment.</p>

<p><img src="/assets/2024/September/markov%20decision%20chain.png" alt="alt text" />
<em>Fig: Example of Markov chain  <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">credit for image</a></em></p>

<p>Let‚Äôs learn some of the algorithms that are used to find the optimal policy for the agent.</p>

<h2 id="state-value-iteration-algorithm-">(State) Value Iteration algorithm üîÑ</h2>

<p>In this algorithm, we calcualte the state value $V(s)$ for all states.</p>

<p>Optimal state value $V^*(s)$ of any state s, is the sum of all discounted future rewards the agent can expect on average after it reaches a state s, assuming it acts optimally. üéØ</p>

<p>$V\star(s) = max_a \sum_sP(s,a,s\prime)[R(s,a,s\prime)+\gamma.V^*(s\prime)]$  for all s</p>

<p><em>Eq: Bellman Optimality Equation</em></p>

<p>where,</p>

<ul>
  <li>$P(s,a,s‚Äô)$ = transition probability from state s to state s‚Äô, given that agent chose action a [conditional probability]. üé≤</li>
  <li>$R(s,a,s‚Äô)$ = reward the agent gets when it goes from state s to state s‚Äô, given that agent chose action a üèÜ</li>
  <li>$\gamma$ = discount factor üàπ</li>
</ul>

<p>If we increase discount factor, we will value the future rewards more.
Bellman optimality equation assumes, that we already have the optimal state value for next state s‚Äô. Since, we don‚Äôt have future value; we update state values iteratively as follows:</p>

<ol>
  <li>First initialize all the state value estimates to 0.</li>
  <li>
    <p>Iteratively update them using recurrent relation</p>

    <p>$V_{k+1}(s) \leftarrow  \underset{a}{\max} \underset{s‚Äô}{\sum}P(s,a,s‚Äô) [R(s,a,s‚Äô) + \gamma.V_k(s‚Äô)]$ for all s</p>

    <p><em>Eq: Value Iteration algorithm</em> üîÅ</p>

    <p>where</p>

    <ul>
      <li>$V_k(s)$ = estimated value of state s at the $k^{th}$ iteration</li>
    </ul>
  </li>
</ol>

<p>After the Value Iteration algorithm converges, we can derive the optimal policy $œÄ^\star$ for each state s: ü•≥</p>

\[\pi^*(s) = \underset{a}{argmax} \sum_{s'} P(s, a, s')[R(s,a,s') + \gamma V^*(s')]\]

<p>This means that for each state, the optimal action is the one that maximizes the expected sum of the immediate reward and the discounted optimal value of the next state. üí∞</p>

<h2 id="q-value-iteration-algorithm-">Q-Value Iteration algorithm üé≤</h2>

<p>This algorithm is used to find the optimal state-action values, genreally called Q-values (Quality values). üí°</p>

<p>Optimal Q-value of state-action pair (s, a), $Q^*(s, a)$, is the sum of discounted future rewards the agent can expect on average after it reaches state s and chooses an action a. üí∞</p>

<p>It involves following steps:</p>
<ol>
  <li>Initialize all Q-values estimates to 0.</li>
  <li>
    <p>Then update them using below recurrence relation. üîÑ</p>

    <p>$Q_{k+1}(s,a) \leftarrow \underset{s‚Äô}{\sum}T(s,a,s‚Äô)[R(s,a,s‚Äô)+\gamma.\underset{a‚Äô}{max} \space Q_k(s‚Äô,a‚Äô)]$</p>

    <p><em>Eq: Q-Value Iteration algorithm</em></p>

    <p>where:</p>
    <ul>
      <li>$\underset{a‚Äô}{max} \space Q_k(s‚Äô, a‚Äô)$ is the maximum Q-value for the next state s‚Äô and all possible actions a‚Äô at $k_{th}$ iteratin</li>
    </ul>
  </li>
</ol>

<p>After the Q-Value Iteration algorithm converges, we can derive the optimal policy $\pi^*(s)$ for each state s.</p>

\[\pi^*(s) = \underset{a}{argmax} \space Q^\star(s,a)\]

<p>That means, when the agent is in state s it should choose the action with the highest Q-Value for that state. üèÜ</p>

<p>Let‚Äôs apply the Q-Value Iteration algorithm to MDP given in above image:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># shape=[s, a, s']  # row - current state, column = action
# s2 to s0 given action a1 transition probability = [2][1][0]
</span><span class="n">transition_probabilities</span> <span class="o">=</span> <span class="p">[</span> 
		<span class="p">[[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]],</span> 
		<span class="p">[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="bp">None</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span> 
		<span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="bp">None</span><span class="p">]</span>
	<span class="p">]</span>

<span class="c1"># shape=[s, a, s']
</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">[</span>  
		<span class="p">[[</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> 
		<span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">50</span><span class="p">]],</span> 
		<span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">+</span><span class="mi">40</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
	<span class="p">]</span>

<span class="c1"># from s0, s1, s2
</span><span class="n">possible_actions</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>   

<span class="c1"># Initialize Q-Values
</span><span class="n">Q_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">full</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="p">)</span>  <span class="c1"># -np.inf for impossible actions
</span><span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">actions</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">possible_actions</span><span class="p">):</span>
	<span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">actions</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>     <span class="c1"># 0 for possible actions
</span>	
<span class="c1"># Q-Value Iteration algorithm
</span><span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.90</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
	<span class="n">Q_prev</span> <span class="o">=</span> <span class="n">Q_values</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
	
	<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
		<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">possible_actions</span><span class="p">[</span><span class="n">s</span><span class="p">]:</span>

			<span class="n">Q_values</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">([</span><span class="n">transition_probabilities</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="n">a</span><span class="p">][</span><span class="n">sp</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">rewards</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="n">a</span><span class="p">][</span><span class="n">sp</span><span class="p">]</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">Q_prev</span><span class="p">[</span><span class="n">sp</span><span class="p">]))</span>
				<span class="k">for</span> <span class="n">sp</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)])</span>
                        
<span class="nf">print</span><span class="p">(</span><span class="n">Q_values</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Best action for each state: </span><span class="sh">"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">Q_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># [[18.91891892 17.02702702 13.62162162]
#  [ 0.                -inf -4.87971488]
#  [       -inf 50.13365013        -inf]]
# Best action for each state  [0 0 1]
</span></code></pre></div></div>

<p>Using above algorithm we can find the best policy for the agent.</p>

<h1 id="q-learning-">Q-Learning ü§ñ</h1>

<p>If you notice in the above MDP diagram, the transition probabilities and rewards are given us in advance. That‚Äôs not the case in real word üåç, now comes the role of Q-Learning algorithm. <strong>Q-Learning algorithm</strong> is an adaptation of the Q-Value Iteration algorithm to the situation where the transition probabilities and the rewards are initially unknown.</p>

<p>This algorithm is useful for problems where the environment is fully observable, and the agent can learn by trial and error. Q-learning has been successfully applied to problems such as game playing, robotics, and natural language processing. üß†ü§ñ</p>

<p>This is an example of <strong>model-free reinforcement learning</strong>, where the transition probabilities and the rewards are initially unknown and agent has to learn these by direct interactions and experiences.</p>

<p>$Q(s,a) \underset {\alpha}{\leftarrow} r + \gamma.\underset{a‚Äô}{max} \space Q(s‚Äô, a‚Äô)$</p>

<p><em>Eq: Q-Learning algorithm</em></p>

<p>$ old \underset {\alpha}{\leftarrow} new ‚áí old(1-a) + a*new$ [This is how be interpret the above equation]</p>

<h2 id="q-learning-algorithm-">Q-learning algorithm üß†</h2>

<ol>
  <li>Initialize the Q-table with arbitrary values for all state-action pairs.</li>
  <li>Observe the current state.</li>
  <li>Select an action to take based on the current state and the values in the Q-table. This can be done using an exploration-exploitation strategy such as epsilon-greedy.</li>
  <li>Take the selected action and observe the reward and the new state. (a, r, s‚Äô)</li>
  <li>
    <p>Update the Q-value for the state-action pair that was just taken based on the observed reward and the maximum Q-value for the new state.</p>

    <p>The Q-learning algorithm uses the following equation to update the Q-value for a state-action pair:</p>

    <p>$Q(s,a) {\leftarrow} (1-\alpha)Q(s,a) + \alpha(  r + \gamma.\underset{a‚Äô}{max} \space Q(s‚Äô, a‚Äô))$</p>

    <p>Where:</p>

    <ul>
      <li>Q(s, a) is the Q-value for state s and action a</li>
      <li>Œ± is the learning rate, which determines how much the Q-value is updated in each iteration</li>
      <li>r is the reward received for taking action a in state s</li>
      <li>Œ≥ is the discount factor, which determines the importance of future rewards</li>
      <li>$\underset{a‚Äô}{max} \space Q(s‚Äô, a‚Äô)$ is the maximum Q-value for the next state s‚Äô and all possible actions a‚Äô (maximum future reward estimate)</li>
      <li>s‚Äô is the next state reached after taking action a in state s</li>
    </ul>
  </li>
  <li>Repeat üîÑ steps 2-5 until the algorithm converges or a maximum number of iterations is reached.</li>
</ol>

<p>The optimal policy üèÜ can be derived by selecting the action with the highest Q-value for each state as in Q-value Iteration algorithm.</p>

<p>Let‚Äôs implement Q-Learning algorithm using open AI gym environment (Taxi-v3). üöï</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="nf">make</span><span class="p">(</span><span class="sh">'</span><span class="s">Taxi-v3</span><span class="sh">'</span><span class="p">)</span>

<span class="n">Q_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="n">env</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">n</span><span class="p">,</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span><span class="p">])</span>

<span class="c1"># exploration policy
</span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Exploration rate
</span>
<span class="k">def</span> <span class="nf">exploration_policy</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="nf">sample</span><span class="p">()</span>  <span class="c1"># Explore
</span>    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">])</span>  <span class="c1"># Exploit
</span></code></pre></div></div>

<p>Q-Learning algorithm with learning rate decay: ‚ò¢Ô∏è</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Hyperparameters
</span><span class="n">alpha0</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Initial learning rate
</span><span class="n">decay</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>  <span class="c1"># Discount factor
</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">reset</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
    
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="nf">exploration_policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        
        <span class="c1"># Q-learning update
</span>        <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">episode</span> <span class="o">*</span> <span class="n">decay</span><span class="p">)</span>
        
        <span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">*=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span>
        <span class="n">Q_values</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">+=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">Q_values</span><span class="p">[</span><span class="n">next_state</span><span class="p">]))</span>
        
        <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
</code></pre></div></div>

<p><img src="/assets/2024/September/Q_learning.png" alt="Fig: The Q-Value Iteration algorithm (left) versus the Q-Learning algorithm (don‚Äôt know anything) (right)" /></p>

<p><em>Fig: The Q-Value Iteration algorithm (left) versus the Q-Learning algorithm (don‚Äôt know anything) (right) <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">credit for image</a></em></p>

<p>Obviously, not knowing the transition probabilities or the rewards makes finding the optimal policy significantly harder!</p>

<h3 id="advantage">Advantage</h3>

<p>It can learn optimal policies without requiring a model of the environment. (Model-free reinforcement learning algorithm).  Instead, it learns directly from experience by updating the Q-values based on observed rewards and transitions between states.</p>

<h3 id="disadvantage">Disadvantage</h3>

<p>It can be computationally expensive and may require a large amount of data to converge to an optimal solution.</p>

<p>Overall, Q-learning is a powerful technique with many potential applications, but it is important to carefully consider the problem and the available data before choosing a Q-learning approach.</p>

<h2 id="references">References</h2>

<ol>
  <li>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Buy here</a></li>
</ol>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2024/09/15/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2024-09-15T15:08:10+05:30</published><updated>2024-09-15T15:08:10+05:30</updated><id>http://localhost:4000/jekyll/update/2024/09/15/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/09/15/welcome-to-jekyll.html"><![CDATA[<p>You‚Äôll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>Jekyll requires blog post files to be named according to the following format:</p>

<p><code class="language-plaintext highlighter-rouge">YEAR-MONTH-DAY-title.MARKUP</code></p>

<p>Where <code class="language-plaintext highlighter-rouge">YEAR</code> is a four-digit number, <code class="language-plaintext highlighter-rouge">MONTH</code> and <code class="language-plaintext highlighter-rouge">DAY</code> are both two-digit numbers, and <code class="language-plaintext highlighter-rouge">MARKUP</code> is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span></code></pre></figure>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll‚Äôs GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[You‚Äôll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.]]></summary></entry><entry><title type="html">Gradient Descent</title><link href="http://localhost:4000/ai/2024/08/03/Gradient_descent.html" rel="alternate" type="text/html" title="Gradient Descent" /><published>2024-08-03T15:08:10+05:30</published><updated>2024-08-03T15:08:10+05:30</updated><id>http://localhost:4000/ai/2024/08/03/Gradient_descent</id><content type="html" xml:base="http://localhost:4000/ai/2024/08/03/Gradient_descent.html"><![CDATA[<p>In this blog post, we will understand the underlying algorithm for training neural networks. We will discuss gradient descent, the most basic step of training any model, and backpropagation.</p>

<h1 id="gradient-descent">Gradient Descent</h1>

<p>The gradient is, simply a row vector of a function‚Äôs partial derivatives. It represents the direction and rate of the steepest increase of a function.</p>

<p>Example: gradient $\nabla f$ of the function $f(a, b, c)  = ab^2 + 2c^3$, where the variables in order, are a, b, and c:</p>

<p>$\nabla f = (\frac{\partial f}{\partial a} \frac{\partial f}{\partial b} \frac{\partial f}{\partial c}) = (b^2 \space\space\space\space 2ab \space\space\space\space 6c^2)$</p>

<p>In basic calculus, with a simple algebraic function such as a polynomial, a standard optimization process is to:</p>

<ol>
  <li>take the derivative of the function</li>
  <li>set the derivative equal to 0, and then</li>
  <li>solve for the parameters (inputs) that satisfy this equation.</li>
</ol>

<p>Since, ANNs functions are very complicated, solving for 0 is not possible. Thus, <strong>heuristic methods are often used</strong> (trail &amp; error).</p>

<p>Gradient descent is a heuristic method that starts at a random point and iteratively moves in the direction (hence ‚Äúgradient‚Äù) that decreases (hence ‚Äúdescent‚Äù) the function that we want to minimize, which is usually a cost function. With enough of these steps in the decreasing direction, a local of these steps in the decreasing direction, a local minimum can theoretically be reached.</p>

<p>Colloquially, think of it as playing a game of ‚Äúhot‚Äù and ‚Äúcold‚Äù until the improvement becomes negligible.</p>

<p><img src="/assets/2024/September/gradient%20descent.png" alt="nse-6188589518431236078-512387566.png" /></p>

<p>The gradient indicates the direction of steepest ascent of the function, and its negative is the direction of steepest descent.</p>

<h3 id="gradient-descent-algorithm">Gradient Descent Algorithm</h3>

<ol>
  <li>Initialize the weights and biases of the neural network with random values.</li>
  <li>Do the following until the cost stops improving or a fixed number of iterations:
    <ol>
      <li>Calculate cost function value with current parameters.</li>
      <li>Calculate the gradient of the cost function w.r.t to its parameters.</li>
      <li>Update the parameters by taking a small step in the opposite direction of the gradient.</li>
    </ol>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
	<span class="n">cost</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>  
	<span class="n">new_point</span> <span class="o">=</span> <span class="n">point</span> <span class="o">-</span> <span class="n">step_size</span> <span class="o">*</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>  <span class="c1"># -ve for descent
</span>	<span class="n">new_cost</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">new_point</span><span class="p">)</span>
	
	<span class="c1"># if doesn't improve cost
</span>	<span class="k">if</span> <span class="nf">abs</span><span class="p">(</span><span class="n">new_cost</span> <span class="o">-</span> <span class="n">cost</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
		<span class="k">return</span> <span class="n">value</span>
	
	<span class="c1"># go to new point
</span>	<span class="k">return</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">new_point</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
</code></pre></div></div>

<p>Let‚Äôs look at an example of how we update the parameters:</p>

<p>Let‚Äôs say we function $f(x, y) = 2 + 3x^2 + 4y^2$, and we try to do a single step of gradient descent. Find the next set of parameters if we start at (10, 10) with step size = 0.5?</p>

<p>Solution: We calculate gradient of this function, gradient $\nabla f = (\frac{\partial f}{\partial x} \frac{\partial f}{\partial y}) = (6x, 8y)$</p>

<p>We know that,</p>

<p>$\text{new point} = point - \text{step size} * gradient(point)$</p>

<p>$\text{new point} = (10, 10) - 0.5 * (12, 16) ‚áí (10, 10) - (6, 8) ‚áí (4, 2)$</p>

<p>Here, we moved in the direction opposite to the vector that is one-half the gradient at (10, 10).</p>

<p>A more scary way to write the above function and equation of gradient descent:
$w_{j+1} = w_j - \eta \nabla Q(w_j)$</p>

<p>where,</p>

<p>$w$ is a vector of parameters we are optimizing over</p>

<p>$Q$ is our cost function</p>

<p>$\eta$ learning parameter</p>

<p>$\nabla Q$ gives direction of steepest ascent, and $- \nabla Q$ points to direction of steepest descent.</p>

<p>Once you get to the bottom of the bowl, $\nabla Q = 0$, the algorithm terminates.</p>

<p><img src="/assets/2024/September/gradient%20descent%20pitfalls.png" alt="Fig: Gradient Descent pitfalls" /></p>

<p><em>Fig: Gradient Descent pitfalls</em></p>

<p>Gradient descent has some pitfalls, like it might get stuck at a local minimum, or the gradient might be much lower, e.g., on a plateau. Because of this, it might take more time to train.</p>

<p>Gradient descent is a key component of training neural networks, and understanding its properties and variants is important for building effective models.</p>

<h2 id="types-of-gradient-descent">Types of Gradient Descent</h2>

<p>There are several variants of gradient descent, including batch gradient descent, stochastic gradient descent, and mini-batch gradient descent. These variants differ in the number of examples used to compute the gradient at each iteration and can have different convergence rates and computational requirements.</p>

<p>Some of the Gradient Descent are explained below:</p>

<h3 id="1-batch-gradient-descent">1. Batch Gradient Descent</h3>

<p>Batch gradient descent (BGD) computes the gradient of the cost function with respect to the parameters for the entire training set at each iteration. The weights and biases are then updated based on this gradient.</p>

<p>gradient is calculated using all training examples.</p>

<p>Example ‚Üí</p>

<p>$Q(w) = \frac{1}{N}   \sum_{i=1}^N Q_i(w)$    = cost is calculated using all training examples</p>

<p>$\nabla Q = \frac{1}{N} \sum_{i=1}^N \nabla Q_i$           = gradient is calculated using all training examples.</p>

<p>Gradient itself contains all parameters, here we are talking about examples.</p>

<p>how much the cost function will change if you change $\theta_j$ just a little bit. This is called <em>partial derivative.</em></p>

<p>$\frac{\partial}{\partial\theta_j}  MSE(\theta) = \frac{2}{m} \sum_{i=1}^{m} (\theta^Tx^{(i)} - y^{(i)})x_j^{(i)}$</p>

<p><img src="/assets/2024/September/gradient%20vector%20of%20cost.png" alt="Fig: Gradient vector of the cost function" /></p>

<p><em>Fig: Gradient vector of the cost function</em></p>

<p>Once you have the gradient vector, which points uphill, just go in the opposite direction to go downhill. This means subtracting $\Delta_{\theta}MSE(\theta)$ from $\theta$ (it‚Äôs like going one unit back).</p>

<p>$\theta^{\text{next step}} = \theta - \eta\Delta_{\theta}MSE(\theta)$</p>

<p>Eq: Gradient Descent step</p>

<p>BGD can be computationally expensive, especially for large datasets, but it can converge quickly and reach a global minimum of the cost function.</p>

<h3 id="2-stochastic-gradient-descent">2. Stochastic Gradient Descent</h3>

<p>Stochastic gradient descent (SGD) updates the weights and biases based on the gradient of the cost function with respect to the parameters for a single training example at each iteration. The gradient is therefore noisy and may not be representative of the overall gradient.</p>

<p>gradient is calculated using one example (as we have been doing in perceptron)</p>

<p>If N is extremely large, computing</p>

<p>$\nabla Q = \frac{1}{N} \sum_{i=1}^N \nabla Q_i$</p>

<p>and evaluating all N functions at w may be very time-consuming.</p>

<p>Stochastic Gradient Descent (SGD) is called ‚Äústochastic‚Äù because it uses a random sample. This randomness helps SGD to avoid local minima and converge faster.</p>

<h3 id="3-mini-batch-gradient-descent">3. Mini-Batch Gradient Descent</h3>

<p>Mini-batch gradient descent (MBGD) is a compromise between BGD and SGD. It computes the gradient of the cost function with respect to the parameters for a small batch of training examples at each iteration.</p>

<p>MBGD can be more computationally efficient than BGD and less noisy than SGD, and it can converge quickly with appropriate batch sizes.</p>

<p>The choice of gradient descent algorithm depends on the specific problem and the available computational resources.</p>

<h1 id="backpropagation">Backpropagation</h1>

<p>If gradient descent was a single step to optimize the weights, then backpropagation is the complete algorithm to train neural networks.
Let‚Äôs understand the intuition behind backpropagation with an example. Suppose a we are predicting the affinity of a person being male athlete on basis of purchases. We have one hidden layer with two neurons which correspond to the likelihood of being male and related to sports. For input X, we predict some output and later get to know that the input was male sports shoes. Now, how should our neural network update the weight of item X in predicting a male if the weight is currently 0? It should increase the weight.</p>

<p><strong>Backpropagation</strong> (backward propagation of errors) is an algorithm for supervised learning of ANN using gradient descent. It works by computing the gradient of the cost function with respect to the network‚Äôs parameters, and then using this gradient to update the parameters using gradient descent. It is a generalization of the delta rule for perceptron‚Äôs to multilayer feedforward neural networks.</p>

<p>The backpropagation algorithm consists of two main steps:</p>

<h3 id="1-forward-pass">1. Forward pass</h3>

<p>The input is fed through the network, and the output is computed for each layer using the current values of the weights and biases.</p>

<p>It also preserves the intermediate results since they are needed for the backward pass.</p>

<h3 id="2-backward-pass">2. Backward pass</h3>

<p>The gradient of the cost function with respect to the weights and biases of each layer is computed using the previously computed gradients and the output of the layer. Finally, the weights and biases are updated using the computed gradients and gradient descent.</p>

<p>Let‚Äôs get to the proof:</p>

<p>Define for each neuron j in layer l the output $o_j^{(l)}$ such that</p>

<p>$o_j^{(l)} = \phi(a_j^{(l)}) = \phi \bigg ( \sum_{k=1}^n w_{kj}^{(l)} o_k^{l-1} \bigg),$</p>

<p>where,</p>

<p>$o_k^{(l-1)}$ neuron output from previous layer</p>

<p>$w_{kj}^{(l)}$ is weight on synapse from k to j (previous layer k neuron to current layer j neuron)</p>

<p>$a_j^{(l)}$ the ‚Äúactivation‚Äù of the neuron</p>

<p>bias is omitted</p>

<p>To find how any error function $E$ (usually mean squared error) changes with respect to a weight $w_{ij}^{(l)}$, we apply the chain rule</p>

<p>$\frac {\partial E}{\partial w_{ij}^{(l)}} = \frac {\partial E}{\partial o_j^{(l)}}\frac {\partial o_j^{(l)}}{\partial a_j^{(l)}} \frac {\partial a_j^{(l)}}{\partial w_{ij}^{(l)}}$</p>

<p>Derivation for Gradient of error function w.r.t to parameters:</p>

<p>$\frac {\partial a_j^{(l)}}{\partial w_{ij}^{(l)}} = o_i^{(l-1)}$</p>

<p>For other terms, we can derive the identify by using the chain rule to write</p>

<p>$\delta_j^{(l)} = \frac {\partial E}{\partial o_j^{(l)}}\frac {\partial o_j^{(l)}}{\partial a_j^{(l)}}$</p>

<p>$\qquad = \frac {\partial o_j^{(l)}}{\partial a_j^{(l)}} \bigg ( \frac {\partial E}{\partial o_j^{(l)}} \bigg)$</p>

<p>$\qquad = \phi‚Äô \bigg(a_j^{(l)} \bigg) \sum_m \frac{\partial E}{\partial o_m^{l+1}} \frac{\partial o_m^{l+1}}{\partial a_m^{l+1}} \frac{\partial a_m^{l+1}}{\partial o_j^{l}}$   divide and multiply by $\partial o_m^{l+1}$,  $\partial a_m^{l+1}$</p>

<p>$\qquad = \phi‚Äô \bigg(a_j^{(l)} \bigg) \sum_m \delta_m^{l+1} w_{jm}^l$              neuron j from current layer sends signals to next layer neuron m.</p>

<p>Note that this is our backpropagation formula. This allows us to compute previous layers of $\delta_j$ by later layers recursively ‚Äî this is where backpropagation comes from. We can compute $\delta_j$ directly if $j$ is an output layer, so this process eventually terminates.</p>

<p>If we combine both of our results we can calculate gradient of Error w.r.t parameters:</p>

<p>$\frac {\partial E}{\partial w_{ij}^{(l)}}  = \phi‚Äô \big(a_j^{(l)} \big) \sum_m w_{jm}^{(l)} \delta_m^{(l+1)} \qquad o_i^{(l-1)},$</p>

<p>time complexity: $O(mn) = O(W)$</p>

<p>where m is the number of neurons in this layer and n is the number of neurons in next layer.</p>

<p>w = number of synapses in the network</p>

<p>The algorithm is called backpropagation because the gradient is computed backwards through the network, starting from the output layer and working backwards towards the input layer. This allows the algorithm to efficiently compute the gradient for each parameter in the network versus the naive approach of calculating the gradient of each layer separately, which can be used to update the weights and biases.</p>

<h2 id="vanishing-gradient-problem">Vanishing Gradient Problem</h2>

<p>Backpropagation is a powerful algorithm that has enabled the training of deep neural networks with many layers. However, it can suffer from the vanishing gradient problem, where the gradient becomes very small as it is propagated backwards through the network, making it difficult to update the weights and biases of the early layers in the network.</p>

<h3 id="why-gradient-keep-shrinking">Why Gradient keep shrinking</h3>

<p>The gradient at each layer is the product of the gradients of the subsequent layers multiplied by the gradient of the current layer. If the gradients of the subsequent layers are small, then the gradient of the current layer will also be small, which can make it difficult to update the weights and biases of the early layers in the network. This is known as the vanishing gradient problem.</p>

<p>This happens because of the activation function, because the activation function compresses the entire real numbers into a small range. You multiply few activation results and gradient becomes too small.</p>

<p>Example ‚Üí Sigmoid always gives output between [0, 1], If we use sigmoid while calculating gradient‚Äôs for previous layers. It keep getting smaller.</p>

<p>This problem has been addressed through the use of activation functions such as ReLU and the development of more advanced optimization algorithms such as Adam and RMSProp.</p>

<p>Sometimes, a smooth approximation to this function is used: $f(x)=ln‚Å°(1+e^x),$ which is called the <strong>softplus function</strong>.</p>

<p>That‚Äôs if for this blog, hope this was worth your time. ü•∞</p>

<h2 id="references">References</h2>

<ol>
  <li><a href="www.brilliant.org">Brilliant.org</a></li>
  <li>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow <a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/">Buy here</a></li>
</ol>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[In this blog post, we will understand the underlying algorithm for training neural networks. We will discuss gradient descent, the most basic step of training any model, and backpropagation.]]></summary></entry><entry><title type="html">Programming Languages</title><link href="http://localhost:4000/programming/2024/02/04/Programming_languages.html" rel="alternate" type="text/html" title="Programming Languages" /><published>2024-02-04T15:08:10+05:30</published><updated>2024-02-04T15:08:10+05:30</updated><id>http://localhost:4000/programming/2024/02/04/Programming_languages</id><content type="html" xml:base="http://localhost:4000/programming/2024/02/04/Programming_languages.html"><![CDATA[<p>Programming languages are the tools we use to write software, create web applications, manipulate data, and more. They‚Äôre fundamental to the world of computing, and there‚Äôs a wide variety to choose from, each with their own strengths and weaknesses.</p>

<p>Let‚Äôs start off with some common types of programming languages:</p>

<h2 id="1-procedural-programming-languages">1. Procedural Programming Languages</h2>

<p>This language type is one of the oldest. It revolves around procedures or routines. They‚Äôre straightforward and efficient, but can be rigid and difficult to manage for larger software projects.</p>

<p>They are great for tasks that can be broken down into a series of sequential steps.</p>

<p>Examples include C and Pascal.</p>

<h3 id="go">Go</h3>

<p>Also known as Golang, Go is a statically-typed compiled language that was developed at Google. It‚Äôs known for its simplicity and efficiency. It‚Äôs particularly good for system-level programming, and it‚Äôs also used in web development. It has a garbage collector, which makes memory management easier. However, it‚Äôs less flexible than some other languages, due to its emphasis on simplicity.</p>

<p>It is primarily a procedural language, but it does offer some support for object-oriented programming.</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">package</span> <span class="n">main</span>

<span class="k">import</span> <span class="s">"fmt"</span>

<span class="k">func</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">fmt</span><span class="o">.</span><span class="n">Println</span><span class="p">(</span><span class="s">"Hello, world!"</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="2-object-oriented-programming-languages">2. Object-Oriented Programming Languages</h2>

<p>These languages organize code into ‚Äòobjects‚Äô that contain both data and the functions that operate on that data. They‚Äôre great for larger projects and promote reusability, but can be overkill for smaller tasks.</p>

<p>Java and Python are examples.</p>

<p>Now, let‚Äôs go in further details of some programming languages:</p>

<h3 id="java">Java</h3>

<p>It‚Äôs a general-purpose language known for its ‚Äòwrite once, run anywhere‚Äô philosophy. It‚Äôs widely used for building enterprise-scale applications. However, it requires a lot of memory and its syntax can be complex for beginners.
Other features ‚Üí memory safe, garbage collection</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">HelloWorld</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">printHello</span><span class="o">()</span> <span class="o">{</span>  
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Hello, world!"</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">HelloWorld</span> <span class="n">helloWorld</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">HelloWorld</span><span class="o">();</span>
        <span class="n">helloWorld</span><span class="o">.</span><span class="na">printHello</span><span class="o">();</span>
    <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div>

<h2 id="3-functional-programming-languages">3. Functional Programming Languages</h2>

<p>These languages treat computation as the evaluation of mathematical functions and avoid changing-state and mutable data. They‚Äôre excellent for parallel processing and have no side effects, but their paradigm can be difficult to grasp for newcomers.</p>

<p>They excel at tasks that can be broken down into independent units that can be executed in any order because they don‚Äôt depend on the state of the program.</p>

<p>Examples include Haskell and Lisp.</p>

<h3 id="haskell-functional">Haskell (Functional)</h3>

<p>Haskell is a statically typed, purely functional programming language with type inference and lazy evaluation. It‚Äôs used in fields where high-level, declarative code is beneficial, such as data analysis and symbolic computation. Due to its purity, code written in Haskell can be easy to test and reason about.</p>

<div class="language-haskell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">factorial</span> <span class="o">::</span> <span class="kt">Integer</span> <span class="o">-&gt;</span> <span class="kt">Integer</span>
<span class="n">factorial</span> <span class="mi">0</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">factorial</span> <span class="n">n</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">factorial</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">main</span> <span class="o">::</span> <span class="kt">IO</span> <span class="nb">()</span>
<span class="n">main</span> <span class="o">=</span> <span class="n">print</span> <span class="p">(</span><span class="n">factorial</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1">-- Outputs: 120</span>
</code></pre></div></div>

<h2 id="4-multi-paradigm-programming-languages">4. Multi-paradigm Programming Languages</h2>

<p>These languages support more than one programming paradigm, offering greater flexibility to developers. They can support procedural, object-oriented, functional programming, and others, depending on the language. They provide a lot of flexibility, but can also be more complex to learn and use because of the multiple paradigms.</p>

<p>Examples include JavaScript and C++.</p>

<p>Some examples are:</p>

<h3 id="javascript-procedural--object-oriented">JavaScript (procedural + object-oriented)</h3>

<p>It‚Äôs the language of the web, used for creating interactive web pages. It‚Äôs flexible and runs directly in the browser. But, it may have security issues and can be inconsistent across different browsers.</p>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">function</span> <span class="nf">greet</span><span class="p">(</span><span class="nx">name</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="dl">"</span><span class="s2">Hello, </span><span class="dl">"</span> <span class="o">+</span> <span class="nx">name</span> <span class="o">+</span> <span class="dl">"</span><span class="s2">!</span><span class="dl">"</span><span class="p">;</span>
<span class="p">}</span>

<span class="kd">var</span> <span class="nx">message</span> <span class="o">=</span> <span class="nf">greet</span><span class="p">(</span><span class="dl">"</span><span class="s2">world</span><span class="dl">"</span><span class="p">);</span>

<span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="nx">message</span><span class="p">);</span>
</code></pre></div></div>

<h3 id="c-procedural--object-oriented">C++ (procedural + object-oriented)</h3>

<p>It‚Äôs a powerful language used for system/software development and game programming. It‚Äôs fast and flexible. However, it has a steep learning curve and managing memory can be tricky.</p>

<h3 id="python">Python</h3>

<p>It‚Äôs a high-level, interpreted language known for its readability. It‚Äôs great for beginners and widely used in scientific computing, data analysis, and AI. However, it‚Äôs slower than some other languages and not ideal for mobile app development.
Other features ‚Üí Memory safe, garbage collection</p>

<p>Each of these languages has its own use cases, advantages, and disadvantages. The key is to choose the right tool for the job at hand.</p>

<h2 id="memory-safe-languages">Memory safe Languages</h2>

<p>Memory-safe languages are programming languages that include preventive measures to avoid common memory-related errors, such as buffer overflow and null pointer dereferencing. These languages can either prevent such errors at compile-time or runtime.</p>

<p>Examples include Java, Python, Rust, Swift, Go, JavaScript, Ruby, C#, TypeScript and Kotlin</p>

<h4 id="buffer-overflow">Buffer Overflow</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">arr</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">arr</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>  <span class="c1"># This is fine in Python. The array resizes automatically.
</span><span class="nf">print</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>

</code></pre></div></div>

<p>In this code, Python automatically resizes the array as new elements are added, preventing a buffer overflow from occurring.</p>

<h4 id="null-pointer-dereferencing">Null Pointer Dereferencing</h4>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Main</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="nc">String</span> <span class="n">str</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">str</span><span class="o">.</span><span class="na">length</span><span class="o">());</span>  <span class="c1">// This will throw a NullPointerException</span>
    <span class="o">}</span>
<span class="o">}</span>

</code></pre></div></div>

<p>In this code, <code class="language-plaintext highlighter-rouge">str</code> is null, so trying to call <code class="language-plaintext highlighter-rouge">str.length()</code> will throw a NullPointerException, preventing the program from continuing to run with invalid data.</p>

<h3 id="garbage-collection">Garbage collection</h3>

<hr />

<p>Garbage collection is a form of automatic memory management. Programming languages with garbage collection automatically reclaim memory that the programmer has allocated but is no longer in use. This process helps to eliminate common programming bugs related to memory management, such as memory leaks and dangling pointers (points to invalid memory).</p>

<p>For example, in Java, you do not need to manually deallocate memory once you‚Äôre done using an object. The Java Virtual Machine (JVM) has a garbage collector that automatically frees up memory that is no longer needed. This greatly simplifies programming and reduces the chance of memory leaks.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Main</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="c1">// Creating a new object</span>
        <span class="nc">String</span> <span class="n">str</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">String</span><span class="o">(</span><span class="s">"Hello, world!"</span><span class="o">);</span>

        <span class="c1">// The object is now eligible for garbage collection because it's no longer reachable</span>
        <span class="n">str</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Another language that uses garbage collection is Python. Like Java, Python automatically manages memory, meaning that objects are automatically destroyed once they are no longer in use.</p>

<p>Here is an example of garbage collection in Python:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyClass</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="k">def</span> <span class="nf">__del__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="s"> has been deleted and is ready for garbage collection</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Create an object
</span><span class="n">my_obj</span> <span class="o">=</span> <span class="nc">MyClass</span><span class="p">(</span><span class="sh">"</span><span class="s">Object 1</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Now, let's delete this object
</span><span class="k">del</span> <span class="n">my_obj</span>

<span class="c1"># Since the object has been deleted, it's now eligible for garbage collection
</span>
</code></pre></div></div>

<p>When the <code class="language-plaintext highlighter-rouge">del</code> keyword is used, it removes a reference to the object.</p>

<p>However, it‚Äôs important to note that an object can also become eligible for garbage collection without the <code class="language-plaintext highlighter-rouge">del</code> keyword, as long as there are no more references to it.</p>

<p>However, it‚Äôs important to note that while garbage collection can make programming easier, it doesn‚Äôt completely prevent memory-related bugs. For instance, if an object is mistakenly kept alive when it‚Äôs not needed, this can still lead to memory leaks. Therefore, understanding how garbage collection works in your programming language of choice is still crucial.</p>

<p>Examples of programming languages that use garbage collection include ‚Üí Java, Python, JavaScript, C#, Ruby, Go and Kotlin.</p>

<h2 id="interpreted-vs-compile-time-language">Interpreted vs compile time language</h2>

<p>Interpreted and compiled languages represent two different ways of translating human-readable source code into machine code that a computer can execute.</p>

<h3 id="interpreted-languages">Interpreted Languages</h3>

<p>In an interpreted language, the source code is not directly translated into machine code. Either, an interpreter reads the source code line-by-line, and executes each command. (such as PHP or Ruby)</p>

<p>Or, the source code is first translated into this intermediate form like bytecode (such as Python, Java, and C#), which allows for platform independence as the same bytecode can be interpreted on different machines. This bytecode is then interpreted (e.g. Python) or compiled at runtime using JIT (it is an optimization, that makes it hybrid with compiled languages) (e.g. Java and C#).</p>

<p>Note, machine code is not executed line by line but as a whole. This allows for certain optimizations that can make the code run faster.</p>

<p><img src="/assets/2024/September/interpreted.png" alt="Untitled" /></p>

<p>Interpreted languages are generally more flexible, and they can even modify themselves during runtime.  However, they also tend to run slower than compiled languages, as the interpretation process takes time.</p>

<p>Examples of interpreted languages include Python, Ruby, and PHP.</p>

<h3 id="compiled-languages">Compiled Languages</h3>

<p>In a compiled language, the source code is directly translated into machine code by a compiler before it‚Äôs run. This means that compiled programs generally run faster than interpreted ones, as all the translation work is done beforehand.</p>

<p>However, they are less flexible than interpreted languages, as the source code cannot be changed during runtime.</p>

<p>Examples of compiled languages include C, C++, and Go.</p>

<p><img src="/assets/2024/September/compiled.png" alt="Untitled" /></p>

<h3 id="jit-compilation">JIT compilation</h3>

<p>Just-In-Time (JIT) compilation is a method of execution where a program is compiled into machine code just before it is run, rather than ahead of time as with traditional compilation.</p>

<p>JIT compilation is used in several programming languages, most notably Java and JavaScript, but also in Python, Ruby, and .NET languages such as C#.</p>

<p>Java and C# are often described as a hybrid of compiled and interpreted languages, due to their two-step process. First, source code is compiled into an intermediate form (bytecode for Java, and Intermediate Language for C#), and then this intermediate form is further compiled to machine code at runtime by a Just-In-Time (JIT) compiler.</p>

<p><img src="/assets/2024/September/flowchart.png" alt="Fig: Flowchart from high level language to Output (Just my understanding) " /></p>

<p>*Fig: Flowchart from high level language to Output (Just my understanding) *</p>

<p>The main advantage of JIT compilation is that it can optimize the program for the machine‚Äôs current state, taking into account factors such as the data being processed and the machine‚Äôs architecture. This can result in more efficient execution than with traditionally compiled code.</p>

<p>However, JIT compilation also has some disadvantages. The compilation process can lead to an initial delay in execution, known as a ‚Äúwarm-up‚Äù period.</p>

<p>Additionally, JIT compilers are complex pieces of software that can introduce their own bugs and security vulnerabilities.</p>

<h2 id="statically-vs-dynamically-typed-languages">Statically vs Dynamically Typed languages</h2>

<h3 id="statically-typed-languages">Statically Typed Languages</h3>

<p>In statically typed languages, the variable type is checked at compile-time. This means that you must declare the data type of the variable when you define it, and once set, the variable type can‚Äôt be changed. This approach can help catch errors early in the development process. Statically typed languages include Java, C, C++, Go, Rust, and Swift.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">num</span> <span class="o">=</span> <span class="mi">10</span><span class="o">;</span> <span class="c1">// Declare an integer variable</span>
<span class="n">num</span> <span class="o">=</span> <span class="s">"Hello"</span><span class="o">;</span> <span class="c1">// Error: incompatible types</span>
</code></pre></div></div>

<p>In the above Java code, an error would be thrown at compile time because you cannot assign a string to an integer variable.</p>

<h3 id="dynamically-typed-languages">Dynamically Typed Languages</h3>

<p>The counterpart to statically typed languages are dynamically typed languages. In these languages, the type is checked at runtime, which means that you can declare a variable without specifying its type, and its type can be changed later in the program. While this provides more flexibility, it can also lead to errors that are only discovered when the code is run. Dynamically typed languages include Python, Ruby, PHP, and JavaScript.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># num is an integer
</span><span class="n">num</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Hello</span><span class="sh">"</span>  <span class="c1"># num is now a string
</span></code></pre></div></div>

<p>In the above Python code, the <code class="language-plaintext highlighter-rouge">num</code> variable can be reassigned to a string without any errors, because the type check happens at runtime.</p>

<p>It‚Äôs worth noting that some languages, like Python, are also capable of type hinting. This is a feature that allows developers to specify the expected type of a variable or function return, improving code readability and allowing for better IDE support and error checking, even though the language itself is dynamically typed.</p>

<p>That‚Äôs it for this blog. ü¶Ñü¶Ñ I hope this helps you to better understand your favorite programming language. If you find any mistake or have any doubt feel free to contact!</p>]]></content><author><name></name></author><category term="Programming" /><summary type="html"><![CDATA[Programming languages are the tools we use to write software, create web applications, manipulate data, and more. They‚Äôre fundamental to the world of computing, and there‚Äôs a wide variety to choose from, each with their own strengths and weaknesses.]]></summary></entry><entry><title type="html">How to do clustering</title><link href="http://localhost:4000/ai/2024/01/20/How_to_do_clustering.html" rel="alternate" type="text/html" title="How to do clustering" /><published>2024-01-20T15:08:10+05:30</published><updated>2024-01-20T15:08:10+05:30</updated><id>http://localhost:4000/ai/2024/01/20/How_to_do_clustering</id><content type="html" xml:base="http://localhost:4000/ai/2024/01/20/How_to_do_clustering.html"><![CDATA[<h1 id="clustering">Clustering</h1>

<p>Clustering is a type of unsupervised learning that involves grouping similar inputs into clusters or categories.</p>

<p>This technique can be used to identify patterns or relationships in data that may not be immediately apparent. There are many algorithms that can be used for clustering, including k-means, hierarchical clustering, and DBSCAN. The choice of clustering algorithm depends on the specific problem and the characteristics of the data.</p>

<p>Hard clustering ‚Üí Assigning each instance to a single cluster.</p>

<p>Soft clustering ‚Üí Assigning each instance a score per cluster, it can be a similarity score (or affinity).</p>

<h2 id="types-of-clustering">Types of Clustering</h2>

<p>There are several types of clustering algorithms, including:</p>

<h3 id="centroid-based-clustering">Centroid-based clustering</h3>

<p>Centroid-based clustering is a type of clustering method in which the position of a cluster is represented by the central point of its objects.</p>

<p>A popular example of centroid-based clustering is the k-means algorithm. Centroid-based algorithms are efficient but sensitive to initial conditions and outliers.</p>

<p><img src="https://developers.google.com/static/machine-learning/clustering/images/CentroidBasedClustering.svg" alt="Fig: Centroid based clustering" /></p>

<p><em>Fig: Centroid based clustering</em></p>

<p>Let‚Äôs learn about K-means clustering, an example of centroid-based clustering.</p>
<h3 id="k-means">K-Means</h3>

<p>The model learns to group inputs into k clusters based on similarity. It is a straightforward and efficient algorithm for data segmentation and pattern recognition.</p>

<p>The main objective of k-means clustering is to partition the data into ‚Äòk‚Äô clusters, where ‚Äòk‚Äô is a user-defined parameter representing the number of clusters desired.</p>

<p>Here‚Äôs how the k-means clustering algorithm works:</p>

<ol>
  <li><strong>Initialization</strong>: Choose ‚Äòk‚Äô initial centroids (cluster centers) randomly from the data points. These centroids represent the initial cluster centers.</li>
  <li><strong>Assignment</strong>: Assign each data point to the nearest centroid. This step is based on the distance metric, commonly the Euclidean distance, but other distance measures can also be used.</li>
  <li><strong>Update Centroids</strong>: Calculate the mean of all the data points assigned to each centroid. Move the centroid to the mean position. This step aims to find the new cluster centers.</li>
  <li><strong>Repeat Assignment and Update</strong>: Repeatedly assign data points to the nearest centroid and update the centroids until convergence or until a maximum number of iterations is reached.</li>
  <li><strong>Convergence</strong>: The algorithm converges when the centroids no longer change significantly between iterations or when a predefined convergence criterion is met.</li>
  <li><strong>Result</strong>: After convergence, each data point will be assigned to one of the ‚Äòk‚Äô clusters based on the final positions of the centroids.</li>
</ol>

<p>When sets of circles from competing centroids overlap they form a line. The result is what‚Äôs called a <strong>Voronoi tessellation</strong>.</p>

<p><img src="https://storage.googleapis.com/kaggle-media/learn/images/KSoLd3o.jpg" alt="Fig: K-means clustering creates a Voronoi tessallation of the feature space." /></p>

<p>Fig: K-means clustering creates a Voronoi tessallation of the feature space.</p>

<p>Choosing the appropriate value of ‚Äòk‚Äô is critical in k-means clustering. The number of clusters should be determined based on domain knowledge or through techniques like the elbow method, silhouette score, or other clustering evaluation metrics.</p>

<p>K-means clustering is widely used in various applications, such as customer segmentation, image compression, anomaly detection, and data preprocessing for other machine learning tasks.</p>

<p>It is important to note that k-means is sensitive to the initial random centroid selection, and it may converge to a suboptimal solution depending on the initial positions of the centroids.</p>

<p><img src="/assets/2024/September/suboptimal%20solutions.png" alt="Fig: Suboptimal solutions due to unlucky centroid initializations" /></p>

<p><em>Fig: Suboptimal solutions due to unlucky centroid initializations</em></p>

<p>To mitigate this issue, it is common to run the algorithm multiple times with different initializations and choose the best result based on a chosen evaluation metric.</p>

<h4 id="disadvantages-of-k-means-algorithm">Disadvantages of K-means algorithm:</h4>

<ul>
  <li>Need to run K-means few times, before finding global optimal solution.</li>
  <li>Need to specify number of clusters.</li>
  <li>K-means does not behave very well when the clusters have varying sizes, different densities, or non-spherical shapes.</li>
</ul>

<p>Let‚Äôs demonstrate the K-means clustering using a real-world dataset. Here, we‚Äôll use the popular <code class="language-plaintext highlighter-rouge">Iris</code> dataset available in the <code class="language-plaintext highlighter-rouge">sklearn</code> datasets module. This dataset includes measurements of 150 iris flowers from three different species.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="n">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Load the iris dataset
</span><span class="n">iris</span> <span class="o">=</span> <span class="nf">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span>

<span class="c1"># Apply K-means clustering
</span><span class="n">kmeans</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># n_init tells how many random initializations to do (times the whole process is repeated)
</span><span class="n">kmeans</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span>

<span class="c1"># labels
</span><span class="sh">"""</span><span class="s">
array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2,
       2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2,
       2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0], dtype=int32)
</span><span class="sh">"""</span>

<span class="c1"># Plot the clusters (plot using any 2 attributes, your wish)
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">kmeans</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Some other functions
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="nf">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">kmeans</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># score for each cluster
</span></code></pre></div></div>

<p><img src="https://www.kaggleusercontent.com/kf/158886682/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..PCQzfyplvHilkSHDdYpjew.S3D9I--L2F0_KlZBRlvAkZPFDXrYGZNfA3IcbtkIUUUPTNth3ZeUka7FOqQqPW4Z-hNChF0fyxZ-qQaoeIqequH6AyA9Ad2KIIqFUsJTQXuIdnnrYadSQjF19vrMpVXZct2M1MUBOzX_obMwyA8dU2yXV6vgk3_YbOCu-lf02MHWw8t25Tizqh5hbUmdsm2PoTFPgkn_M2R54xanJFb8upKBC7JOF6k7MBS0Dhzo-kXhku7fNLFKDLJhOZTEJcCD46JIFj0BlteTf_bGB6ijfz2rFo-ub7yJEvgHDSKZyzgKc0eMihW6k_iMf2WSKoidCZao7Jj4DcIEGlZy7-BMWMDk5Eus9qmODrd63UB1xVI4ZjJ25W9itFlO_8kI67yv4xSWN8fIRqhtOo4bvLKySNQOYA1bE9WNFXeX_1Ug9mqqr5-K5f8xGtC5rkzQs-KnuDRhtYdcmzot_U2s-QHs96hJkC53FHwqdKf453pGvMnJCobbh4ZF9Z_DKa7R0t_vXaZVx0RAZMLcJDaGZ5XnYZXb7MdUd9NJbTQEpGI849jUwiIhK9oav7dP7w02w7UsSRUdJKzJlQEA3HFDN_4d53hM1FULpc1RgZufrSEvQEfo08Dam398PRhtyq98NhjAkL6Roe25uoAAhyfi2NndN3G5a3P4YtoBInrpIwzG1iI.ajnu3QmYOLkOgnndJwPAXw/__results___files/__results___6_0.png" alt="Fig: Dataset is divided into 3 clusters" /></p>

<p>In this code, <code class="language-plaintext highlighter-rouge">iris.data</code> is a 150x4 matrix where each row is a flower sample and each column is a feature (sepal length, sepal width, petal length, petal width). The K-means algorithm groups the flowers into 3 clusters based on these features. The final line plots the clusters, with the cluster centers marked in red.</p>

<h3 id="density-based-clustering">Density-based clustering</h3>

<p>Density-based clustering connects areas of high example density into clusters. This method can form clusters of any shape as long as dense areas are connected. However, it struggles with data that has different densities and many dimensions. Also, these algorithms intentionally do not include outliers in any clusters.</p>

<p><img src="https://developers.google.com/static/machine-learning/clustering/images/DensityClustering.svg" alt="Fig: Density based clustering" /></p>

<p><em>Fig: Density based clustering</em></p>

<ul>
  <li><strong>DBSCAN Clustering</strong>: the model learns to group inputs into clusters based on density, with high-density regions representing clusters and low-density regions representing noise.</li>
  <li><strong>Mean Shift Clustering:</strong> the model learns to identify and group inputs based on local density maxima.</li>
</ul>

<h3 id="distribution-based-clustering">Distribution-based clustering</h3>

<p>This clustering approach assumes data is composed of distributions, such as <a href="https://wikipedia.org/wiki/Normal_distribution"><strong>Gaussian distributions</strong></a>. As distance from the distribution‚Äôs center increases, the probability that a point belongs to the distribution decreases.</p>

<p><img src="https://developers.google.com/static/machine-learning/clustering/images/DistributionClustering.svg" alt="Fig: Distribution-based clustering" /></p>

<p>Fig: Distribution-based clustering</p>

<p>A common example of distribution-based clustering is the Gaussian Mixture Model (GMM).</p>

<h3 id="hierarchical-clustering">Hierarchical clustering</h3>

<p>The model learns to group inputs into a hierarchy of clusters, with larger clusters containing smaller clusters.</p>

<p><img src="https://developers.google.com/static/machine-learning/clustering/images/HierarchicalClustering.svg" alt="Fig: Hierarchical clustering" /></p>

<p>Fig: Hierarchical clustering</p>

<ul>
  <li>Agglomerative clustering</li>
  <li>BIRCH (scale well to large dataset)</li>
</ul>

<p>Each type of clustering algorithm is suited for different types of data and problems, and choosing the right type of clustering is an important part of building an accurate machine learning model.</p>

<h2 id="applications-of-clustering">Applications of Clustering:</h2>

<ul>
  <li>Data analysis</li>
  <li>Customer segmentation</li>
  <li>recommender systems</li>
  <li>Dimensionality reduction</li>
  <li>Anomaly detection (outlier detection)</li>
  <li>Search engines</li>
  <li>image segmentation</li>
  <li>Semi-supervised learning</li>
</ul>

<h2 id="creating-a-similarity-matrix">Creating a Similarity Matrix</h2>

<p>A similarity matrix is a matrix where each element ij represents the similarity between the ith and jth elements of the dataset. A common method of calculating similarity is by using the Euclidean distance.</p>

<p>In the context of clustering, we use a similarity matrix to find the similarity between any element and it‚Äôs corresponding centroid.</p>

<p>There are 2 types of similarity measures: ‚Äì</p>

<ol>
  <li>
    <p><strong>Supervised similarity</strong> measure refers to the use of a supervised machine learning model to calculate how similar two items are. This model is trained on data that includes the correct answer, which it uses to learn how to predict the similarity of new items.</p>
  </li>
  <li>
    <p><strong>Manual similarity</strong> measure means calculating the similarity between two items using a predefined formula or method, without the use of a machine learning model. This approach is often used when it‚Äôs straightforward to calculate similarity, such as measuring the distance between two points in a space.</p>
  </li>
</ol>

<p>Here is a sample Python code for creating a similarity matrix:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">cdist</span>

<span class="c1"># Calculate Euclidean distance between each sample and each cluster centroid
</span><span class="n">dist_matrix</span> <span class="o">=</span> <span class="nf">cdist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">)</span>

<span class="c1"># Create similarity matrix
</span><span class="n">similarity_matrix</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">dist_matrix</span>

<span class="c1"># Print the similarity matrix
</span><span class="nf">print</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">)</span>

<span class="sh">"""</span><span class="s">
Output
array([[ 0.29246175,  7.074606  ,  0.19764636],
       [ 0.29424103,  2.23394674,  0.19550559],
       [ 0.28016253,  2.3974543 ,  0.18941707],
       [ 0.29219179,  1.90353644,  0.1940395 ],
       [ 0.28841184,  5.30147879,  0.19591195],
       [ 0.31779005,  1.4770227 ,  0.2136073 ],
</span><span class="sh">"""</span>
</code></pre></div></div>

<p>Each row in the similarity matrix corresponds to a sample, and each column corresponds to a cluster centroid. The higher the value in the similarity matrix, the closer the sample is to the corresponding cluster centroid.</p>

<h2 id="interpret-results">Interpret results</h2>

<p>The results of K-means clustering can be visualized using a scatter plot, as shown above. Each cluster is represented by a different colour, and the cluster centres are marked in red.</p>

<p>The results can also be evaluated quantitatively using various metrics such as inertia (sum of squared distances of samples to their closest cluster centre) and silhouette score (a measure of how close each sample in one cluster is to the samples in the neighbouring clusters).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Calculate silhouette score
</span><span class="n">sil_score</span> <span class="o">=</span> <span class="nf">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># Print silhouette score
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Silhouette Score: </span><span class="sh">'</span><span class="p">,</span> <span class="n">sil_score</span><span class="p">)</span>

<span class="c1"># Print inertia
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Inertia: </span><span class="sh">'</span><span class="p">,</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># Inertia:  78.85144142614601
# Silhouette Score:  0.5528190123564095
</span></code></pre></div></div>

<p>In this code, <code class="language-plaintext highlighter-rouge">kmeans.inertia_ returns</code> the inertia of the KMeans clustering. A lower inertia means a better model.
In this code, silhouette_score(X, labels) calculates the silhouette score of the clustering result. A higher silhouette score indicates that the samples are well clustered.</p>

<p>That‚Äôs it for this blog. I hope you learned something useful about clustering ‚ù§Ô∏è‚ù§Ô∏è.</p>

<h3 id="references">References</h3>

<p><a href="https://developers.google.com/machine-learning/clustering">Google Developers</a></p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Clustering]]></summary></entry><entry><title type="html">Just machine learning</title><link href="http://localhost:4000/ai/2023/10/29/Just_machine_learning.html" rel="alternate" type="text/html" title="Just machine learning" /><published>2023-10-29T15:08:10+05:30</published><updated>2023-10-29T15:08:10+05:30</updated><id>http://localhost:4000/ai/2023/10/29/Just_machine_learning</id><content type="html" xml:base="http://localhost:4000/ai/2023/10/29/Just_machine_learning.html"><![CDATA[<p>In this blog post, we‚Äôre going to talk about machine learning and its different types.</p>

<p>Artificial intelligence (AI) refers to machines that are programmed to learn and perform tasks that usually require human thinking, like recognizing images, understanding speech, making decisions, and translating languages.</p>

<p>Machine learning is a branch of AI that allows computers to learn and make predictions or decisions based on data. It uses algorithms and statistical models to analyze data, find patterns, and make predictions on new data.</p>

<h1 id="supervised-learning">Supervised Learning</h1>

<p>Supervised learning is a machine learning technique where a model is trained on labeled data. The model is presented with inputs and corresponding outputs, and it learns to make predictions based on those inputs.</p>

<p>This technique is used for tasks such as classification, regression, and prediction.</p>

<p>Some common types of supervised learning include:</p>

<ul>
  <li><strong>Classification:</strong> the model learns to classify inputs into different categories or classes.</li>
  <li><strong>Regression:</strong> the model learns to predict a continuous output based on the input.</li>
  <li><strong>Time Series Prediction:</strong> the model learns to make predictions based on time series data.</li>
  <li><strong>Anomaly Detection:</strong> the model learns to identify unusual or unexpected data points.</li>
</ul>

<h2 id="classification">Classification</h2>

<p>Classification is a type of supervised learning in machine learning where the model learns to put inputs into different categories or classes.</p>

<p>Examples ‚Üí Image recognition, sentiment analysis, and speech recognition.</p>

<p>There are a bunch of algorithms that can be used for classification, including decision trees, random forests, and support vector machines (SVMs).</p>

<p>The choice of algorithm depends on the specific problem and the characteristics of the data. For example, decision trees are great for problems with just a few features, while SVMs are awesome when there are lots of features and the data isn‚Äôt linearly separable.</p>

<p>There are many algorithms that can be used for classification, including:</p>

<ul>
  <li>Decision trees</li>
  <li>Random forests (Ensemble method)</li>
  <li>Support vector machines (SVMs)</li>
  <li>Nearest neighbor</li>
  <li>K-nearest neighbors (KNN)</li>
  <li>Naive Bayes</li>
</ul>

<p>Let‚Äôs Discuss some of these techniques:</p>

<h3 id="decision-trees">Decision Trees</h3>

<p>Decision trees are a type of classification algorithm used in machine learning. They are especially handy for problems with just a few features and a ton of training examples.</p>

<p>The basic idea behind decision trees is to split up the input space into different regions, where each region represents a different class or category. This is done by recursively splitting up the input space over and over again based on the values of the input features.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>![Fig: Decision Tree](https://static.javatpoint.com/tutorial/machine-learning/images/decision-tree-classification-algorithm.png)

Fig: Decision Tree

At each level of the tree, the algorithm picks the input feature that separates the training examples into different classes the best. This feature is used to make a decision node, which splits the input space into two or more regions. The process is repeated on each of the resulting regions until a stopping criterion is met, like reaching the maximum depth or having a minimum number of examples in each region.

Decision trees are super easy to understand and interpret, and they can be used for both classifying and regression problems. They can also handle non-linear relationships between the input features and the target variable.

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score

model = DecisionTreeClassifier(random_state=0)
model.fit(X_train, Y_train)

score = cross_val_score(model, X, Y, cv=10)
```

Decision trees can also be used for regression problems, where the goal is to predict a continuous output variable based on the input features. The decision tree algorithm works in the same way as for classification problems, but instead of predicting a class label, it predicts a numeric value.

Here is an example of a decision tree for a regression problem:

- **Regression Decision Tree**
    
    ![Fig: Regression Decision Tree](https://scikit-learn.org/stable/_images/sphx_glr_plot_tree_regression_001.png)
    
    Fig: Regression Decision Tree
    
    In this example, the decision tree is used to fit a sine curve as a result it learns linear regression approximating the sine curve. We can see in this example, that if max depth of the tree is set to high, it can overfit the training data by learning the noise observations also.
    
    The algorithm chooses the feature that results in the best split of the data based on a measure of the variance reduction. The prediction for each leaf node is the average of the target values of the training examples that fall within that leaf node.
    

However, decision trees can be sensitive to small changes in the input data and may overfit the training data if not properly regularized. To address these issues, ensemble methods such as random forests and gradient boosting are often used.

Overall, decision trees are a simple and effective technique for classification and regression problems, particularly when the decision boundary is simple or linear.
</code></pre></div></div>

<ul>
  <li>
    <p><strong>Nearest-neighbor classification</strong></p>

    <p>In this algorithm, the model given an input chooses the class of the nearest data point to that point.</p>

    <p>This technique is useful for problems where the decision boundary between classes is complex or nonlinear. However, it can be computationally expensive and may not perform well on high-dimensional data.</p>
  </li>
  <li>
    <p><strong>K-Nearest Neighbor Classification (KNN)</strong></p>

    <p>In this algorithm, the model assigns a class to a new data point based on the classes of the k nearest data points in the training data set. The value of k is a hyperparameter that can be tuned to optimize the model‚Äôs performance.</p>

    <p>This technique is often used for problems with a small number of classes and a large number of features. However, it can be sensitive to the choice of distance metric used to calculate the distance between data points.</p>

    <p><a href="https://miro.medium.com/v2/resize:fit:1100/0*ItVKiyx2F3ZU8zV5">Fig: KNN Example</a></p>

    <p>Fig: KNN Example</p>

    <p>Overall, k-nearest neighbor classification is a simple and effective technique for classification problems, particularly when the decision boundary is complex or nonlinear.</p>
  </li>
</ul>

<h3 id="regression">Regression</h3>

<p>Regression is a type of supervised learning in machine learning. It involves the use of algorithms and statistical models to predict a continuous output based on input data.</p>

<p>This is useful when trying to predict a value that falls within a range, such as the price of a house based on its size, location, and other factors.</p>

<p>Example ‚Üí f(size, location, architecture) = price
                   f(1200, Delhi, 2 story building) = 1 million</p>

<h3 id="types-of-regression">Types of Regression</h3>

<p>There are several types of regression, including:</p>

<ul>
  <li>
    <p><strong>Linear Regression:</strong> the model learns to predict a continuous output based on a linear relationship between the input and output variables.</p>

    <p>!https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-in-machine-learning.png</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># using skitit learn
</span>  <span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Linear</span> <span class="n">Regression</span>
    
  <span class="n">model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    
  <span class="c1"># Print coefficients and accuracy
</span>  <span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
    
  <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Logistic Regression:</strong> the model learns to predict a binary output based on the input variables.</li>
  <li><strong>Polynomial Regression:</strong> the model learns to predict a continuous output based on a polynomial relationship between the input and output variables.</li>
  <li><strong>Ridge Regression:</strong> a regularization technique used to prevent overfitting in linear regression models.</li>
  <li><strong>Lasso Regression:</strong> a regularization technique used to prevent overfitting in linear regression models, but with a different approach than Ridge Regression.</li>
  <li><strong>Elastic Net Regression:</strong> a combination of Ridge and Lasso Regression, which balances their strengths and weaknesses.</li>
</ul>

<p>Each type of regression is suited for different types of data and problems, and choosing the right type of regression is an important part of building an accurate machine learning model.</p>

<p><strong>Logistic Regression</strong></p>

<p>Logistic regression is a type of supervised learning in machine learning that is used for binary classification tasks. In this technique, the model learns to predict a binary output (0 or 1) based on the input variables.</p>

<p>It is commonly used in applications such as fraud detection, spam filtering, and medical diagnosis.</p>

<p>The logistic regression algorithm uses a sigmoid function to map the input values to a range between 0 and 1 (generate probabilities), which represents the probability of the input data belonging to one of the two categories. The algorithm then makes a binary decision based on this probability.</p>

<p>!https://static.javatpoint.com/tutorial/machine-learning/images/logistic-regression-in-machine-learning.png</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Logistic Regression
</span><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">Y_test</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Ridge Regression</strong></p>

<p>Ridge regression is a type of linear regression that adds a regularization term (L2) to the cost function to prevent overfitting. The cost function for ridge regression is:</p>

<p>The Ridge Regression Equation is given by:</p>

<p>$J(w) = \sum_{i=1}^{m} [y^{(i)} - \hat{y}^{(i)}]^2 + \alpha\sum_{j=1}^{n} w_j^2$</p>

<p>where:</p>

<ul>
  <li>J(w) is the cost function</li>
  <li>m is the number of training examples</li>
  <li>n is the number of features</li>
  <li>y is the target variable</li>
  <li>w is the vector of coefficients</li>
  <li>Œ± is the regularization parameter</li>
</ul>

<p>The first term in the equation is the mean squared error (MSE) between the predicted values and the true values. The second term is the L2 regularization term, which penalizes the magnitude of the coefficients.</p>

<p><strong>Lasso Regression</strong></p>

<p>Lasso regression is another type of linear regression that adds a regularization term (L1) to the cost function. The cost function for lasso regression is:</p>

<table>
  <tbody>
    <tr>
      <td>$J(w) = \sum_{i=1}^{m} [y^{(i)} - \hat{y}^{(i)}]^2 + \alpha\sum_{j=1}^{n}</td>
      <td>w_j</td>
      <td>$</td>
    </tr>
  </tbody>
</table>

<p>Where:</p>

<ul>
  <li>$J(w)$ is the cost function</li>
  <li>$m$ is the number of training examples</li>
  <li>$n$ is the number of features</li>
  <li>$y$ is the target variable</li>
  <li>$w$ is the vector of coefficients</li>
  <li>$\alpha$ is the regularization parameter (hyperparameter)</li>
</ul>

<p>The first term in the equation is the mean squared error (MSE) between the predicted values and the true values. The second term is the L1 regularization term, which penalizes the absolute value of the coefficients.</p>

<p>Lasso regression is useful for feature selection, as it tends to set the coefficients of less important features to zero. This can lead to a more interpretable model and improve its generalization performance.</p>

<h2 id="unsupervised-learning">Unsupervised Learning</h2>

<hr />

<p>Unsupervised learning is a type of machine learning where the model is trained on unlabeled data. The model is not given any specific outputs to learn from, but instead must identify patterns and relationships in the input data on its own.</p>

<p>This technique is used for tasks such as clustering, anomaly detection, and dimensionality reduction.</p>

<p>Some common types of unsupervised learning include:</p>

<ul>
  <li>
    <p><strong>Clustering:</strong> the model learns to group similar inputs into clusters or categories.</p>

    <p><a href="https://www.notion.so/But-how-you-do-clustering-d6b2d75d69204bf0a78f8df5548f7fc8?pvs=21">But how you do clustering?</a></p>
  </li>
  <li><strong>Anomaly Detection:</strong> the model learns to identify unusual or unexpected data points.</li>
  <li><strong>Dimensionality Reduction:</strong> the model learns to identify the most important features or variables in the input data.</li>
  <li><strong>Density estimation</strong> involves a model learning a probability density function (PDF), which is used in anomaly detection. Instances found in very-low density regions are considered anomalies.</li>
</ul>

<p><a href="https://www.notion.so/Gaussian-Mixtures-b0c8ae93678d4590a12aeb3e42f68240?pvs=21">Gaussian Mixtures</a></p>

<p>Unsupervised learning is useful when working with large amounts of data that may not be well understood or labeled. By identifying patterns and relationships in the data, unsupervised learning can help to uncover insights and guide further analysis.</p>

<h2 id="reinforcement-learning">Reinforcement learning</h2>

<hr />

<p><a href="https://www.notion.so/Learn-by-Reinforcement-e811c0c2b34c47abb946dc90b59749fe?pvs=21">Learn by Reinforcement</a></p>

<p><strong>Convergence Rate</strong></p>

<p>The convergence rate of a model refers to how quickly the model is able to converge to an optimal solution during training.</p>

<p>A faster convergence rate means that the model is able to reach a good solution more quickly, while a slower convergence rate means that the model may require more time and resources to reach a good solution.</p>

<p>The convergence rate can be affected by various factors, such as the choice of optimization algorithm, the learning rate, the size of the training data, and the complexity of the model architecture. A well-designed model with appropriate hyperparameters can achieve a faster convergence rate and better performance.</p>

<h2 id="ensemble-methods">Ensemble Methods</h2>

<hr />

<p>A group of predictors is called ensemble and an ensemble learning algorithm is called Ensemble method.</p>

<p>In other words, Ensemble methods are a type of machine learning technique that involve combining multiple models to improve their performance.</p>

<p>Ensemble has a similar bias but a lower variance than a single predictor trained on a the original training set.</p>

<p>There are several types of ensemble methods, including:</p>

<ul>
  <li>
    <p><strong>Bagging:</strong> the model combines the predictions of multiple models trained on different subsets of the training data. This can help to reduce overfitting and improve the accuracy of the model.</p>

    <p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/5989232b-4798-4c63-ac9f-04cb2f5fb1a8/48745c7a-5e51-4186-8452-6647e672a3f6/Untitled.png" alt="Fig: Bagging and pasting involves training several predictors on different random samples of the training set" /></p>

    <p>Fig: Bagging and pasting involves training several predictors on different random samples of the training set</p>

    <p>Bagging - sampling is performed with replacement (bootstrap=True)</p>

    <p>Pasting - sampling is performed without replacement (bootstrap=False)</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
  <span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
    
  <span class="n">bag_clf</span> <span class="o">=</span> <span class="nc">BaggingClassifier</span><span class="p">(</span>
      <span class="nc">DecisionTreeClassifier</span><span class="p">(),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
      <span class="n">max_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">bootstrap</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
  <span class="p">)</span>
  <span class="n">bag_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">bag_clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</code></pre></div>    </div>

    <p>n_estimators = number of decision trees</p>

    <p>max_samples = 100 training samples randomly sampled from training set</p>

    <p>bootstrap = True, with replacement</p>

    <p>n_jobs = number of CPU cores to use for training and predictions, -1 means use all available</p>

    <p>Bootstrapping introduces more diversity into the predictor, means it is more biased than pasting; but the diversity also means the predictors are less correlated and ensemble variance is reduced.</p>
  </li>
  <li>
    <p><strong>Boosting:</strong> the model combines the predictions of multiple weak models to create a strong model. This can help to improve the accuracy of the model and reduce bias.</p>
  </li>
  <li>
    <p><strong>Stacking:</strong> the model combines the predictions of multiple models using a meta-model (blender). This can help to improve the accuracy of the model and reduce overfitting.</p>

    <p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/5989232b-4798-4c63-ac9f-04cb2f5fb1a8/8984dd70-5bb4-482c-8329-825d5ce887ba/Untitled.png" alt="Fig: Aggregating predictions using a blending predictor" /></p>

    <p>Fig: Aggregating predictions using a blending predictor</p>
  </li>
</ul>

<p>Ensemble methods are particularly useful when working with complex data or when the performance of a single model is not sufficient. By combining the predictions of multiple models, ensemble methods can help to improve the accuracy and reliability of the model.</p>

<p>Some common ensemble methods include:</p>

<h3 id="random-forests"><strong>Random Forests</strong></h3>

<hr />

<p>Random Forest is an ensemble of Decision trees, generally trained via the bagging method (or sometimes pasting), typically with <em>max_samples</em> set to the size of training set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">rnd_clf</span> <span class="o">=</span> <span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rnd_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">y_pred_rf</span> <span class="o">=</span> <span class="n">rnd_clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</code></pre></div></div>

<p>Random Forest algorithm introduces extra randomness when growing trees; instead of searching for the best feature when splitting a node, it searches for the best feature among a random subset of features.</p>

<p><strong>Feature Importance</strong></p>

<p>Random forests allow us to measure the relative importance of each feature. Feature importance is calculated by how much tree nodes that use that use that feature reduce impurity on average.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># feature importance
</span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="sh">"</span><span class="s">feature_names</span><span class="sh">"</span><span class="p">],</span> <span class="n">rnd_clf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>

<span class="c1"># output
# sepal length (cm) 0.10109300798027078
# sepal width (cm) 0.031280365249363895
# petal length (cm) 0.3941268382545283
# petal width (cm) 0.47349978851583696
</span></code></pre></div></div>

<p>Random forests are particularly useful for high-dimensional data and problems with complex decision boundaries. They can also handle missing values and noisy data.</p>

<p>Overall, random forests are a powerful and versatile technique for solving a wide range of machine learning problems.</p>

<h3 id="adaboost"><strong>AdaBoost</strong></h3>

<hr />

<p>A type of boosting ensemble method used for classification problems. AdaBoost combines the predictions of multiple weak models using a weighted sum, where the relative weight of misclassified instances increased (boost).</p>

<p>The algorithm increases the relative weight of the misclassified training instances.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>

<span class="n">ada_clf</span> <span class="o">=</span> <span class="nc">AdaBoostClassifier</span><span class="p">(</span>
    <span class="nc">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
    <span class="n">algorithm</span><span class="o">=</span><span class="sh">"</span><span class="s">SAMME.R</span><span class="sh">"</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<span class="n">ada_clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="gradient-boosting"><strong>Gradient Boosting</strong></h3>

<hr />

<p>A type of boosting ensemble method used for classification and regression problems. Gradient boosting tries to fit the new predictor to the residual errors (literally) made by the previous predictor.</p>

<p>The basic idea behind gradient boosting is to build a sequence of models, each of which tries to correct the errors of the previous models. The final prediction is the weighted sum of the predictions of all the models in the sequence.</p>

<p>For example, in a binary classification problem, the first model might predict the probability of the positive class for each example. The second model would then focus on the examples that were misclassified by the first model, and try to improve the predictions for those examples. The third model would then focus on the examples that were still misclassified by the first two models, and so on.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</code></pre></div></div>

<p>Gradient boosting with early stopping:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">xgboost</span>

<span class="n">xgb_reg</span> <span class="o">=</span> <span class="n">xgboost</span><span class="p">.</span><span class="nc">XGBRegressor</span><span class="p">()</span>
<span class="n">xgb_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">xgb_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
           <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)],</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">2</span>
           <span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">xgb_reg</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
</code></pre></div></div>

<p>Gradient boosting is a powerful technique for improving the performance of machine learning models, particularly when working with complex data or when the performance of a single model is not sufficient. However, it can be computationally intensive and may require careful tuning of hyperparameters to achieve good performance.</p>

<p>Overall, ensemble methods are a powerful technique for improving the performance of machine learning models, and they are widely used in industry and research. However, it is important to carefully consider the problem and the available data before choosing an ensemble method.</p>

<p><a href="https://www.kaggle.com/code/dsmeena/ch-7-ensemble-learning-and-random-forests"></a></p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[In this blog post, we‚Äôre going to talk about machine learning and its different types.]]></summary></entry><entry><title type="html">Start a Webserver with aws</title><link href="http://localhost:4000/cloud/2023/10/22/Start-a-webserver-with-aws.html" rel="alternate" type="text/html" title="Start a Webserver with aws" /><published>2023-10-22T15:08:10+05:30</published><updated>2023-10-22T15:08:10+05:30</updated><id>http://localhost:4000/cloud/2023/10/22/Start-a-webserver-with-aws</id><content type="html" xml:base="http://localhost:4000/cloud/2023/10/22/Start-a-webserver-with-aws.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>In this blog, we are gonna try to create our own webserver in aws. We will follow operation Excellence principle by designing it failure by using multi-AZ architecture or extending it to more than 1 availability zones. We will use load balancer to uniformly distribute the requests coming to our webserver to different EC2 instances. and If you have a domain we will learn how to create DNS records so that your domain points to this newly created webserver. While doing all of this we will not forget the security principle of well-architected framework.</p>

<h3 id="create-an-ec2-instance">Create an EC2 Instance</h3>

<p>Let‚Äôs first create an EC2 instance to run our webserver. Amazon Elastic compute cloud (EC2) is a web service that provides resizable computing capacity in the cloud.</p>

<p>EC2 offers a wide range of <a href="https://aws.amazon.com/ec2/instance-types/">instance types</a> to cater to different workload requirements. Here are some commonly used EC2 instance types:</p>

<ul>
  <li>General Purpose Instances</li>
  <li>Compute-Optimized Instances</li>
  <li>Memory-Optimized Instances</li>
  <li>Storage-Optimized Instances</li>
</ul>

<p>For creating a new EC2 instance follow the steps</p>

<ol>
  <li>Go to EC2 service, then go instances and click Launch an Instance.</li>
  <li>Give a name to your instance and choose an ubuntu AMI (Amazon Machine Image), its similar to docker images.</li>
  <li>Choose an Instance type, there are different instance families including General Purpose, compute-optimized, memory-optimized and storage-optimized. For now just choose t2.micro.</li>
  <li>Amazon recommends to use a key pair to securely connect to your instance. If you already have one use that otherwise you can easily create a new one.</li>
  <li>Leave other settings to default.</li>
  <li>Then click Launch Instance.</li>
</ol>

<p><img src="/assets/2024/September/start%20ec2%20instance.png" alt="Fig: Creating a new EC2 Instance" /></p>

<p><em>Fig: Creating a new EC2 Instance</em></p>

<h3 id="set-up-a-web-server">Set up a web server</h3>

<p>For this connect to your EC2 instance, by choosing your newly created instance and then click on connect. Make sure it‚Äôs in running state.</p>

<p><img src="/assets/2024/September/connect%20to%20ec2%20instance.png" alt="Fig: Connecting to EC2 Instance" /></p>

<p><em>Fig: Connecting to EC2 Instance</em></p>

<p>After connecting, run the following commands:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt update
<span class="nb">sudo </span>apt upgrade

<span class="c"># This will instance apache web server</span>
<span class="nb">sudo </span>apt <span class="nb">install </span>apache2
</code></pre></div></div>

<p>If you see something like this after running upgrade, then you need to reboot your system. The different between rebooting and Start/stop is that on start/stop the hardware running your instance is changed but on rebooting the hardware is the same.</p>

<p><img src="/assets/2024/September/start%20ec2%20instance2.png" alt="Untitled" /></p>

<p>In the next screen, select via tab then click enter.</p>

<p><img src="/assets/2024/September/reboot%20instance.png" alt="Fig: Rebooting Instance" /></p>

<p><em>Fig: Rebooting Instance</em></p>

<p>Again connect to your instance and install the Apache webserver. If at this time you try to connect to your apache webserver via your EC2 pubic IP, it will be timed out.  because currently your EC2 instance does not allow http traffic.  For that we need to modify security group.</p>

<h3 id="using-security-group-as-firewall">Using security group as firewall</h3>

<p>Security groups in AWS are virtual firewalls that control inbound and outbound traffic for EC2 instances. They act as a protective layer around instances, allowing you to define rules that specify the protocols, ports, and IP ranges that are allowed to access the instances.</p>

<p>We will create a custom security group for our EC2 instance.  Inside EC2 service go to Network &amp; security panel and click on Create security group.</p>

<p>Add following inbound rules to the security group.</p>

<p><img src="/assets/2024/September/inbound%20rules.png" alt="Fig: Inbound rules to allow http traffic" /></p>

<p><em>Fig: Inbound rules to allow http traffic</em></p>

<p>To change add this newly created security group to your EC2 instance following the steps:</p>

<p>Instances ‚Üí select instance ‚Üí Action ‚Üí security ‚Üí change security group</p>

<p>Add the newly created security group and remove the old security group, then save it.</p>

<p><img src="/assets/2024/September/change%20security%20group.png" alt="Fig: Adding security group to EC2 instance" /></p>

<p><em>Fig: Adding security group to EC2 instance</em></p>

<p>Now, you will be able to send request to your webserver over http connection. To confirm, type the IPv4 address of your EC2 instance in browser and you will see the default Apache web server page.</p>

<p>Hooray, but that‚Äôs not it we are gonna do more than this to improve the architecture of our web server.</p>

<h3 id="create-backups-with-ami-snapshot">Create backups with AMI snapshot</h3>

<p>You can create the backup of your current webserver by creating an Image that contains all the information required to launch more EC2 instances with same configuration.</p>

<p>To create an image of your webserver follow the steps:</p>

<p>Instances ‚Üí select Instance ‚Üí Action ‚Üí Image and templates ‚Üí Create Image</p>

<p>Give some appropriate name to your image and keep the rest settings default. Click on create Image.</p>

<p>It will take some time to create the Image or we can say Amazon Machine Image (AMI). You will be able to check this AMI under AMI section of EC2 instance.</p>

<p><img src="/assets/2024/September/create%20ami%20snapshot.png" alt="Fig: Amazon Machine Images" /></p>

<p><em>Fig: Amazon Machine Images</em></p>

<p>After the status is changed to Available, click on Launch Instance from AMI to create your duplicate web servers. Prefer to select same key-pair, security group and under network settings choose a subnet (Availability zone) other than that your current EC2 instance is using to design for failures.</p>

<p><img src="/assets/2024/September/create%20new%20instance%20from%20ami.png" alt="Fig: Creating new instance from AMI" /></p>

<p><em>Fig: Creating new instance from AMI</em></p>

<p>After this you will have 2 EC2 instances running your webserver in two different availability zones. You can create as many as you want but for now let‚Äôs keep it two and try some more things.</p>

<p>If you try to access the IPv4 of your new instance, you will see the default Apache page.</p>

<h3 id="scaling-with-elastic-load-balancer-elb">Scaling with Elastic Load Balancer (ELB)</h3>

<p>We will create an Elastic Load balancer (ELB) to uniformly route the incoming requests to healthy instances.</p>

<p>There are three types of load balancers that AWS provides:</p>

<ol>
  <li><strong>Application Load Balancer (ALB)</strong>: This load balancer operates at the application layer and is best suited for applications that require advanced routing capabilities. It can distribute traffic based on URL paths or HTTP headers, making it ideal for routing requests to different microservices or handling multiple domains. ALBs are commonly used for web applications, API gateways, and container-based architectures.</li>
  <li><strong>Network Load Balancer (NLB)</strong>: This load balancer operates at the transport layer (Layer 4) and is designed for applications that require ultra-high performance and low latency. It can handle extremely high volumes of traffic and is suitable for TCP/UDP-based applications, gaming, and real-time streaming.</li>
  <li><strong>Gateway Load Balancer (GLB)</strong>: This load balancer is designed to handle traffic at the edge of the AWS network and is used for scenarios where you need to distribute traffic across multiple virtual appliances, such as firewalls, intrusion detection systems, or deep packet inspection systems.</li>
</ol>

<p>For our task application load balancer is best choice. To create ALB go to EC2 dashboard then to Load Balancing section.</p>

<ol>
  <li>Click on Create new load balancer.</li>
  <li>Choose Application load balancer.</li>
  <li>Add security group that allows inbound traffic over internet.</li>
  <li>
    <p>Create a target group and add the EC2 instances ‚Üí Include as pending below ‚Üí Register pending targets.</p>

    <p><img src="/assets/2024/September/register%20target%20group.png" alt="Untitled" /></p>
  </li>
  <li>
    <p>Click Create Load balancer.</p>

    <p><img src="/assets/2024/September//create%20load%20balancer.png" alt="Fig: Application load balancer" /></p>

    <p><em>Fig: Application load balancer</em></p>
  </li>
</ol>

<p>If you go to the DNS name of the elb, you will be routed to one of the healthy EC2 instances.</p>

<p>But this domain doesn‚Äôt look good, if you already have a domain or want to buy a domain in that case you use Route 53.</p>

<h3 id="route-53">Route 53</h3>

<p>Amazon Route 53 is a highly available and scalable Domain Name System (DNS) web service.</p>

<p>You can buy a domain from here also in around $12.</p>

<p>Pricing:</p>

<ul>
  <li>$0.50 per hosted zone / month for the first 25 hosted zones</li>
  <li>$0.10 per hosted zone / month for additional hosted zones</li>
</ul>

<p>If hosted zone deleted within 12 hours of creation then no charge.</p>

<h3 id="create-a-hosted-zone">Create a Hosted zone</h3>

<p>In Amazon Route 53, a hosted zone is a container for a collection of DNS records that define how domain names are resolved. It is a way to manage the DNS records for a domain. Each hosted zone represents a domain and contains the DNS records that specify how traffic for that domain is routed.</p>

<p>Create a hosted zone by going to Route 53 ‚Üí Hosted zones. In the domain add you own domain like <a href="http://abc.com">abc.com</a> Keep the rest default and click create Hosted zone.</p>

<p><img src="/assets/2024/September/create%20hosted%20zone.png" alt="Fig: Hosted zone for my website" /></p>

<p><em>Fig: Hosted zone for my website</em></p>

<p>Nameservers are part of the Domain Name System (DNS) infrastructure and are responsible for translating domain names into IP addresses</p>

<p>Replace your domain name server urls with hosted zone urls.</p>

<p><img src="/assets/2024/September/hostinger.png" alt="Fig: Added Route 53 Name servers" /></p>

<p><em>Fig: Added Route 53 Name servers</em></p>

<p>It might take few hours until the changes reflect for your domain. Till then lets add the record for our ALB.</p>

<p>1st record: It will point to the application load balancer.</p>

<p><img src="/assets/2024/September/create%20record.png" alt="Untitled" /></p>

<p>Create another record with subdomain www, this will point to the our first record.</p>

<p><img src="/assets/2024/September/create%20another%20record.png" alt="Fig: Creating record with www. and routing to dsm-blogs.in" /></p>

<p><em>Fig: Creating record with www. and routing to dsm-blogs.in</em></p>

<p>Now, if you try to access your domain you will see the default Apache web server page.</p>

<p><img src="/assets/2024/September/apache%20running.png" alt="Fig: Now, [dsm-blogs.in](http://dsm-blogs.in) is point to lba which directs to one of EC2 instances" /></p>

<p>Fig: Now, <a href="http://dsm-blogs.in">dsm-blogs.in</a> is point to lba which directs to one of EC2 instances</p>

<p>Hurray, we come really far starting from just EC2 instance to our own domain.</p>

<p>That‚Äôs enough for this blog post. We will continue developing our webserver in future blog posts, by adding storage services like EBS, EFS and S3 and distributing content with CloudFront. Our aim is better understand the usage of services and when to use which service for our application.</p>

<p>Hope you learnt something useful from this blog. See ya in next blog posts ‚ù§Ô∏è‚ù§Ô∏è.</p>]]></content><author><name></name></author><category term="cloud" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Advancing in Git</title><link href="http://localhost:4000/web/2023/09/23/Advancing-git.html" rel="alternate" type="text/html" title="Advancing in Git" /><published>2023-09-23T15:08:10+05:30</published><updated>2023-09-23T15:08:10+05:30</updated><id>http://localhost:4000/web/2023/09/23/Advancing-git</id><content type="html" xml:base="http://localhost:4000/web/2023/09/23/Advancing-git.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>This blog post discusses intermediate techniques for using Git, a version control system commonly used in software development. Topics covered include branch management, interactive staging, cherry-picking commits, creating and applying diff patches, and rebasing. The post also explains the use of pre-receive hooks and the Git Rerere feature.</p>

<h2 id="branch-management">Branch Management</h2>

<h3 id="git-reset">Git reset</h3>

<p>If you‚Äôre using Git and you need to undo changes you made to files, you can use the <code class="language-plaintext highlighter-rouge">git reset</code> command. Basically, it resets your working directory and staging area to a previous commit. So, let‚Äôs say you made some changes to files that you haven‚Äôt committed yet, you can undo those changes with <code class="language-plaintext highlighter-rouge">git reset</code>.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git reset</td>
      <td>reset your working directory and staging area to a previous commit</td>
    </tr>
    <tr>
      <td>git reset ‚Äìsoft HEAD^</td>
      <td>reset your working directory to the previous commit but keep your changes in the staging area</td>
    </tr>
    <tr>
      <td>git reset ‚Äìhard HEAD^</td>
      <td>reset both your working directory and staging area to the previous commit</td>
    </tr>
    <tr>
      <td>git reset <file></file></td>
      <td>unstage a file that you accidentally added to the staging area</td>
    </tr>
    <tr>
      <td>git clean -f</td>
      <td>remove untracked files</td>
    </tr>
    <tr>
      <td>git rm ‚Äìcached testfile.js</td>
      <td>no longer track the file</td>
    </tr>
    <tr>
      <td>git restore ‚Äìstaged file.txt</td>
      <td>unstage the changes made to file</td>
    </tr>
    <tr>
      <td>git restore file.txt</td>
      <td>restore the file to its previous state</td>
    </tr>
  </tbody>
</table>

<p>Just keep in mind that <code class="language-plaintext highlighter-rouge">git reset</code> can be a bit risky since it can permanently discard changes and commits. So be careful when using it, alright?</p>

<h3 id="fetch">Fetch</h3>

<p><code class="language-plaintext highlighter-rouge">git fetch</code> is a command in Git that downloads new changes from a remote repository without merging them into the local branch. It updates the remote-tracking branch, which is a local branch that tracks changes in the remote repository.</p>

<p>After running <code class="language-plaintext highlighter-rouge">git fetch</code>, you can use <code class="language-plaintext highlighter-rouge">git merge</code> or <code class="language-plaintext highlighter-rouge">git rebase</code> to integrate the changes from the remote repository into your local branch. Alternatively, you can use <code class="language-plaintext highlighter-rouge">git checkout</code> to switch to the remote-tracking branch and inspect the changes without merging them.</p>

<p><code class="language-plaintext highlighter-rouge">git fetch</code> is a useful command to use when collaborating with others on a project. It allows you to keep your local repository up-to-date with changes made by others, without affecting your working directory.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git fetch</td>
      <td>Downloads new changes from a remote repository without merging them into the local branch.</td>
    </tr>
    <tr>
      <td>git fetch ‚Äìtags</td>
      <td>Fetches all tags from the remote repository that are not already present in the local repository.</td>
    </tr>
    <tr>
      <td>git fetch ‚Äìprune</td>
      <td>Deletes any remote-tracking branches that are no longer on the remote repository.</td>
    </tr>
    <tr>
      <td>git fetch -p</td>
      <td>Shortcut for <code class="language-plaintext highlighter-rouge">git fetch --prune</code>.</td>
    </tr>
  </tbody>
</table>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># command to overwrite of your local files with the master branch</span>
git fetch <span class="nt">--all</span>
git reset <span class="nt">--hard</span> origin/master
</code></pre></div></div>

<p>The git amend command allows you to modify the most recent commit on your branch. You can use it to add changes you forgot to include in the commit, or to modify the commit message. When you run <code class="language-plaintext highlighter-rouge">git commit --amend</code>, Git will open up your default text editor and allow you to edit the commit message. Once you save and close the editor, the commit message on your most recent commit will be updated.</p>

<p>If you have staged changes that were not included in the previous commit, running <code class="language-plaintext highlighter-rouge">git commit --amend</code> will add those changes to the previous commit. You can also use the <code class="language-plaintext highlighter-rouge">-m</code> flag to modify the commit message without opening the text editor.</p>

<p>To remove a file from the previous commit, you can use <code class="language-plaintext highlighter-rouge">git rm --cached &lt;file&gt;</code> and then run <code class="language-plaintext highlighter-rouge">git commit --amend</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># change the previous commit</span>
git add
git commit <span class="nt">--amend</span> <span class="c"># will add the staged changes to previous commit</span>

git commit <span class="nt">--amend</span> <span class="nt">-m</span> <span class="s2">"New commit message"</span>  <span class="c"># modify commit message</span>

<span class="c"># remove file from staging </span>
git <span class="nb">rm</span> <span class="nt">--cached</span> testfile.js    <span class="c"># no longer tracked</span>
</code></pre></div></div>

<h3 id="force-push-to-a-remote">Force push to a remote</h3>

<p>Reasons to use force push:</p>

<ul>
  <li>Local version is preferable to the remote version</li>
  <li>The remote version went wrong and needs repair</li>
  <li>Versions have diverged and merging is undesirable</li>
  <li>Force push replaces the remote branch with your local branch</li>
  <li>Use with caution</li>
  <li>Commits may disappear</li>
  <li>It can be disruptive for others using the remote branch</li>
  <li>It‚Äôs an easy way to frustrate your development team</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push -f</code> or <code class="language-plaintext highlighter-rouge">git push --force</code></td>
      <td>Force push the changes to the remote repository, replacing the commits that are already there and not in the local repository.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push --force-with-lease</code></td>
      <td>Allow force push if no one else has pushed changes to that branch since you pulled.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git commit -am "Add salsa to shopping list"</code></td>
      <td>Automatically add changed files to the staging area and add the message.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git log</code></td>
      <td>Show the commits in the local repository.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git log origin/main</code></td>
      <td>Show the commits in the <code class="language-plaintext highlighter-rouge">origin/main</code> branch.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git show origin/main</code></td>
      <td>Show the changes done in commits in the <code class="language-plaintext highlighter-rouge">origin/main</code> branch.</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git reset --hard origin/main</code></td>
      <td>Replace the local repository with the remote repository. Collaborators can use this command to replace their local repository with the remote repository.</td>
    </tr>
  </tbody>
</table>

<h3 id="identify-merged-branches">Identify Merged branches</h3>

<p>Here‚Äôs a cool trick for Git! You can use the command <code class="language-plaintext highlighter-rouge">git branch --merged</code> to see which branches have been merged into your current branch. This is really useful if you want to keep track of what features have been incorporated or if you need to do some cleanup after merging a bunch of features. By default, the command uses your current branch, but you can specify other branch names or commits too. Basically, it shows you all the branches whose tips are reachable from the specified commit (or HEAD if you don‚Äôt specify anything). So, if you‚Äôre working on a project with multiple branches, give this command a try!</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git branch ‚Äìmerged</td>
      <td>List branches that have been merged to the current branch</td>
    </tr>
    <tr>
      <td>git branch ‚Äìno-merged</td>
      <td>List branches that haven‚Äôt been merged to the current branch</td>
    </tr>
    <tr>
      <td>git branch -r ‚Äìmerged</td>
      <td>Show results for remote branches that have been merged</td>
    </tr>
    <tr>
      <td>git merge main</td>
      <td>Merge the main branch into the current branch</td>
    </tr>
    <tr>
      <td>git branch ‚Äìmerged july_release</td>
      <td>Show what branches are merged into the specified branch</td>
    </tr>
    <tr>
      <td>git branch ‚Äìmerged origin/july_release</td>
      <td>Show what branches are merged into the specified remote branch</td>
    </tr>
    <tr>
      <td>git branch ‚Äìmerged b325a7c49</td>
      <td>Show what branches have this commit</td>
    </tr>
  </tbody>
</table>

<h3 id="prune-stale-branches">Prune Stale Branches</h3>

<p>To keep your Git repository organized, it‚Äôs important to delete stale branches. A stale branch is a remote-tracking branch that no longer tracks anything because the actual branch in the remote repository has been deleted. To delete a remote branch, you must also delete your remote-tracking branch. However, if another collaborator deletes a remote branch, your remote-tracking branch remains. Fetching does not automatically delete remote-tracking branches, so you must manually prune them.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git branch -d bugfix</code></td>
      <td>Delete local branch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push -d origin bugfix</code></td>
      <td>Delete remote branch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git remote prune origin</code></td>
      <td>Delete stale remote-tracking branches</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git remote prune origin --dry-run</code></td>
      <td>Demo which branch would be pruned or removed</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git branch -r</code></td>
      <td>Show remote-tracking branches</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git fetch --prune</code> or <code class="language-plaintext highlighter-rouge">git fetch -p</code></td>
      <td>Shortcut to prune, then fetch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git config --global fetch.prune true</code></td>
      <td>Always prune before fetch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git prune</code></td>
      <td>Prune all unreachable objects</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git gc</code></td>
      <td>Part of garbage collection</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git prune --expire &lt;time&gt;</code></td>
      <td>Prune unreachable objects older than specified time</td>
    </tr>
  </tbody>
</table>

<h2 id="taging">Taging</h2>

<h3 id="create-tags">Create Tags</h3>

<p>Tags in Git are like bookmarks, marking important points in the history of a repository. They can be used to mark software versions or to highlight key features or changes. You can also use tags to mark points for discussion with collaborators, like bugs or issues. So, if you‚Äôre working on a project in Git, don‚Äôt forget to use tags to help keep track of important points in your repository‚Äôs history!</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git tag issue_136 655da716e7</code></td>
      <td>Add lightweight tag (using hash or branch name)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git tag -am "Version 1.0" v1.0 dd5c49428a0</code></td>
      <td>Add annotated tag (most common)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git tag -d v1.0</code> or <code class="language-plaintext highlighter-rouge">git tag --delete v1.0</code></td>
      <td>Delete a tag</td>
    </tr>
  </tbody>
</table>

<h3 id="list-tags">List Tags</h3>

<p>| Command | Description |
| ‚Äî | ‚Äî |
| git tag
git tag ‚Äìlist
git tag -l | List tags alphabetically |
| git tag -l ‚Äúv2*‚Äù | List tags beginning with ‚Äúv2‚Äù |
| git tag -n | List tags with first line of each annotation |
| git tag -n5 | List tags with five lines of each annotation |
| git show v1.1 | Show changes made in the commits tagged with v1.1 |
| git diff v1.0..v1.1 | Show all differences from v1.0 to v1.1 |
| git switch v1.0 | Switch to the commit or branch labeled as v1.0 |
| git switch -c branch_v1 v1.0 | Create a new branch from a tag |</p>

<h3 id="push-tags-to-a-remote">Push Tags to a Remote</h3>

<p>Like branches, tags are local unless shared to a remote. Git push does not transfer tags, so they must be explicitly transferred. However, git fetch automatically retrieves shared tags. So, if you‚Äôre collaborating with others on a project, make sure to share your tags to keep everyone in the loop!</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push origin v1.0</code></td>
      <td>Push a tag to a remote repository</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push origin --tags</code></td>
      <td>Push all tags to a remote repository</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git fetch</code></td>
      <td>Fetch commits and tags</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git fetch --tags</code></td>
      <td>Fetch only tags (with necessary commits) (rarely used)</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git push -d origin v1.0</code></td>
      <td>Delete remote tags like remote branches</td>
    </tr>
  </tbody>
</table>

<h2 id="interactive-staging">Interactive Staging</h2>

<h3 id="interactive-mode">Interactive Mode</h3>

<p>Interactive staging is a cool feature in Git that lets you pick and choose which changes you want to stage. This means you can make smaller, focused commits and avoid committing changes you‚Äôre not sure about. It‚Äôs also a feature of many Git GUI tools. So, next time you‚Äôre using Git, give interactive staging a try!</p>

<p>To enter into interactive mode, use:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git add <span class="nt">-i</span>
git add <span class="nt">--interactive</span>
</code></pre></div></div>

<p><img src="/assets/2024/September/interactive%20mode.png" alt="Untitled" /></p>

<p>In interactive mode, you can stage changes, unstage changes, and add untracked files. You can choose options either by clicking on the corresponding number or the first letter of the option:</p>

<ul>
  <li>s: Status of the repository</li>
  <li>u: Add files to the staging area</li>
  <li>r: Remove files from the staging area</li>
  <li>a: Add untracked files</li>
  <li>d: Differences in file</li>
  <li>q: Quit interactive mode</li>
  <li>h: Help</li>
</ul>

<h3 id="patch-mode">Patch mode</h3>

<p>In Git, you can pick and choose which changes you want to stage using interactive staging. This means you can make smaller, focused commits and avoid committing changes you‚Äôre not sure about. You can stage each hunk (chunk of changes) separately. It‚Äôs really useful!</p>

<p>To enter patch mode, go to interactive mode and enter ‚Äúp‚Äù, followed by the file number.</p>

<p><img src="/assets/2024/September/patch%20mode.png" alt="Untitled" /></p>

<p>Other ways to use patch mode</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git add ‚Äìpatch or git add -p</td>
      <td>Interactively choose which changes you want to add to the staging area.</td>
    </tr>
    <tr>
      <td>git stash -p</td>
      <td>Interactively choose which changes you want to stash.</td>
    </tr>
    <tr>
      <td>git reset -p</td>
      <td>Interactively choose which changes you want to unstage.</td>
    </tr>
    <tr>
      <td>git restore -p</td>
      <td>Interactively choose which changes you want to discard from your working directory.</td>
    </tr>
    <tr>
      <td>git commit -p</td>
      <td>Interactively choose which changes you want to include in your commit.</td>
    </tr>
  </tbody>
</table>

<h3 id="split-a-hunk">Split a Hunk</h3>

<p>When using Git‚Äôs interactive staging feature, you can split a hunk further by using the ‚Äús‚Äù option in patch mode. This is useful when a hunk contains multiple changes and requires one or more unchanged lines between them.</p>

<h3 id="edit-a-hunk">Edit a Hunk</h3>

<p>When editing a hunk in Git, you can do it manually if needed. This is especially useful when a hunk cannot be split automatically. However, make sure to pay attention to the prefixes (+, -, space) while editing, or the hunk might not be staged correctly. So, take your time and give them the respect they deserve!</p>

<h2 id="share-select-changes">Share Select Changes</h2>

<h3 id="cherry-picking-commits">Cherry-Picking Commits</h3>

<p>Cherry-picking commits is like copying and pasting code from one branch to another. Each commit becomes a new commit on the current branch, and they‚Äôll have different SHA codes. You can cherry-pick commits from any branch, but you can‚Äôt do it with merge commits. You can use the ‚Äìedit or -e flag to edit the commit message if you need to. However, conflicts can arise that you‚Äôll need to resolve. It‚Äôs a useful feature to have in your Git toolkit!</p>

<p><img src="/assets/2024/September/cherry%20pick.png" alt="Untitled" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git cherry-pick d4e8411d09
git cherry-pick d438411d09..57d290ec44
</code></pre></div></div>

<p>Resolve cherry-picking conflicts is similar to resolving merge conflicts. Just edit in editor and try again!</p>

<h3 id="diff-patches">Diff Patches</h3>

<p>If you want to share changes with collaborators but the changes aren‚Äôt ready for a public branch or your collaborators don‚Äôt share a remote, you can use diff patches to share the changes via files. It‚Äôs useful for discussing bugs or issues with collaborators or for sharing changes that need further testing before merging into the main branch.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git diff from-commit to-commit <span class="o">&gt;</span> output.diff
</code></pre></div></div>

<p>Use following common to apply changes in a diff patch file to the working directory. But remember, apply diff patches does not transfer commit history.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git apply output.diff 
</code></pre></div></div>

<h3 id="formatted-patches">Formatted Patches</h3>

<p>In Git, you can export each commit in Unix mailbox format using formatted patches. It‚Äôs a great way to distribute changes via email and includes commit messages. You can apply formatted patches using the <code class="language-plaintext highlighter-rouge">git am</code> command. It‚Äôs similar to cherry-picking, which copies and pastes code from one branch to another. However, formatted patches are better for sharing changes that aren‚Äôt ready for a public branch or when collaborators don‚Äôt share a remote. Keep in mind that applying formatted patches transfers the commit history.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch 2e33d..655da</code></td>
      <td>Creates patch files for all commits in the range</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch main</code> or <code class="language-plaintext highlighter-rouge">git format-patch main..HEAD</code></td>
      <td>Creates patch files for all commits on the current branch that are not in the <code class="language-plaintext highlighter-rouge">main</code> branch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-path -1 655da</code></td>
      <td>Creates a patch file for a single commit with hash <code class="language-plaintext highlighter-rouge">655da</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch 2e33d..655da -o ~/feature_patches</code></td>
      <td>Creates patch files for all commits in the range and puts them into a directory named <code class="language-plaintext highlighter-rouge">feature_patches</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git format-patch 2e33d..655da --stdout &gt; feature.patch</code></td>
      <td>Outputs patch files as a single file named <code class="language-plaintext highlighter-rouge">feature.patch</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git am feature/0001-some-name.patch</code></td>
      <td>Applies a single patch</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git am feature/*.patch</code></td>
      <td>Applies all patches in a directory</td>
    </tr>
  </tbody>
</table>

<p>In the command <code class="language-plaintext highlighter-rouge">git am feature/*.patch</code>, <code class="language-plaintext highlighter-rouge">am</code> stands for ‚Äúapply mailbox‚Äù. This command applies a mailbox-style patch to the current branch.</p>

<h2 id="rebasing">Rebasing</h2>

<h3 id="rebase-commits">Rebase Commits</h3>

<p>Rebasing is a way to move commits from one branch to another. It‚Äôs useful when you want to integrate recent commits without merging and to maintain a clearer, more linear project history. It also ensures that topic branch commits apply cleanly. So, if you‚Äôre working on a project and want to keep your commits organized, give rebasing a try!</p>

<p><img src="/assets/2024/September/rebase.svg" alt="Untitled" /></p>

<p><em>Fig: Rebasing Feature branch <a href="www.atlassian.com">Credit</a></em></p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git rebase main</td>
      <td>Rebase current branch on tip of main (from feature branch)</td>
    </tr>
    <tr>
      <td>git rebase main new_feature</td>
      <td>Rebase new_feature to tip of main (from main)</td>
    </tr>
    <tr>
      <td>git rebase ‚Äìonto newbase upstream branch</td>
      <td>Rebase branch onto newbase</td>
    </tr>
    <tr>
      <td>git rebase ‚Äìonto target main new_feature</td>
      <td>Rebase new_feature commits on target branch that are not on main (merged)</td>
    </tr>
  </tbody>
</table>

<h4 id="handle-rebase-conflicts">Handle Rebase Conflicts</h4>

<p>When you rebase commits, it can cause conflicts with existing code. Git will pause the rebase before each conflicting commit, and you‚Äôll need to resolve the conflicts. This process is similar to resolving merge conflicts. It‚Äôs important to be patient and take your time to ensure that the conflicts are resolved correctly.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git rebase ‚Äìcontinue</td>
      <td>Continue the rebase after resolving conflicts</td>
    </tr>
    <tr>
      <td>git rebase ‚Äìskip</td>
      <td>Skip the current commit during the rebase process</td>
    </tr>
    <tr>
      <td>git log ‚Äìgraph ‚Äìall ‚Äìdecorate ‚Äìoneline</td>
      <td>Visualize the branch history as a graph</td>
    </tr>
    <tr>
      <td>git merge-base main new_feature</td>
      <td>Return the commit SHA where the topic branch diverges from main</td>
    </tr>
    <tr>
      <td>git rebase -i</td>
      <td>Open an interactive rebase prompt to choose which commits to move</td>
    </tr>
  </tbody>
</table>

<p><img src="/assets/2024/September/diverges.png" alt="Fig: The branch test diverges from main" /></p>

<p><em>Fig: The branch test diverges from main</em></p>

<h3 id="merging-vs-rebasing">Merging vs. Rebasing</h3>

<ul>
  <li>Two ways to incorporate changes from one branch into another branch</li>
  <li>Similar ends but the means are different</li>
  <li>Side effects are important to understand</li>
</ul>

<p><img src="https://www.edureka.co/blog/wp-content/uploads/2022/01/fig13.png" alt="Edureak" />
<em>Fig: Git Merge vs Git Rebase <a href="">Credit: Edureka</a></em></p>

<table>
  <thead>
    <tr>
      <th>Merging</th>
      <th>Rebasing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Adds a merge commit</td>
      <td>No additional merge commit</td>
    </tr>
    <tr>
      <td>Nondestructive</td>
      <td>Destructive: SHA changes, commits are rewritten</td>
    </tr>
    <tr>
      <td>Complete record of what happened and when</td>
      <td>No longer a complete record of what happened and when</td>
    </tr>
    <tr>
      <td>Easy to undo</td>
      <td>Tricky to undo</td>
    </tr>
    <tr>
      <td>Logs can become cluttered and nonlinear</td>
      <td>Logs are cleaner and more linear</td>
    </tr>
  </tbody>
</table>

<p><strong>The Golden Rule of Rebasing</strong></p>

<ul>
  <li>Thou Shalt not rebase a public branch</li>
  <li>Rebase abandons existing, shared commits and creates new, similar commits instead</li>
  <li>Collaborators would see project history vanish</li>
  <li>Getting all collaborators back in sync can be hassle</li>
</ul>

<p><strong>How to Choose</strong></p>

<ul>
  <li>Merge to allow commits to stand out or to be clearly grouped</li>
  <li>Merge to bring large topic branches back into main</li>
  <li>Rebase to add minor commits in main to a topic branch</li>
  <li>Rebase to move commits from one branch to another</li>
  <li>Merge anytime the topic branch is already public and being used by others (The Golden Rule of Rebasing).</li>
</ul>

<h3 id="interactive-rebasing">Interactive Rebasing</h3>

<p>Interactive rebasing is a feature in Git that allows you to modify commits as they‚Äôre being replayed. When you run <code class="language-plaintext highlighter-rouge">git rebase -i</code>, Git will open up the git-rebase-todo file for editing. In this file, you can reorder, skip, or edit commits. The options available to you in interactive rebasing include:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">pick</code>: include the commit</li>
  <li><code class="language-plaintext highlighter-rouge">drop</code>: remove the commit</li>
  <li><code class="language-plaintext highlighter-rouge">reword</code>: edit the commit message</li>
  <li><code class="language-plaintext highlighter-rouge">edit</code>: pause the rebasing process to allow you to make changes to the commit</li>
  <li><code class="language-plaintext highlighter-rouge">squash</code>: combine the commit with the one immediately before it</li>
  <li><code class="language-plaintext highlighter-rouge">fixup</code>: combine the commit with the one immediately before it, but discard its commit message</li>
</ul>

<p>Interactive rebasing is useful when you want to modify the history of a branch before sharing it with others. It can also be helpful for cleaning up your commit history by grouping related changes or removing unnecessary commits. However, be careful when using interactive rebasing, as it can be risky if not done properly. It‚Äôs always a good idea to make a backup copy of your branch before rebasing it.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Interactive rebase</span>
git rebase <span class="nt">-i</span> main new_feature

<span class="c"># Rebase last three commits onto the same branch</span>
<span class="c"># but with the opportunity to modify them</span>
git rebase <span class="nt">-i</span> HEAD~3
</code></pre></div></div>

<p><img src="/assets/2024/September/rebase.png" alt="Untitled" /></p>

<h3 id="squash-commits">Squash Commits</h3>

<p>Squash commits is a way to combine multiple commits into one. It‚Äôs useful for when you have several small commits that are related to each other and you want to make them into a single, cohesive commit. This can help to keep your commits organized and make it easier to understand the history of your code.</p>

<p>When squashing commits, you‚Äôll take the changes from each commit and combine them into a single commit. The commit message for the new commit will be a combination of the commit messages from the original commits. You can use the <code class="language-plaintext highlighter-rouge">git rebase -i</code> command to interactively rebase your branch and squash commits.</p>

<p>To squash commits, follow these steps:</p>

<ol>
  <li>Use <code class="language-plaintext highlighter-rouge">git log</code> to find the SHA IDs of the commits you want to squash.</li>
  <li>Use <code class="language-plaintext highlighter-rouge">git rebase -i HEAD~&lt;number of commits&gt;</code> to start an interactive rebase.</li>
  <li>In the interactive rebase, change <code class="language-plaintext highlighter-rouge">pick</code> to <code class="language-plaintext highlighter-rouge">squash</code> for the commits you want to squash. You can also edit the commit messages if needed.</li>
  <li>Save and close the file to complete the rebase.</li>
</ol>

<p>After squashing the commits, you‚Äôll have a single commit that contains all the changes from the original commits. This can be helpful for keeping your commit history clean and organized, especially when collaborating with others on a project.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Rebase last four commits onto the same branch</span>
<span class="c"># but with the opportunity to modify them</span>
git rebase <span class="nt">-i</span> HEAD~4

pick 81a73ff Redesign
squash b2baf90 Change image sizes
fixup c0261b3 Bug fix to the design
squash 0f7760e Adjust styles
</code></pre></div></div>

<h3 id="pull-rebase">Pull Rebase</h3>

<p>Pull rebase is a way to fetch changes from a remote repository and then rebase them onto the local branch instead of merging them. This helps to keep the commit history cleaner by reducing the number of merge commits. However, it should only be used for local commits that are not shared to a remote branch.</p>

<p><img src="https://media.geeksforgeeks.org/wp-content/uploads/20200415234509/Rebasing-in-git.png" alt="" /></p>

<p><em>Fig: Rebasing <a href="geeksforgeeks.org">Credit: GFG</a></em></p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull -r</code></td>
      <td>Pull with rebase</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull --rebase</code></td>
      <td>Pull with rebase</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull --rebase=preserve</code></td>
      <td>Pull with rebase and preserve merge commits</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">git pull --rebase=interactive</code></td>
      <td>Pull with interactive rebase</td>
    </tr>
  </tbody>
</table>

<h2 id="track-down-problems">Track Down Problems</h2>

<h3 id="log-options">Log Options</h3>

<p><code class="language-plaintext highlighter-rouge">git log</code> is a command in Git that displays the commit history for a repository. It shows the SHA-1 hash, author, date, and commit message for each commit in reverse chronological order. By default, it shows the entire commit history for the current branch.</p>

<p>However, there are many options to customize the output, such as sorting, filtering, and formatting. Some common options are <code class="language-plaintext highlighter-rouge">--oneline</code> to show each commit on one line, <code class="language-plaintext highlighter-rouge">--graph</code> to display the commit history as a graph, and <code class="language-plaintext highlighter-rouge">--since</code> or <code class="language-plaintext highlighter-rouge">--until</code> to filter the commit history by date. You can also use <code class="language-plaintext highlighter-rouge">git log</code> to show the commit history for a specific file or directory, or to show the changes made by a specific commit.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git log filename.txt</td>
      <td>List commits that changed filename.txt</td>
    </tr>
    <tr>
      <td>git log -p or git log ‚Äìpatch</td>
      <td>List commits as patches (with diffs)</td>
    </tr>
    <tr>
      <td>git log -L 100,150:filename.txt or git log -L 100,+50:filename.txt</td>
      <td>List changes (as patches) to lines 100-150 in filename.txt</td>
    </tr>
    <tr>
      <td>git log -S ‚ÄúMaxConnections‚Äù</td>
      <td>List all commits that add or change the string</td>
    </tr>
    <tr>
      <td>git log ‚Äìpretty=format:‚Äù%h %cn %cd %s %an‚Äù</td>
      <td>Show commit hash, committer name, commit date, commit message, author name</td>
    </tr>
    <tr>
      <td>git reflog</td>
      <td>Used to recover lost commits and branches</td>
    </tr>
    <tr>
      <td>git log ‚Äìsince=yesterday</td>
      <td>Show commits since yesterday (midnight)</td>
    </tr>
    <tr>
      <td>git log ‚Äìsince=‚ÄùMay 1, 2021‚Äù</td>
      <td>Show commits since a specific date</td>
    </tr>
    <tr>
      <td>git log ‚Äìsince=‚ÄùMay 1, 2021 14:23:45‚Äù</td>
      <td>Show commits since a specific date and time</td>
    </tr>
    <tr>
      <td>git log ‚Äìsince=‚Äù3 days ago‚Äù</td>
      <td>Show commits since a certain number of days ago</td>
    </tr>
    <tr>
      <td>git log ‚Äìsince=‚Äù2 hours ago‚Äù</td>
      <td>Show commits since a certain number of hours ago</td>
    </tr>
  </tbody>
</table>

<p><strong>Git diff</strong></p>

<p>Git uses standard UNIX less program do show the git diff.</p>

<p><img src="/assets/2024/September/git%20diff.png" alt="Untitled" /></p>

<p><strong>Git pager</strong> (used with diff)</p>

<p>The <code class="language-plaintext highlighter-rouge">core.pager</code> setting determines the pager used when Git pages output. This setting can be configured globally or per-repository.</p>

<p>To set the pager globally, use the following command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git config --global core.pager &lt;pager&gt;
</code></pre></div></div>

<p>Replace <code class="language-plaintext highlighter-rouge">&lt;pager&gt;</code> with the name of the pager you want to use, such as <code class="language-plaintext highlighter-rouge">less</code> or <code class="language-plaintext highlighter-rouge">more</code>.</p>

<p>To set the pager per-repository, use the same command without the <code class="language-plaintext highlighter-rouge">--global</code> option, inside the repository directory.</p>

<p>Git comes with a default pager, which is <code class="language-plaintext highlighter-rouge">less</code>. If you haven‚Äôt set a pager explicitly, <code class="language-plaintext highlighter-rouge">less</code> will be used as the default.</p>

<h3 id="blame">Blame</h3>

<p><code class="language-plaintext highlighter-rouge">git blame</code> is a command in Git that allows you to see who made changes to a file, which lines were changed, and when the changes were made. It can be helpful for understanding the history of a file, tracking down the source of a bug, or determining who to contact with questions about a particular piece of code. The output of <code class="language-plaintext highlighter-rouge">git blame</code> includes the commit SHA, author name, date, and the specific line of code that was changed. By default, <code class="language-plaintext highlighter-rouge">git blame</code> shows the annotations for the entire file, but you can also specify a specific range of lines or a specific revision to show annotations for.</p>

<table>
  <thead>
    <tr>
      <th>Command</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>git blame filename.txt</td>
      <td>Annotate file with commit details</td>
    </tr>
    <tr>
      <td>git blame -w filename.txt</td>
      <td>Annotate file with commit details, ignoring whitespace</td>
    </tr>
    <tr>
      <td>git blame -L 100,150 filaname.txt</td>
      <td>Annotate lines 100-150</td>
    </tr>
    <tr>
      <td>git blame -L 100,+50 filename.txt</td>
      <td>Annotate lines 100-150</td>
    </tr>
    <tr>
      <td>git blame d9dba0 filename.txt</td>
      <td>Annotate file at revision d9dba0</td>
    </tr>
    <tr>
      <td>git blame d9dba0 ‚Äì filename.txt</td>
      <td>Same as previous command</td>
    </tr>
    <tr>
      <td>git config ‚Äìglobal alias.praise blame</td>
      <td>Add a global alias for ‚Äúpraise‚Äù (if blame sounds negative)</td>
    </tr>
    <tr>
      <td>git annotate filename.txt</td>
      <td>Annotate file with commit details, different output format</td>
    </tr>
  </tbody>
</table>

<h3 id="bisect">Bisect</h3>

<p>If you‚Äôre trying to find a bug in your Git project, binary search is your friend! Here‚Äôs how it works: first, find the commit that introduced the bug or regression. Then, mark the last good revision and the first bad revision. Reset your code to the midpoint between these two revisions and test it out. If the code is still broken, mark the midpoint as bad. If it‚Äôs fixed, mark it as good. Keep repeating this process, dividing the revisions in half each time, until you find the exact commit that introduced the bug. It may take a few tries, but it‚Äôs worth it to squash that bug!</p>

<p><img src="/assets/2024/September/bisect.png" alt="Untitled" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git bisect start
git bisect good &lt;treeish&gt;
git bisect bad &lt;treeish&gt;
git bisect reset
</code></pre></div></div>

<p>That‚Äôs all for today‚Äôs learning. ü•∞</p>

<h2 id="references">References</h2>

<p><a href="https://github.com/LinkedInLearning/git-intermediate-techniques-3082618">LinkedIn Learning</a></p>]]></content><author><name></name></author><category term="Web" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Generative Pre-training</title><link href="http://localhost:4000/ai/2023/08/13/Generative_pre_training.html" rel="alternate" type="text/html" title="Generative Pre-training" /><published>2023-08-13T10:00:10+05:30</published><updated>2023-08-13T10:00:10+05:30</updated><id>http://localhost:4000/ai/2023/08/13/Generative_pre_training</id><content type="html" xml:base="http://localhost:4000/ai/2023/08/13/Generative_pre_training.html"><![CDATA[<h1 id="introduction-">Introduction üöÄ</h1>

<p>In this blog, we will explore the main idea behind chat-GPT, which is generative pre-training, and create our own smaller version of a question-answering model using generative pre-training. ü§ñüí¨</p>

<p>The research paper we will be referencing is ‚ÄúImproving Language Understanding by Generative Pre-Training.‚Äù üìöüî¨</p>

<h1 id="generative-pre-trained-transformer-gpt-">Generative Pre-Trained Transformer (GPT) üß†</h1>

<h4 id="transfer-learning-">Transfer Learning üîÑ</h4>

<p>Transfer learning is a machine learning technique in which a model trained on a large dataset is adapted for a different but related task. üéì‚û°Ô∏èüÜï</p>

<p>The concept behind transfer learning is that the pre-trained model has learned general patterns and can be adjusted to specific domains or tasks with minimal additional training data. This saves time and resources compared to training a model from scratch. ‚è≥üí∞</p>

<h4 id="generative-pre-training-">Generative Pre-training üîÆ</h4>

<p>In the field of natural language processing, generative pre-training is an example of transfer learning. A language model is pre-trained on a large corpus of text data using self-supervised learning, and then fine-tuned on a smaller, labeled dataset for a specific task. üìö‚û°Ô∏èüéØ</p>

<p>The Generative Pre-trained Transformer (GPT) is a state-of-the-art deep learning architecture developed by OpenAI for natural language processing tasks, such as text generation, text completion, and text classification. üåüü§ñ</p>

<p>GPT models are usually pre-trained on a large corpus of text data from the internet to learn general language patterns. Then, they are fine-tuned on specific domains or tasks using smaller, domain-specific datasets to adapt them to the specific context and language patterns of the target domain. üåê‚û°Ô∏èüéØ</p>

<p>This is a semi-supervised approach that involves unsupervised pre-training and supervised fine-tuning. üîÑüèãÔ∏è</p>

<p>During pre-training in generative pre-training, the model is trained to predict missing words or generate new text based on the input context. The goal is to learn a universal representation that transfers with little adaptation to a wide range of tasks. üß©üîÆ</p>

<p>In the context of generative pre-training, ‚Äúgenerative‚Äù refers to the ability of the model to generate new output based on the input it has learned. In other words, the model is capable of generating new text that is similar to the text it was trained on, but not identical. This is distinct from discriminative models, which are used for tasks such as classification and are designed to distinguish between different input classes. üé®üÜöüîç</p>

<h4 id="self-supervised-learning-">Self-Supervised Learning ü§ñüîÑ</h4>

<p>Self-supervised learning is a type of machine learning in which the model is trained to predict or generate missing information in the data without explicitly being told what the missing information is. This is different from supervised learning, where the model is given labeled data to learn from. üïµÔ∏è‚Äç‚ôÇÔ∏èüß†</p>

<p>An example of self-supervised learning is image inpainting, where the model is trained to fill in missing pixels in an image based on the context of the surrounding pixels. In this case, the model is not explicitly told which pixels are missing, but rather it learns to infer the missing pixels based on the patterns it has learned in the input image. üñºÔ∏èüîç</p>

<p>Self-supervised learning is a powerful approach because it allows the model to learn from large amounts of unlabeled data, which is often easier to obtain than labeled data. This can be especially useful in domains where labeled data is scarce or expensive to obtain. üìäüí°</p>

<h1 id="training-framework-Ô∏èÔ∏è">Training Framework üèãÔ∏è‚Äç‚ôÇÔ∏è</h1>

<p>In the context of generative pre-training, the training framework typically involves two stages: pre-training and fine-tuning. üîÑ</p>

<ol>
  <li>
    <p>Pre-training üéì</p>

    <p>During pre-training, the model is trained on a large, unlabeled corpus of text data using a self-supervised learning approach. This involves predicting missing words or generating new text based on the context of the input. üîÆ</p>

    <p>The goal of pre-training is to learn a general representation of language that can be fine-tuned for specific tasks. üåê</p>
  </li>
  <li>
    <p>Fine-tuning üéØ</p>

    <p>During fine-tuning, the pre-trained model is further trained on a smaller, labeled dataset specific to the task at hand. This involves adjusting the parameters of the pre-trained model to better fit the specific context and language patterns of the target domain. üîß</p>

    <p>Fine-tuning allows the model to adapt to the specific task and improve its performance. üìà</p>
  </li>
</ol>

<p>Overall, the goal of the training framework in generative pre-training is to learn a general representation of language that can be fine-tuned for a wide range of tasks with minimal additional training data. üöÄ</p>

<h2 id="unsupervised-pre-training-">Unsupervised Pre-Training ü§ñüîÆ</h2>

<p>To perform generative pre-training, an unsupervised corpus of tokens $\mu = (u_1, ‚Ä¶, u_n)$ is required. The language modeling objective in this context refers to predicting the next word in a sequence given the previous words. The goal is to maximize the probability of the next word in the sequence given the preceding words.</p>

<p>To achieve this, we use the standard language modeling objective and maximize:</p>

<p>$L_1(U) = \sum_i log P(u_i \lvert u_{i‚àík}, . . . , u_{i‚àí1}; Œò)$</p>

<p>where k is the size of the context window. The conditional probability is modeled using a neural network with parameters $Œò$, which are trained using stochastic gradient descent.</p>

<p>We use a multilayer transformer decoder for the language model, this is used to calculate the probability of next token given a sequence of tokens.</p>

<p>$h_0 = UW_e +W_p$, calculate the initial hidden state of the model.</p>

<p>where:</p>

<p>$U = (u_{-k}, . . . , u_{‚àí1})$ is the context vector of tokens.</p>

<p>$W_e$ is the token embedding matrix, which maps each token to a high-dimensional vector representation.</p>

<p>$W_p$ is the position embedding matrix, which encodes the relative position of each token in the input sequence.</p>

<p>This hidden state is then processed through multiple layers of transformer blocks to produce the final output of the model. Each layer producing a new block of data $h_l$ that serves as the input to the next layer.</p>

<p>$h_l = transformer_block(h_{l‚àí1})‚àÄi ‚àà [1, n]$</p>

<p>where:</p>

<p>n is the number of layers in the transformer block.</p>

<p>We then calculate the probability distribution of the next word in a sequence given the previous words. The softmax function is applied to the dot product of the hidden state vector ($h_n$) and the transpose of the word embedding matrix ($W_e$) to obtain the probabilities of the next word.</p>

<p>$P(u) = softmax(h_nW^T_e )$</p>

<h2 id="supervised-fine-tuning-Ô∏èÔ∏è">Supervised Fine-Tuning üéØüèãÔ∏è‚Äç‚ôÇÔ∏è</h2>

<p>We use a labeled dataset C and a sequence of input tokens $x^1, x^2, ‚Ä¶., x^m$ and a label y. These inputs are passed through the pre-trained model to obtain the final output $h_l^m$, which is then fed to a linear output layer with parameter $W_y$.</p>

<p>This equation $P(y\lvert x^1, . . . , x^m) = softmax(h_l^m W_y)$ calculates the probability of target output y given a set of input tokens $x^1, . . . , x^m$.</p>

<p>where:</p>

<p>$h_l^m$ represents the hidden state of the model after processing the input sequence (of size m) through l layers of transformer blocks.</p>

<p>$W_y$ is the parameter matrix of the fine-tuned model.</p>

<p>The final objective is to maximize:</p>

<p>$L_2(C) = \sum_{(x, y)}log P(y\lvert x^1,‚Ä¶,x^m)$ i.e. the objective is to maximize a function $L_2(C)$, which is a sum of logarithmic probabilities.</p>

<p>Including language modeling as an auxiliary objective to fine-tuning helps learning by improving the generalization of the supervised model and accelerating convergence. To achieve this, we add $L_1(C)$ language modeling objective with weight $\lambda$. Therefore, the final objective to maximize is:</p>

<p>$L_3(C) = L_2(C) + \lambda * L_1(C)$</p>

<h1 id="task-specific-input-transformations-">Task-specific Input Transformations üîÑ</h1>

<p>We use a traversal-style approach to convert structured inputs into an ordered sequence that our pre-trained model can process.</p>

<p><img src="/assets/2024/September/gpt.png" alt="Fig: **(Left) Transformer architecture and training objectives used in this work.
      (Right) Input transformations for fine-tuning on different tasks. We convert all structured inputs into token sequences to be processed by our pre-trained model, followed by a linear + softmax layer.**" /></p>

<p><em>Fig: <strong>(Left) Transformer architecture and training objectives used in this work.
      (Right) Input transformations for fine-tuning on different tasks. We convert all structured inputs into token sequences to be processed by our pre-trained model, followed by a linear + softmax layer.</strong></em></p>

<ol>
  <li>
    <p>Textual Entailment üß©</p>

    <p>For entailment tasks, we concatenate the token sequences of the premise p and hypothesis h, with a delimiter token ($) in between.</p>
  </li>
  <li>
    <p>Similarity ü™û</p>

    <p>For similarity tasks, the input sequence contains both possible sentence orderings (with a delimiter in between). We process each independently to produce two sequence representations $h_l^m$.</p>
  </li>
  <li>
    <p>Question Answering and Commonsense Reasoning üí°</p>

    <p>For these tasks, we are given a context document z, a question q, and a set of possible answers ${a_k}$. We create a sequence of [z;q;$;a_k].</p>
  </li>
</ol>

<p>Each of these sequences is processed independently with our model and then normalized via a softmax layer to produce an output distribution over possible answers.</p>

<h3 id="implementation">Implementation</h3>

<p>You can find the Implementation of fine Tuning this GPT2 model on question-answering dataset here .</p>

<p><a href="https://www.kaggle.com/code/dsmeena/pytorch-fine-tuning-gpt2">Kaggle</a></p>

<h3 id="references">References</h3>

<p><a href="https://paperswithcode.com/method/gpt">Papers with Code - GPT Explained</a></p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Introduction üöÄ]]></summary></entry><entry><title type="html">Attention in DL</title><link href="http://localhost:4000/ai/2023/06/25/Attention_in_DL.html" rel="alternate" type="text/html" title="Attention in DL" /><published>2023-06-25T10:00:10+05:30</published><updated>2023-06-25T10:00:10+05:30</updated><id>http://localhost:4000/ai/2023/06/25/Attention_in_DL</id><content type="html" xml:base="http://localhost:4000/ai/2023/06/25/Attention_in_DL.html"><![CDATA[<p>Welcome to this blog post on attention in deep learning! In this post, we will explore the concept of attention and its importance in the field of deep learning. We will start by explaining what attention is and how it works, and then move on to different types of attention mechanisms and their applications. Whether you are new to deep learning or an experienced practitioner üßë‚Äç‚öïÔ∏è, this post is sure to provide valuable insights into one of the most important concepts in modern machine learning.</p>

<h1 id="attention">Attention</h1>

<p>Attention is a mechanism in neural networks that allows the model to focus üîç on specific parts of the input sequence when making predictions. It has been a breakthrough in natural language processing and computer vision.</p>

<p>Attention was first introduced in 2014 by Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio, and since then, it has become a fundamental concept in deep learning.</p>

<p><img src="/assets/2024/September/attention%20mechanism.png" alt="Fig: The attention mechanism improves model‚Äôs prediction. Taken from Show, Attend and Tell: Neural Image Caption Generation with Visual Attention" /></p>

<p><em>Fig: The attention mechanism improves model‚Äôs prediction. Taken from Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</em></p>

<h2 id="working-of-attention-">Working of Attention üë∑</h2>

<p>The attention mechanism assigns weights to each element in the input sequence, indicating their relevance to the current output. Here‚Äôs how it works:</p>

<ol>
  <li>The attention weights üèãÔ∏è‚Äç‚ôÄÔ∏è are computed based on the current state of the model and the entire input sequence.</li>
  <li>The input sequence is multiplied ‚ùå element-wise by the attention weights, producing a sequence of weighted vectors. These vectors are then summed ‚ûï to obtain a single vector or context vector that captures the most relevant parts of the input sequence.</li>
  <li>
    <p>This weighted sum of the input sequence or context vector is then used to compute the next state of the model.</p>

    <p>How? by concatenating üîó the context vector with the decoder output and passing through a feedforward neural network to get the final output sequence which is again used to update decoder hidden state.</p>
  </li>
</ol>

<p>By focusing on specific parts of the input sequence that are most relevant to the current output, the attention mechanism improves the model‚Äôs performance.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  Input Sequence  --&gt; Encoder --&gt; Attention --&gt; Decoder --&gt; Output Sequence
</code></pre></div></div>

<p>In this diagram, the input sequence is first passed through an encoder, which produces a set of encoded representations. The attention mechanism then computes weights for each encoded representation, indicating its relevance ü§î to the current output. The weighted sum of the encoded representations is then passed through a decoder, which produces the final output sequence.</p>

<h2 id="coding-view-">Coding View üßë‚Äçüíª</h2>

<p>To write an attention model from scratch, you would need to define the input and output shapes of the model, as well as the layers to be used. The model would then need to be trained using a suitable loss function and optimizer.</p>

<p>Here is an example of how to implement an attention model using TensorFlow üåä:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">dot</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">concatenate</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="n">tensorflow.keras.backend</span> <span class="k">as</span> <span class="n">K</span>

<span class="c1"># Define the input sequence shape and size
</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1"># Define the encoder and decoder layers using LSTM cells
</span><span class="n">encoder_inputs</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
<span class="n">encoder_lstm</span> <span class="o">=</span> <span class="nc">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span> <span class="o">=</span> <span class="nf">encoder_lstm</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">)</span>
<span class="n">encoder_states</span> <span class="o">=</span> <span class="p">[</span><span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span><span class="p">]</span>

<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
<span class="n">decoder_lstm</span> <span class="o">=</span> <span class="nc">LSTM</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">decoder_lstm</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_states</span><span class="p">)</span>

<span class="c1"># Compute attention weights
</span><span class="n">attention</span> <span class="o">=</span> <span class="nf">dot</span><span class="p">([</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">attention</span> <span class="o">=</span> <span class="nc">Activation</span><span class="p">(</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)(</span><span class="n">attention</span><span class="p">)</span>

<span class="n">context</span> <span class="o">=</span> <span class="nf">dot</span><span class="p">([</span><span class="n">attention</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">decoder_combined_context</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">context</span><span class="p">,</span> <span class="n">decoder_outputs</span><span class="p">])</span>

<span class="c1"># Define the output layer
</span><span class="n">output_layer</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="nf">output_layer</span><span class="p">(</span><span class="n">decoder_combined_context</span><span class="p">)</span>

<span class="c1"># Define the model
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">([</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">],</span> <span class="n">output</span><span class="p">)</span>

</code></pre></div></div>

<p>In this example, we first define the shape and size of the input sequence. The input vectors have a dimensionality of 32 and input sequence has a length of 10.</p>

<p>Let‚Äôs take a quick glance, at these terms. üßê</p>

<table>
  <thead>
    <tr>
      <th>Term</th>
      <th>Definition</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Input Vectors</td>
      <td>Represent the elements of the input sequence</td>
    </tr>
    <tr>
      <td>Input Sequence</td>
      <td>Input of the model</td>
    </tr>
    <tr>
      <td>Input size</td>
      <td>Refers to the dimensionality of the input vectors</td>
    </tr>
    <tr>
      <td>Input sequence length</td>
      <td>Refers to the number of elements in the input sequence.</td>
    </tr>
  </tbody>
</table>

<p>We then define the encoder and decoder layers üß± using LSTM cells, similar to the previous example.</p>

<p>We then compute the attention weights by taking the dot product of the decoder outputs and encoder outputs, and passing the result through a softmax activation function ü•é to obtain the attention weights.</p>

<p>We then compute the context vector üìÉ by taking the dot product of the attention weights and the encoder outputs.</p>

<p>Finally, we concatenate üîó the context vector and the decoder outputs, and pass the result through the output layer to obtain the final output.</p>

<p>There are many variations and improvements that can be made depending on the specific task and dataset being used.</p>

<h2 id="mathematical-view-">Mathematical View üë©‚Äçüî¨</h2>

<p>Here are the mathematical equations for the attention mechanism:</p>

<p>Let $h_t$ be the hidden state of the decoder at time $t$, and let $e_{i,j}$ be a score that measures the relevance of the ith encoder output ($h_i$) and the jth decoder hidden state ($h_j$).</p>

<p>The attention scores $e_{i,j}$ can be computed using various methods, such as dot product, additive, and multiplicative attention.</p>

<p>In the <strong>dot product method üîµ</strong>, the scores are computed as the dot product of the encoder outputs and the decoder hidden state:</p>

<p>$e_{i,j} = h_i^T h_j$</p>

<p>In the <strong>additive method ‚ûï</strong>, the scores are computed as the sum of two feedforward neural networks:</p>

<p>$e_{i,j} = v_a^T \tanh(W_a h_i + U_a h_j)$</p>

<p>where $v_a$, $W_a$, and $U_a$ are learnable weight matrices.</p>

<p>In the <strong>multiplicative method ‚úñÔ∏è</strong>, the scores are computed as the dot product of the decoder hidden state and a learnable weight matrix, which is then multiplied element-wise with the encoder outputs:</p>

<p>$e_{i,j} = h_i^T W_a h_j$</p>

<p>where $W_a$ is a learnable weight matrix.</p>

<p>In all cases, the attention mechanism allows the model to focus üîç on specific parts of the input sequence that are most relevant to the current output, improving the performance of the model.</p>

<p>The attention weights $\alpha_{i,j}$ are computed using the softmax function ü•é:</p>

<p>$\alpha_{i,j} = \frac{\exp(e_{i,j})}{\sum_{k=1}^{T_x} \exp(e_{i,k})}$</p>

<p>where $T_x$ is the length of the input sequence,</p>

<p>The exponential function: $\exp(x) = e^x$</p>

<p>The context vector $c_t$ is then computed as a weighted sum ‚ûï of the encoder outputs, using the attention weights:</p>

<p>$c_t = \sum_{i=1}^{T_x} \alpha_{i,t} h_i$</p>

<p>Finally, the context vector is concatenated üîó with the decoder hidden state $h_t$ and passed through a feedforward neural network to obtain the final output.</p>

<p>This output represents the model‚Äôs prediction or the next state of the model.</p>

<h2 id="self-attention-">Self-Attention ü§≥</h2>

<p>Self-attention, also known as intra-attention, is a type of attention mechanism where the input sequence is compared ü™û to itself to obtain a set of attention weights. This allows the model to attend to different parts of the input sequence when making predictions, without requiring any additional context.</p>

<h3 id="working-of-self-attention-">Working of self-attention üë∑</h3>

<p>In self-attention, the input sequence is first passed through three linear transformations to obtain query, key üóùÔ∏è, and value vectors.</p>

<p>Let‚Äôs say we have an input sequence of length $T_x$ and input size $d$.</p>

<p>Then, we define three weight matrices $W_q$, $W_k$, and $W_v$, each of shape $d \times d$.</p>

<p>We use these weight matrices to transform the input sequence into query, key, and value vectors:</p>

<ul>
  <li>
    <p>The query ‚ùì vector $q_i$ for the ith element of the input sequence is obtained by multiplying the input sequence by $W_q$:</p>

    <p>$q_i = W_q x_i$</p>
  </li>
  <li>
    <p>The key üóùÔ∏è vector $k_j$ for the jth element of the input sequence is obtained by multiplying the input sequence by $W_k$:</p>

    <p>$k_j = W_k x_j$</p>
  </li>
  <li>
    <p>The value ‚öñÔ∏è vector $v_t$ for the th element of the input sequence is obtained by multiplying the input sequence by $W_v$:</p>

    <p>$v_t = W_v x_t$</p>
  </li>
</ul>

<p>where $x_i$, $x_j$, and $x_t$ are the embeddings of the ith, jth, and th elements of the input sequence, respectively.</p>

<p>These vectors are then used to compute the attention scores as the dot product üîµ of the query and key vectors, which is then scaled by the square root of the dimensionality $d$ to prevent the scores from becoming too large:</p>

<p>$e_{i,j} = \frac{q_i^T k_j}{\sqrt{d}}$</p>

<p>where $q_i$ and $k_j$ are the query and key vectors for the ith and jth elements of the input sequence, respectively.</p>

<p>The attention scores are then normalized using the softmax function ü•é to get attention weights:</p>

<p>$\alpha_{i,j} = \frac{\exp(e_{i,j})}{\sum_{k=1}^{T_x} \exp(e_{i,k})}$</p>

<p>where $T_x$ is the length of the input sequence.</p>

<p>The context vector $c_i$ for the ith element of the input sequence is then computed as the weighted sum ‚ûï of the value vectors, using the attention weights:</p>

<p>$c_i = \sum_{j=1}^{T_x} \alpha_{i,j} v_j$</p>

<p>where $v_j$ is the value vector for the jth element of the input sequence.</p>

<p>Finally, the context vectors are concatenated üîó and passed through a feedforward neural network to obtain the final output.</p>

<p>It represents the model‚Äôs prediction or the next state of the model. The specific details of the final output would depend on the architecture and task of the deep learning model being used.</p>

<p>However, self-attention is particularly useful in natural language processing tasks, where the input sequence is often a sequence of words or tokens, and the model needs to capture long-range dependencies between them.</p>

<p>Self-attention has been a breakthrough in natural language processing and has been used in many state-of-the-art models such as BERT and GPT-2.</p>

<h3 id="differences-">Differences üîé</h3>

<p>In Generic attention, on the other hand, the input sequence is compared to some additional context to obtain a set of attention weights.</p>

<p>The additional context can be the current state of the model (like decoder outputs), image or another sequence.</p>

<p>For example,</p>

<p>In image captioning, üì∏ the model uses both the image and the previously generated words as additional context to generate a caption. The attention mechanism can then focus on different parts of the image when generating each word of the caption.</p>

<p>Similarly, in machine translation ü§ñ, the model can use the previously generated words as additional context when generating the next word. The attention mechanism can then focus on different parts of the source sentence when generating each word of the target sentence.</p>

<p>So, the additional context can be any sequence or vector that is relevant to the task being performed by the model, including the output of the model itself.</p>

<p>The key difference between the two is that in <strong>scaled dot product attention</strong> üîµ, the query, key, and value matrices are all derived from different sources, while in self-attention, they are all derived from the same input sequence.</p>

<p>Scaled dot product attention is commonly used in transformer-based models, while self-attention is commonly used in recurrent neural networks and other models for natural language processing tasks.</p>

<p>This differences will help you better understand the attention mechanism.</p>

<h2 id="types-of-attention-mechanism">Types of Attention Mechanism</h2>

<p>There are several types of attention mechanisms, including:</p>

<h3 id="global-attention-">Global attention üåç</h3>

<p>In this type of attention, the model considers all the input elements when computing the attention weights. It is also known as hard attention or window-based attention.</p>

<p>For example, in image captioning, global attention can be used to attend to all the regions of the image when generating the corresponding caption.</p>

<p>However, global attention can be computationally expensive when dealing with long input sequences, as it requires computing the attention weights for all the input elements.</p>

<h3 id="local-attention-">Local attention üè†</h3>

<p>In this type of attention, the model only considers a subset of the input elements when computing the attention weights. This subset can be determined based on the current state of the model or other factors. It is also known as soft attention or content-based attention.</p>

<p>For example, in machine translation, local attention can be used to attend to a subset of the source sentence when generating the corresponding target sentence.</p>

<h3 id="multi-head-attention-">Multi-head attention ü§π</h3>

<p>In this type of attention, the model computes multiple sets of attention weights, each focusing on a different part of the input sequence. 
In multi-head attention, the input is split into multiple heads, each of which is processed using self-attention. The outputs of the multiple heads are then concatenated and passed through a linear layer to produce the final output.</p>

<p>This allows the model to capture different aspects of the input sequence simultaneously.</p>

<p>One example of a complex task that requires multi-head attention is language modeling üîÆ, where the model is trained to predict the next word in a sentence given the previous words. In this task, the model needs to capture both local dependencies between adjacent words and long-range dependencies between distant words. Multi-head attention can be used to capture both types of dependencies by allowing the model to attend to different parts of the input sequence in parallel. This has been demonstrated in models such as GPT-2 and BERT, which have achieved state-of-the-art performance on a wide range of natural language processing tasks.</p>

<p><img src="/assets/2024/September/soft-hard.png" alt="Fig: As the model generates each word, its attention changes to reflect the relevant parts of the image. ‚Äúsoft‚Äù (top row) vs ‚Äúhard‚Äù (bottom row) attention. 
Taken From Show, Attend and Tell: Neural Image Caption Generation with Visual Attention" /></p>

<p><em>Fig: As the model generates each word, its attention changes to reflect the relevant parts of the image. ‚Äúsoft‚Äù (top row) vs ‚Äúhard‚Äù (bottom row) attention. 
Taken From Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</em></p>

<p>Each type of attention mechanism has its own advantages and disadvantages, and the choice of which one to use depends on the specific task and dataset being used.</p>

<h2 id="applications">Applications</h2>

<p>Attention has been used in various applications in deep learning, such as machine translation, speech recognition, image captioning, and question answering.</p>

<p>One of the most popular models that use attention is the Transformer, which was introduced in 2017 by Vaswani et al.</p>

<p>Overall, attention has proven to be a powerful mechanism in deep learning that allows the model to focus on specific parts of the input sequence, improving the performance of various deep learning models.</p>

<h2 id="references-">References üëè</h2>

<p><a href="https://towardsdatascience.com/transformers-89034557de14">Data science</a></p>

<p><a href="https://arxiv.org/pdf/1502.03044.pdf">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention ‚Üí Image captioning using Attention</a></p>

<p><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is All you Need ‚Üí Self-Attention, Multi-Head Attention, Transformers</a></p>

<p>That‚Äôs it for this blog, hope this was will help you better understand the concepts of deep learning ‚ù§Ô∏è‚ù§Ô∏è.</p>]]></content><author><name></name></author><category term="AI" /><summary type="html"><![CDATA[Welcome to this blog post on attention in deep learning! In this post, we will explore the concept of attention and its importance in the field of deep learning. We will start by explaining what attention is and how it works, and then move on to different types of attention mechanisms and their applications. Whether you are new to deep learning or an experienced practitioner üßë‚Äç‚öïÔ∏è, this post is sure to provide valuable insights into one of the most important concepts in modern machine learning.]]></summary></entry></feed>